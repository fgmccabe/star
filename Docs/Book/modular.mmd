#Boiling the Ocean[boiling-the-ocean]

It is a commonplace in software engineering that you should not try to 'boil the ocean'; which is a synonym for 'biting off more than you can chew'. However, it _is_ possible to build very large scale systems if you approach it in the right way. This is the purview of architecture and of software development teams.

>The 'right' way to boil an ocean is one cup at a time. The 'smart' way to do it is to build a machine that makes cups that boil the ocean.

Building software in the context of a team is quite different to writing individual functions in a program. It is not enough for your code to compute the correct function; it must also interact properly with the environment it is in. As a result, professional programmers find themselves often more concerned with making sure that all the 'pieces' are in the right place than simply the correctness of an algorithm.[^This is not to deny that correctness is important. It is just that algorithm correctness is _not enough_.] Interfaces, contracts, APIs and integration issues often dominate the system builder's landscape.

>One's attitude to basic language features like types is also different: having to deal with the knowledge that is in your co-worker's head (and not yours) should be enough to convince anyone of the merits of strong static types.

**Star**'s modularity features are built from the same functional programming foundation as the other features of the language. This has important implications for the programmability of larger systems.

##Packages and Worksheets[packages-and-worksheets]

We have already seen the two basic forms of compilation unit in **Star**: the `package` and the `worksheet`.

>Since **Star** is an extensible language, it is quite possible to create other forms of compilation unit.

### Package [package]

**Package**
: A `package` is a collection of definitions that are intended to represent some coherent functionality or purpose.

This is, of course, a vague and non-actionable definition. There _are_ higher-level notions of what 'functionality' might mean: for example, in the context of Service Oriented Architecture, a **service** is the 'manifestation of a business functionality'. If that is clearer, then a `package` is a manifestation of an application functionality. Purpose is a topic we will return to in our chapter on agents.

For all of its vagueness, the basic idea of a `package` is that it is a container for a collection of definitions. **Star**'s modularity makes it quite straightforward to refactor your package hierarchy should you need to.

The form of a package is

_Package Identifier_ `{` _Definitions_ `}`


The _Package Identifier_ at the beginning of the package definition is the name of the package. It typically consists of a sequence of identifiers separated by periods. Normally a package identifier has little role within the package itself; it is used when referring to the package externally.

Most of the _Definitions_ are those that we have already seen: function definitions, variable definitions and type definitions. There are some additional forms however, including the `import` statement — that allows one to import elements from other packages.

####The `main` Program[the-main-program]

If a package defines a main procedure[^A procedure, in **Star**, is a function that returns the void tuple `()`.] then that package may act as a command-line program as well as a package. There are two styles of main program possible; one where command line arguments are automatically converted into regular values and one where you get the arguments as a `list[string]`s.

If the `main` procedure is defined then automatic coercion from command line arguments to internal types is performed. For example,

```
myProgram{
  main:(integer,string)=>().
  main(Count,Name) do {
    ...
  }
}
```

With this style of `main`, a command-line invocation of the program is possible:

```
$ Star myProgram 34 fred
```

where the run-time verifies verifies that exactly two arguments are passed, the first being an integer. In principle, the arguments of `main` may be of _any_ type — so long as the type is known to implement the `coercion` contract:

`coercion[string,`_T_`]`

where _T_ is the type being passed to the `main` function. I.e., so long as there is a way of parsing a `string` value we can pass such arguments from the command line to our main program. However, there is another constraint: the ability of the operating system to pass in arbitrary strings to a command line program.

>For example, `list` structures are difficult to get past the typical shell:

```
$ Star myProgram "list of [1,2,3]"
```

In practice, this means that most simple types can easily be passed to a `main` procedure; and, with some difficulty, collection types such as `list[integer]` may also be used.

>This capability is not often provided in programming languages. Normally, you are limited to passing in an array of strings to the top-level main function. Why this is the case is a question best asked of the respective programming language designers.

However, for program safety reasons, it is not permitted to coerce strings into _functions_ or other forms of code (the ability to coerce a string into a function amounts to dynamic compilation).

If you want to manage all the command-line arguments, then define the procedure `_main` instead:

```
myProgram{
  _main:(list[string])=>()
  _main(args) do { ... }
}
```

The `_main` procedure is given all the command line arguments as a `list[string]`. This variant of `_main` (you cannot have both in the same package) is useful if you want to process command line arguments with dash-options.

###Worksheet[worksheet]

We have already seen a number of examples of using worksheets. They represent a modern replacement for the traditional REPL — or Read-Eval-Print-Loop. The main advantages of worksheets over the traditional REPL are that they simultaneously act as their own transcript and they integrate well with editor-centric IDEs.

>We prefer worksheets to normal packages for the same situations as one might prefer a REPL over a traditional file: worksheets make it easy to set up simple experiments and 'see what happens' when you try something.

The contents of a worksheet may be anything that counts as a definition — including `import` statements. In addition, there are some special 'actions' that may be specified; some of which we have already seen:

**`perform`**
: `perform` an action. For example:

```
worksheet{
  perform task {
    logMsg(info,"This is an action")
  }
}
```

`perform` is used to perform a `task` expression.

**`ignore`**
: Evaluate an expression for side-effect purposes; ignoring its value.

  This is used in those cases where a computation has a value that we wish to ignore – i.e., is evaluated for its effect only.

  In many programming languages expressions are automatically 'promoted' to statements. For example, if you have the expression `3+X` in Java (say) then it is also a statement:

```
while(true){
  3+X;
}
```

Of course, in this case, the expression `3+X` doesn't do anything; but the feature is commonly used to allow a function call in a situation where the returned value is thrown away or 'ignored'.

**Star** does not have an _automatic_ way of promoting expressions to actions; but you can use the `ignore` keyword for the same effect. The action

```
ignore 3+X
```

is the way that you would write `3+X` as an action.

**`show`**
: Evaluate an expression and `show` its value.

For example:

```
worksheet{ show 1+2 }
```

`show` is probably the most used special action in a worksheet. After all, the purpose of a worksheet is to help figure out what is going on...

**`assert`
: `assert` a condition.

For example:

```
worksheet{ assert 3>2 }
```

**`{` ... `}`**
: Perform a block of actions, enclosed in parentheses.

For example:

```
worksheet{
  {
    for Ix in range(0,10,1) do{
      logMsg(info,"hello $Ix")
  }
}
```

In many cases, the actions that are used most often are the `show` and the `assert` actions; in conjunction with a set of regular definitions. This reflects one of the main purposes of the worksheet: to give some insight into the behavior of a program.

Unlike a traditional REPL, because the worksheet is in a file, there is much more freedom within a `worksheet` to order things. In particular the definitions can be in any order: a later definition may be referenced explicitly or implicitly in a `show` action.

>It _is_ possible to include actions in a regular `package`. However, especially in cases where the package is to be imported into another program this practice is not recommended.

###Importing Packages[importing-packages]

There are two basic ways of importing a package[^You cannot import a worksheet.] into your code: the _open import_ and the _named import_. The open import is the simplest; to import a package you just import it (sic):

```
worksheet{
  import myPackage.

  -- Use definitions from myPackage
}
```

You can also import packages outside the `worksheet` structure:

```
import myPackage.
worksheet{
  -- Use definitions from myPackage
}
```

Any definition that is contained in `myPackage` is available throughout the worksheet (or other package if you are building a
package).

>Like other forms of definition, the `import` statement may appear anywhere at the top-level of the importing `worksheet` or `package`. However, it is normally at the beginning of the package.

The second way of importing a package is to use the _named import_. As suggested, a named import associates a local identifier with the import:

```
worksheet{
  mP is import myPackage

  -- Use definitions from myPackage via mP
}
```

For example, suppose that `myPackage` looked like:

```
myPackage{
  public all t ~~ foo[t] ::= foo(t) | bar.

  public unFoo:all t ~~ (foo[t]) => t.
  unFoo(foo(X)) => X.
}
```

To use the `unFoo` function in our second worksheet, we simply reference it as a field in the `mP` variable:

```
worksheet{
  mP is import myPackage.

  getTheStuff:all t ~~ (mP.foo[t])=>t.
  getTheStuff(F) is mP.unFoo(F).
}
```

What may be a little surprising is that this applies to the `foo` type also, and also to the `foo` and `bar` constructors:

```
worksheet{
  mP is import myPackage.

  wrapF:all t ~~ (option[t])=>foo[t].
  wrapF(none) => mP.bar.
  wrapF(some(X)) => mP.foo(X).
}
```

One of the benefits of the named import is that it makes it possible to import packages even when there are potential clashes amongst the packages being imported and/or definitions in the importing package itself.

By using named imports the effect is to establish a local _namespace_ for the imported package. Different definitions imported from different places can be reliably distinguished using the normal record field access syntax (i.e., a period).

####Private and Public Imports[private-imports]
By default, when a package is imported, it is privately imported -- the contents of the package are not automatically re-exported. This means that if a package implicitly re-exports something from a package (such as a type) then when you import the package you must also import the dependent packages.

However, when constructing a library, which itself may be built from more than one package, it can become tedious to require clients to import all the constituent packages of the library.[It also exposes the structure of the library to clients; something that is typically not desirable.]

In order to facilitate the construction of libraries, and larger scale packages, we allow for so-called public imports.

A public import is written:

```
public import fooPkg.
```
This will have the effect of re-exporting elements of `fooPkg` as though they were directly exported (made `public`) by the current package.

One common pattern for specifying libraries -- that are made of multiple packages -- is though a stub package that just consists of a sequence of `public` imports:

```
libraryPkg{
  public import part1.
  public import part2.
  ...
}
```

##Code Products[code-products]

One important question that must be answered in any scheme that permits importing is "where is the code coming from?". **Star** has three architectural elements that are the basis of code management: the _code repository_, a system of _universal resource identifiers_ (URI) to identify packages uniquely, and _catalog_s to reduce the bureaucratic burden.

>The issues that show up when managing resources tend to fall in the 'annoyingly complex' rather than 'rocket science' category. However,that does not make them less important, and addressing them certainly helps with that oceanic problem.

###Code Repository[code-repository]

Apart from simply being a place compiled code can be kept, a _code repository_ has several other responsibilities: it must be possible to access the compiled code from multiple packages — including packages that were imported. In fact, a **Star** code repository is able to contain the compiled code of any number of packages — since code repositories are also used to hold compiled libraries as well as applications.

In addition, we have to be able to manage multiple _versions_ of a given compiled package; in some cases an application may be using multiple versions of a package (different libraries may have dependencies on specific versions of a package).

The scale of the repository is also flexible: ranging from a and we must be able to manage different kinds of code repository: from individual packages, libraries of packages and even large-scale collections of libraries.

We will not go into the details of **Star**'s code repositories here. However, note that code repositories may store their code in different ways — file systems, memory, in a _Star Archive_. Furthermore, repositories can be combined into composite repositories.

###Universal Resource Identifier[universal-resource-identifier]

Each package is identified by a URI. The intention of a URI is that a given URI identifies exactly one package.

>The URI has an IETF standard specification (RFC 2396) [][#rfc2396].


One important source of confusion with the IETF URI is the distinction between URIs and URLs. Although they share a common syntax a URI is _not_ intended to convey the _location_ of the resource.

For example, the URI

```
file://foo/bar/x/y.star
```

looks like a file-based name: one might be tempted to believe that the file `x.Star` resides in the directory `/foo/bar/x`. While it is possible that it might, there is actually no such commitment. Furthermore, the same resource may be someplace else (and _will be_ if the identified file is in a code repository).

####Transducer[transducer]

The connection between a URI and the actual resource must be established by a _transducer_. A transducer is any system that can take a URI and produce a copy of identified resource. If you will, the transducer establishes the link between a URI and a URL.

The **Star** compiler has a range of transducers built-in to it; and also has a extensibility mechanism so that you can define your own URI scheme and have it mapped to some physical storage mechanism.

####Standard URI Schemes[standard-uri-schemes]

Although the **Star** compiler can, in principle, utilize any URI scheme, some schemes are 'built-in' — in the sense that there is a standard transducer for them. It is obviously an implementation dependent aspect of the language: different compilers may support different schemes; but all should support at least the following:

**Star**
: E.g. `Star://foo/bar/gar.star`. This is intended to be used as a system dependent but universal way of identifying **Star** files. I.e., each system is free to choose how to find resources using the **Star** scheme in its own way. It is also  expected that methods would be provided for importing and exporting resources between the system and other systems (e.g., mobile vs desktop computers).

**http**
: E.g., `http://www.example.com/foo/bar.star`. This is intended to denote resources that are accessible in some way from the web.

**std**
: E.g., `std:arithmetic.star`. This is intended to represent internally important resources — typically **Star** packages that are part of the standard language definition

In addition, the compiler may support the **file** scheme and other schemes as appropriate.

####Package URIs[package-uris]

We stated earlier that an `import` statement looks like:

```
import myPackage
```

where `myPackage` was an identifier that named the required package to import. Such simple identifiers hardly qualify as URIs of course. In fact, the full form of an import is:

`import` "_scheme_:/_host_/_path_?_version_"

where _scheme_ is one of the supported URI schemes, _path_ is the name of the resource and _version_ is an optional _version specification_.

It turns out that, most of the time, specifying imported packages with explicit URIs in this way is awkward; and subject to errors when refactoring a code base.[^fn2]

[^fn2]:The linguistically precise version of the `import` statement would be even worse; since strings are not actually the same thing as URIs. The accurate version should have been something like:

	```
	import "http:/foo.com/bar/x/y.star" as uri
	```

However, while correct, this is unnecessarily clumsy. Instead, we allow identifiers to name package URIs (as we have been throughout this book) and use our third mechanism to bridge the gap: the _catalog_.

###Catalogs[catalogs]

A _catalog_ is a mapping from identifiers to package URIs; i.e., it is the missing link between package identifiers and package URIs. Catalogs are sometimes written explicitly — in the form of a file that you can place in the same directory as your source files — but usually the compiler makes an automatic catalog depending on where the source code of a package is actually located.

A `catalog` is a **Star** term that looks like:

```
catalog{
  version = "2.3.1";
  baseURI = "http://path";
  content = dictionary of [
    "myPackage" -> "file:/example.com/foo/bar/myPackage"
    "yourLib" -> "http://example.com/foo/lib/youLib?version=3.4"
  ]
}
```

The catalog term is placed in a file — also called `catalog` — that is in the same directory as the source files of the packages that this catalog supports. (I.e., one catalog file supports a whole directory worth of source files.)

Most of the contents of the catalog are optional. The `version` information defines the version that will be appended to any programs that are compiled using this catalog. Similarly, the `baseURI` is used to override the default URI; allowing the compiler to attach special URIs to compiled code — no matter where the source code itself lives.

The `content` field defines a set of mappings from identifiers to URIs. The target URI is denoted as a string that follows the standard RFC2396 syntax for naming URIs.

If a target URI identifies a `version`, then exactly that version will be searched for in the code repository. This is the feature that allows large applications to reference multiple versions of a package.

If a target does not reference a specific version then the repository will be searched for the latest version of the requested package and that version will be used at run-time.

In either case, the compiler will determine the exact version of a package to import — not the run-time.

For most projects you will not need to be very aware of code repositories, catalogs and so on. However, the code product architecture is an important part of **Star**'s strategy for helping you building all scales of system.

##Existentialism[existentialism]

If we take a slightly deeper look at the `package` we will see some surprising features; features that are sadly not very common in programming languages.

Lets start with a super simple source `package`:

```
ss is package{
  fun double(X) is X*2
}
```

This package structure is semantically equivalent to:

```
def ss is let{
  fun double(X) is X*2
} in {double=double}
```

Since there is a variable being defined here — the package variable `ss` — we might ask what is its type:

```
ss:{ double:(integer)=>integer }
def ss is let{
  fun double(X) is X*2
} in {double=double}
```

In effect, a package reduces to a variable declaration whose type is a record type and whose value is an anonymous record of all the functions defined in the package.

What about types though? **Star** allows us to export types from packages too:

```
simple is package{
  type foo of t is foo(t) or bar

  fooMe(X) is foo(X)
}
```

Exporting types — and their constructors — is an extremely important part of the package functionality. However, it turns out that we can account for types too in our semantics of packages. Similarly to our previous unfolding, the `simple` package is equivalent to:

```
simple:{
  foo has kind type of type
  foo:for all t ~~
    (t)<=>foo of t
  bar:for all t ~~
    ()<=>foo of t
  fooMe:for all t ~~ (t)=>foo of t
}
def simple is let{
  type foo of t is foo(t) or bar
  fooMe(X) is foo(X)
} in { type foo=foo; foo=foo; bar=bar; fooMe=fooMe}
```

This is clearly quite a bit more complex than our super-simple example; but the basic story is still there: a package consists of a variable definition whose value is an anonymous record. In this case, the anonymous record contains a type, two constructors as well as a regular function.

Having constructors in a type is only a small extension to the conventional notion of a record — while many languages restrict records to containing just data values, most functional programming languages do allow functions in records. A constructor is just a special kind of function.

On the other hand, having a type in a record is quite different.

####Type Variables and their Kind[type-variables-and-their-kind]
We also have a new form of statement about types in this type signature: a `kind` annotation.

In general, types have a _kind_ associated with them; kinds serve the same role for types as types do for expressions and values. In particular, when a type variable is used in a type expression, its kind must be consistent with its use. A significant difference between kind expressions and type expressions is that there are very few different forms of kind:

```
type t has kind type
type u has kind type of type
type v has kind type of (type,type,...,type)
```

The statement about the `foo` type asserts that it is a regular generic type:

```
foo has kind type of type
```

The `kind` annotation is a way of declaring that the `foo` type exists, without being specific about what the type actually is.

###Existential Types[existential-types]
What does it mean to have a type in a record? From a programmer's point of view it is actually quite a natural extension of the concept of a record; there does not seem to be any intrinsic reason why a record shouldn't have types in it. However, the logic of this bears a deeper look.

The type expression in our record type:

```
simple:{
  foo has kind type of type
  ...
}
```

is itself a kind of macro form. The true meaning of the declaration of the `foo` type involves the use of an _existential_ quantifier:

```
simple:exists f ~~ {
  type foo=f
  ...
} where f has kind type of type
```
Notice how the `kind` annotation is still there, it is simply attached to a type variable, specifically an existentially quantified type.

The meaning of an existentially quantified type is complementary to the universally quantified type. An existential type quantification is an assertion that the type exists — with possible constraints as in this case.

####Use and Evidence[use-and-evidence]
To get a better grip on type quantification in general and existentially quantified types in particular it can be helpful to see what the rules and expectations are for a quantified type. Occurrences of a type variable can be classified into two forms — depending on whether the context is one of _using_ a variable or whether one is defining it — or providing _evidence_ for it.

Consider the simple function `d` with its type declaration:

```
d:for all t ~~
  (t)=>t where arithmetic over t
fun d(X) is X+X
```

In the equation that defines `d` we have not explicit referenced `t`; but the rules of type inference lead us to determine that — within the equation — type of `X` is `t`.

If we had forgotten the `arithmetic` constraint:

```
d:for all t ~~ (t)=>t
fun d(X) is X+X
```

the compiler would have complained with a type error. The reason being that, because `t` is universally quantified, we are not permitted to further constrain `t` _within_ the body of the function. Requiring that `t` support addition is such a constraint and we are not permitted to assume it.

On the other hand, when we _call_ `d`, the rules are more generous: calls of the forms `d(2)` and `d(2.4)` are both permitted because we are allowed to _use_ any type — that implements the `arithmetic` contract — when we call `d`.

>The reason we can substitute any type for `t` is a result of the universal quantifier: a `for all` quantifier means we can use any type for `t`.

For existentially quantified types the situation is reversed: within an expression involving an existential type we can use what ever type we want — again, providing that other constraints have been met — but _outside_ the defining expression we can't make any assumptions or additional constraints about the quantified type.

For various reasons, which we will explore further, existentially quantified types are mostly associated with records — like the package record we saw earlier. Let us look again at our simple package type:

```
simple:exists f ~~ {
  type foo=f
  ...
  fooMe:for all t ~~ (t)=>foo of t
} where f has kind type of type
```

As with universally quantified types, there are two kinds of contexts in which we use existentially quantified type variables: _use_ and _evidence_ contexts. In the former we are using the type and in the latter we are providing evidence that an expression has the right type.

The existential quantifier means is that within an instance of this record we can instantiate `foo` to any type that meets the constraints. The simplest way is to provide a type definition for `foo`:

```
def simple is let{
  type foo of t is foo(t) or bar
  fun fooMe(X) is foo(X)
} in { type foo=foo; foo=foo; bar=bar; fooMe=fooMe}
```

Externally, when we use the record, the opposite happens: we can make use of the existence of `foo` but we cannot further constrain it. We can use `simple`'s `foo` type, as well as the `fooMe` function that relies on it; for example, in:

```
m:for all t ~~
  (t)=>simple.foo of t
fun m(X) is simple.fooMe(X)
```

There is something a little different going on here: the type of `m` appears to be dependent on a field of the variable `simple`; i.e., the type of `m` apparently depends on the value of `simple`. This is not something that we would normally sanction in a type system because of the potential for disaster.

For example, consider the scenario where '`simple` is not simple'; i.e., suppose that its value were computed; for example suppose that the value of `simple` depended on a conditional computation. In that case the actual type `simple.foo` might also depend on the conditional computation; why does this not cause problems?

Normally such dynamic types do cause substantial problems. The presence of a dynamic type is one of the hallmarks of dynamically typed languages and it makes most type inference impossible at compile time.

However, the type rules for existentially quantified variables are crafted so that _it must not matter_ what the actual type `simple.foo` is. So long as no additional constraints on the `simple.foo` are permitted then the program is provably compile-time type-safe. I.e., uses of an existentially quantified type may not further constrain the type — the exact complement of the situation with universally quantified types.

####Using Existentially Quantified Types[using-existentially-quantified-types]

So, what _are_ the rules for existentially quantified types?

The first is one that we have already been looking at:

>An existential variable may be bound to a type when providing _evidence_ that a value has a certain type, but may not be constrained when _using_ a value with an existential quantifier in its type.

The second is related to this:

>_Each occurrence of an existentially quantified type is potentially different_.

Think about a function with the type:

```
exFn:for all t ~~
  (t)=>exists e ~~ R of (e,t)
```

For the moment, we don't much care about `R`. Now, consider how we might use `exFn`:

```
def X1 is exFn("alpha")
...
def X2 is exFn("alpha")
```

An important question is "what is the relationship between the type of `X1` and the type of `X2`?". Unfortunately, the fundamental answer is 'we cannot know in general'; which in type terms means effectively there is no relationship: they are different. The reason is that the internal type used within the implementation of `exFn` may result in _different_ instantiations for `e` for each invocation. The result is we cannot assume any link between the types of `X1` and `X2`: they are different.

On the other hand, consider the similar sequence of definitions:

```
def Y1 is exFn("alpha")
...
def Y2 is Y1
```

In this case we do know that the type of `Y1` is identical to the type of `Y2`. This leads us to the third rule:

>Each _use_ of an existential quantification introduces a new type — called a _Skolem type_[^Technically, the type is denoted by a _Skolem Constant_ or a _Skolem Function_.] — that follows the normal inference rules for all types.

I.e., once a type has been introduced as a Skolem type, it behaves just like any regular type and the normal rules of inference apply. This applies equally to the two fragments of code above; but the additional constraint on the immutable values of `Y1` and `Y2` make it easier to propagate type information.

We can see this a little clearly by looking at the effective type annotations of `Y1` and `Y2`:

```
Y1:R of (e345,string)
def Y1 is exFn("alpha")
...
Y2:R of (e345,string)
def Y2 is Y1
```

where `e345` is the skolemized variant of the existential type `e`.

The effective annotations for `X1` and `X2` will have different skolem constants:

```
X1:R of (e235,string)
def X1 is exFn("alpha")
...
X2:R of (e678,string)
def X2 is exFn("alpha")
```

>If `Y1` or `Y2` were declared to be re-assignable variables then, once again, we would not be able to connect the types of `Y1` and `Y2` together.

##Abstract Data Types[abstract-data-types]

Abstract data types can be viewed as the mathematics behind object oriented programming.[^Not to be confused with _Algebraic Data Types_ — which represent the mathematical foundation for enumerations and other non-object values.]

**Abstract Data Type**
: An _abstract data type_ is a mathematical model of a set of related values that share a common set of semantics.

In programming, it is the _common_ semantics that defines the structure; but, of course, programming languages are not able to capture the full semantics of a program or type and hence the stand-in for this is usually a type specification.

Perhaps an example is overdue. In our chapter on [Collections][collections] we looked at many operators over collections and not a few example collection types. Although programs using the `sequence` contract are fairly abstract, the type of the collection itself is still visible. Suppose we wanted to build a set structure where only the fact that there is a set, and the set-like operators over the set were visible. The representation type for the set should otherwise be completely opaque.

One might start with a type definition:

```
type genSet is genSet{
  coll has kind type of type
  z:for all t ~~ coll of t
  addElement:for all t ~~
    (t,coll of t)=>coll of t
  present:for all t ~~
    (t,coll of t)=>boolean
}
```

The essence of this type declaration is a collection of operators that define set-style operators. By protecting the `coll` type with an existential quantifier, we ensure that the representation of `genSet` values is not accessible externally; whilst at the same time we do allow other programs to _use_ the set operators.

One example implementation of `genSet` might use `list`s to represent the set structure itself:

```
def LS is genSet{
  type list counts as coll
  def z is list of []
  fun addElement(X,L) where X in L is L
   |  addElement(X,L) is list of [X,..L]
  fun present(X,L) is X in L
}
```

The statement:

```
type list counts as coll
```

is one of the ways that we can give evidence for the existence (sic) of the `coll` type. Type inference — of the evidence gathering kind — will link `coll` internally to `list`. The `counts as` statement can be viewed as a more fluent way of writing:

```
type coll = list
```

Given `LS`, we can use it like a set generator — `LS` provides a set of operators over sets:

```
def Z is LS.z
def One is LS.addElement(1,Z)
def Two is LS,addElement(2,One)
```

The type of `LS` gives no clue as to the internal type used to represent sets generated by it:

```
LS:genSet
```

But `Z`, `One` and `Two` have more interesting types:

```
Z:collK341 of integer
```

where `collK341` is a Skolem type — a unique type generated when we assign a type to `LS`. In effect, `LS` is a module that exports the set type and associated operators; this module is referenced by name and is used to construct particular sets.

A reasonable question here is 'where is the Abstract Data Type?'. What we have is a record with a type and some functions in it. Recall that an ADT is a 'model of a set of related values that share a common set of semantics'. The semantics in common are the functions in the record; and the type itself is the existentially quantified type in that record — `coll`.

Notice how we index off the `LS` variable to access the operators for this set; even while passing into it instances of sets created and modified by `LS`. This is one of the hallmarks of a module system.

###Opening Up[opening-up]

One of the reasons that we are so interested in establishing a 'normal' semantics for modules and ADTs is that we can develop systems where the contents of a module depends on some additional computation; i.e., we can use _functions over modules_. For example, we can show that _aspect oriented programming_ and _dependency injection_ can be realized just using normal code structuring with functions and `let` environments.

Techniques like dependency injection are typically applied to large programs; unfortunately that makes constructing small examples a little forced. So, we'll use a crow-bar to open a soda bottle. Imagine, if you will, that we needed to define a new arithmetic type that supported arbitrary fractions.

>Floating point numbers are fractions. But they do not permit the representation of all fractions — e.g., it is not possible to represent 1/3 exactly in IEEE 754.

However, while we want to expose the type, and a set of operator functions, we definitely do not want to expose anything about the implementation of fractional numbers: as far as users are to be concerned, the type `fraction` is to be completely opaque and might be implemented in any way.

Let us start with an interface; which in this case will take the form of a record type:

```
type fractionals is fracts{
  fraction has kind type
  frPlus:(fraction,fraction)=>fraction
  frToString:(fraction)=>string
  frParse:(string)=>fraction
  fraction:(integer,integer)=>fraction
}
```

One of the first things to note here is that `fraction` is existentially quantified; secondly we need to ensure that the set of operators we expose is complete. Our interface is not really complete, but includes two critical operators: a means of constructing `fraction`s and a means of escaping from the world of `fraction`s to other types (in this case `string`).

Here we are mostly concerned with _using_ `fraction`s, so we will assume that we have at least one implementation — courtesy of the `FR` variable:

```
FR:fractionals
```

One way to use our implementation of fractions would be to reference the needed operators via the `FR` variable:

```
def F0 is FR.frParse("3/4")
def F1 is FR.fraction(1,2)
def F2 is FR.frPlus(F0,F1)
show FR.frToString(F2)   -- results in 5/4
```

However, we can do rather better than this in **Star**. We have already encountered the `import` statement; there is an analogous statement that allows us to unwrap a record like `FR` in a binding environment — such as a `let`:

```
let{
  open FR
  def F0 is frParse("3/4")
  def F1 is fraction(1,2)
  def F2 is frPlus(F0,F1)
} do
  show frToString(F2)   -- results in 5/4
```

The `open` statement has a similar effect to the package import: it enables the functions, types and other elements that are embedded in a record to be made available as normal identifiers within the normal scope of the `let` action (or expression).

Of course, this code is still fairly clumsy; since we would like to use normal arithmetic notation over `fraction`s; which we can do by implementing the `arithmetic` contract:

```
let{
  open FR
  implementation arithmetic over fraction is {
    X+Y is frPlus(X,Y)
   ... -- more operators needed
  }
} do {
   def F0 is frParse("3/4")
   def F1 is fraction(1,2)
   def F2 is F0+F1
   show frString(F2)
}
```

We can improve this further by also implementing the `coercion` contract between `string`s and `fraction`s:

```
let{
  open FR
  implementation arithmetic over fraction is {
    X+Y is frPlus(X,Y)
   ... -- more operators needed
  }
  implementation coercion over (string,fraction) is {
    coerce(S) is frParse(S)
  }
  implementation coercion over (fraction,string) is {
    coerce(F) is frToString(F)
  }
}
```

This allows us to use a more natural notation for expressions involving our `fraction`s:

```
let{
  open FR
  ...
} do {
   def F0 is "3/4" as fraction
   def F1 is fraction(1,2)
   show F0+F1
}
```

While much better than our original, we still have too much code to write to use the `fraction` type: we have to get the type and then demonstrate the appropriate implementations. We want to be able to combine everything that is important about `fraction`s into a single structure.

There is a straightforward way we can do this. Our original signature for `fractionals` simply required the presence of the `fraction` type. What we can do is further require that the `arithmetic` and appropriate `coercion` contracts are also implemented; we do this by constraining the type definition for `fractionals`:

```
 type fractionals is fracts{
  fraction has kind type where arithmetic over fraction
       and coercion over (string,fraction)
       and coercion over (fraction,string)
  frPlus:(fraction,fraction)=>fraction
  fraction:(integer,integer)=>fraction
}
```

>Since we are using contracts we do not need the explicit `frParse` and `frToString` functions in the signature any more.

When we instantiate a `fracts` record we must provide — within the record itself — appropriate implementations of `arithmetic` and `coercion`:

```
def FX is fracts{
  type myFraction counts as fraction
  implementation arithmetic over myFraction is {
    fun X+Y is frPlus(X,Y)
   ... — more operators needed
  }
  implementation coercion over (string,myFraction) is {
    fun coerce(S) is frParse(S);
  }
  implementation coercion over (myFraction,string) is {
    fun coerce(F) is frToString(F)
  }
  ...
}
```

Notice that we implemented `arithmetic` for the internal `myFraction` type. We could have equally implemented the contract for `fraction` type too; the key requirement is to provide evidence that `arithmetic` is implemented for the type.

The `FX` record now has everything we want to expose about `fraction`al numbers.[^Assuming that we added the missing operators that we would actually need.] If we `open` the structure then indeed we can write programs like:

```
let{
  open FX
} do {
   def F0 is "3/4" as fraction
   def F1 is fraction(1,2)
   show F0+F1
}
```

This is virtually equivalent to the code we might have written if we were importing a package with the definition of the `fraction` type in it. The difference is that we have access to the full expressive power of the language in computing `FX`.

###Injection[injection]

Injection is a technique where we specialize a program with additional information; especially where that additional information is not part of the normal argument flow. Of course, it can be hard to be crisp about 'not part of the normal argument flow'; but injection is an architectural technique to apply if and when it makes a difference in the readability of your code.

Injection is often used to manage _configuration_ of code: the configuration is injected into the main program; for example, we might configure an application server with the path name of a particular application, or with the port on which the app server should be listening. Neither of these would normally be considered part of the normal information flow in an application server.

There is a standard functional programming style that can be used to represent injection — namely functions that return functions. To take an extremely simple example, suppose that we wanted to have a function that counted the percentage of a class that passes an exam. The function itself is pretty simple:

```
fun passes(L) is fraction(
   size(list of { all X where X in L and X.score>Pass}),
   size(L))
```

The configuration parameter here is obviously the `Pass` value; this is an important parameter to the function but is not part of the normal argument flow (think about computing the pass count for an entire school).

We can use the function returning approach to inject an appropriate value of `Pass`:

```
fun passes(Pass) is
  (L)=>fraction(
     size(list of { all X where X in L and X.score>Pass}),
     size(L))
```

Using this `passes` is a two-step process; we first use a specific passing grade to construct the test function and then use this to measure performance on groups of students:

```
def HS is passes(60)

def allPass is list of { all C where C in Courses and HS(C)>0.80 }
```

>The two-step process is a key part of the injection technique.

###Extensible Types[extensible-types]

Sometimes, rather than configuring a program with a numeric value (or any other value for that matter), we need to configure it with a _type_. This does not happen that often, and **Star**'s type constraints can eliminate many cases where it might be needed; but the requirement still shows up occasionally. Where it can show up is in situations where you need to develop customizable applications — applications that can be extended further by your customers without you having to change a line of your own code.

For example, you might need to build a system that attempts to predict the behavior of equipment based on historical performance and current demand. This kind of software could be very useful in determining a proper maintenance schedule. Suppose that you determine that what is important in predicting potential breakdowns is the number of units processed and the number of days since the last scheduled maintenance. You might keep track of this in a record:

```
maint ::= maint{
  date:date.
  units:integer.
}
```

And you will also probably have a description of each piece of equipment:

```
equip ::= equip{
  id:string.
  eqpType:string.
  nextMaint:date.
}
```

Using this, and similar records, together with some clever algorithms, you design a function that determines the next most likely piece of equipment to fail — perhaps together with an expected failure date:

```
nextToFail:(list[maint],list[equip])=>(equip,date)
...
```

>The details of this algorithm, while critical to an actual application, are of no concern to us here.

Now, you deliver your software to your customer and the first thing that they ask for is an ability to tweak it. You see, you designed it for generic pieces of equipment and they have particular pieces of equipment, with particular foibles affecting the computations needed to determine when equipment needs maintenance. And they need to keep some information in the description of equipment and maybe also in the maintenance records that is not in your types.

>Your challenge is to permit this kind of extension without requiring your code to be modified or even recompiled for each customer.

The standard OO approach to addressing would be to permit the customer to _sub-class_ some of the critical types (such as `maint` and `equip`). However, there are problems with using sub-types: in particular, if your algorithm requires computing _new_ instances of data structures then sub-classing cannot work: when your algorithm creates a new `equip` record, it will not know how to create a customer variant of that record:

```
fun updateEquip(E,W) is equip{
  id = E.id
  eqpType = E.eqpType
  nextMaint = W
}
```

with the result that the customer data is lost. An alternative approach is to allow some extensibility in the record by having a special `extra` field:

```
type equip of t is equip{
  id:string
  eqpType:string
  nextMaint:date
  extra:t
}
```

Since we do not want to constrain the kind of information our customizer can store we make its type quantified. The `extra` field is there to support extensions; and, because we know about its existence, we can carry the data with us:

```
fun updateEquip(E,W) is equip{
  id = E.id
  eqpType = E.eqpType
  nextMaint = W
  extra = E.extra
}
```

The problem with adding such an `extra` field is its type: this version changes the unquantified `equip` type into a quantified one. This will have potentially devastating impact on your code — especially if you want to allow multiple extensions for multiple data structures. The reason is that potentially a large number of functions will be required to carry the type parameters in their type signatures. This is doubly galling as these extra type parameters do not have any significance in the main code: they are there only to support potential customizations.

Instead of universal quantification, we can use an existential type for the `extra` field:

```
type equip is equip{
  id:string
  eqpType:string
  nextMaint:date
  t has kind type
  extra:t
}
```

This has the effect of permitting a local extension to a record type while also effectively hiding the type from the main code.

Of course, in order for `extra` to have any effect on our code, we have to be able to make use of it within our algorithm. This is another customization point in the code: not only do we need to allow additional data but we need to be able to reference it appropriately. For example, we might decide that the `extra` field should have a say in determining the next maintenance date; so our `updateEquip` function should take it into account — but how?

A simple way is to add to the `equip` record a set of extensibility functions that the customer must supply, in addition to the data itself:

```
type equip is equip{
  id:string
  eqpType:string
  nextMaint:date
  t has kind type
  extra:t
  extraDate:(t,date)=>date
}
```

Then, our `updateEquip` function calls this `extraDate` function when computing the new maintenance schedule:

```
fun updateEquip(E,W) is equip{
  id = E.id
  eqpType = E.eqpType
  nextMaint = E.extraDate(E.extra,W)
  type t = E.t     — note evidence for type
  extra = E.extra
  extraDate = E.extraDate
}
```

A more succinct way of expressing this would be to use **Star**'s `substitute` operator:

```
fun updateEquip(E,W) is E substitute {
  nextMaint = E.extraDate(E.extra,W)
}
```

Of course, the customer has to provide functions that create the initial data structures, and the initial values of `extra` and the updating function `extraDate`. You, as the provider of the software, will offer a default implementation:

```
fun equip(Id,Tp,Maint) is equip{
  id = Id
  eqpType = Tp
  nextMaint = Maint
  type t = ()  — () is Star's void type
  extra = ()
  extraDate = (_,W) => W
}
```

This approach meets our goals: we can allow customers of our software access to key data structures in a safe way that does not require use to modify our code for each customer or even to recompile it.

##Phew

This Chapter covers some difficult material! We start with a requirement to scale — to be able to scale code from a single module through to applications built by assembling libraries. Along the way we take in existential quantification and abstract data types.

What we have not yet addressed are the needs of distributed applications. Managing distributed applications is one of the most tedious and difficult challenges of modern software development. However, before we can demonstrate **Star**'s approach to this, we must look at _agent oriented systems_ and **actors** — the subject of [Chattering Agents][chattering-agents].
