# Chattering Agents[chattering-agents]

Software agents represent one of those concepts that are very compelling -- perhaps precisely because it speaks to natural human intuitions. Agents are also a popular model for distributed systems. Distributed systems are often characterized by multiple loci of control -- typically one per machine in the system -- and assigning an agent to each locus is a very natural architecture.

In this chapter we look at how we can build agent-based systems and hence distributed systems.

>You will notice that the style of this chapter is a little different from previous chapters. This is because many of the concepts we discuss relatively high-level and are not commonly directly grounded in conventional programming paradigms. However, building distributed systems _is_ a programming task; even if many of the issues and concepts don't have much in the way of touch points in language features.

On the other hand, **Star** does have some important features that simplify building this style of application: notably the _actor_, _speech actions_ and support for _component architectures_.

## A Taxonomy of Agents[a-taxonomy-of-agents]

There is a natural hierarchy of types of agent -- which roughly aligns with their roles and capabilities in distributed applications:

**Agent**
: An _agent_ is an entity that can act; often on behalf of another entity. By extension, a software agent is one that acts primarily in the software domain.

The difference between an agent and a function is that the latter must be invoked before any actions in it's body can be performed; whereas an agent is 'already' ready to act.

There is a vast potential range in capabilities of agents; for example, at a lower limit, one can argue that a thermostat can be viewed as a very simple agent -- because it represents a localized responsibility for controlling the temperature in a room. Another common, though considerably more complex example, is the web browser: from the perspective of most web servers, browsers are agents that acts in the network for and on behalf of consumers.

>There is even a fair amount of autonomy in browsers: modern browsers have features that attempt to keep their owners safe from phishing attacks and also are able to warn users that certain websites are dangerous to visit.

We have already encountered a **Star** feature that can be interpreted as being agent-like -- the `task`. In fact, tasks have quite a few characteristics of autonomy: they can be performed in the background, they can collaborate via rendezvous and they can be used to implement systems involving multiple loci of activity.

However, a more accurate assessment would be that `task`s and the rendezvous are good candidate technologies to _realize_ an agent; just as bits of wire and bimetal can be bent together to make a thermostat. Moreover, **Star**'s concurrency concepts are more suited to constructing concurrent algorithms than whole distributed systems. This is because the primary issues that drive the complexity of distributed systems are different to those of concurrent algorithms: in particular, the necessity of handling communication between different computers.

Given the basic concept of agent, one might ask what are the characteristic attributes of an agent. Clearly, the most basic attribute is a capacity for action (this is built in to the definition of agenthood). A corollary of this is some kind of sensing capability -- to determine what action to take (or not).

Once one can sense and act, the next required capability is the capacity to decide to act. This leads us to a hierarchy of introspective capabilities which we call _cognition_:

**Cognitive Agent**
: A software agent that has an explicit representation of its own activities and capabilities.

Typically, this model takes the form of internal data structures that contain representations of some of the data the agent has (beliefs), some of the activities the agent is engaged in (actions) and some of the objectives the agent is pursuing (goals). Cognitive agents may also have explicit structures that describe the capabilities of the agent (plans).

Note that mechanical thermostats cannot be considered to be cognitive: there is no representation within a typical thermostat of its switching capabilities: it simply flips when the temperature moves; it cannot know that that is what it is doing -- much less know about about the heating system it controls. On the other hand, some modern advanced computer-controlled thermostats certainly do understand that they are controlling heating and cooling systems.

Cognitive agent architectures are useful in situations where the activities of the agent are likely to be dynamic; perhaps responding to multiple stimuli, perhaps being able to perform a range of different capabilities.

![Cognitive Agent][cogAgent]

[cogAgent]:images/headnbody.png width=300px

A cognitive system can be interacted with at a higher level too. One can ask such a system if it is busy, for example.

One systematic way of endowing a software system with such a model is to model the beliefs, goals and ongoing actions as logical structures, perhaps as RDF graphs:

```
...
beliefs:graph[fact]
goals:graph[goal]
actions:graph[action]
capabilities:graph[plan]
...
```

Together, of course, with the semantics that links changes in the real world with changes in these variables and with rules that allow beliefs, goals and actions to be properly integrated.

>We should also emphasize that many software systems already do have some limited cognitive capabilities. For example, a system with a 'plug-in' architecture can be said to have some awareness of its capabilities; similarly, in multi-threaded systems, _task queues_ represent a simple form of self-awareness of current activities.

  However, having a _systematic_ representation of beliefs, desires, intentions and capabilities should simplify and accelerate the development of heterogenous agent-based applications.

While the difference between a 'dumb agent' and a cognitive agent may be one of degree, self-awareness is viewed as _the_ major distinguishing feature of cognitive agents. Self-awareness is especially useful in situations where agents have to deal with complex overlapping scenarios; such as, for example, with human-computer interaction; or when trying to make sense of noisy physical data with multiple potential interpretations.

A self aware agent can even refuse to perform some activity -- one of the more popular definitions of software agents is that they are _autonomous_ systems. This can arise when a cognitive agent can _measure_ the utility value for performing tasks: the basis for refusing to do something would be if the utility is below some
threshold.

>Even for agent systems that do have explicit representations of themselves there is always a large and deep 'sub-conscious' part of the agent -- i.e., that part of the agent that is not modeled within the agent. It is simply not possible for an agent to know everything about itself -- a situation familiar to most human agents.

**Collaborative Agent**
: A collaborative agent is one which participates in a network of agents; and is able to achieve goals by involving other agents in the network. A particularly interesting case of collaboration is where one agent _recruits_ one or more agents to help it achieve it's goals.

Collaborative agents abound in distributed systems; for example, the triumvirate of the browser, the web server and the database server can be viewed as three collaborating agents.

Collaboration is independent of cognition. It is perfectly feasible to design networks of agents that have limited or no self-awareness. Conversely, cognitive agents are not _required_ to participate in a network; although much of the motivation for self-awareness disappears if the agent has no-one to talk to.

The obvious hallmark of collaborative agents is _communication_: you cannot recruit others to do your bidding if you can't talk to them. There are many styles of communication possible between software entities; the one that we suggest for use in **Star** agents is based on _speech actions_.

## Speech Actions[speech-actions]

As the term suggests, speech actions are a communications model based on an anthropomorphic understanding of how agents communicate. Speech actions were first investigated by John Austin[][#austin:60] in the 1940's as a vehicle for understanding the role of speech in human society. Since that time the basic ideas have been progressively formalized by John Searle [][#searle:69] and standardized in KQML [][#kqml:93] and FIPA [][#FIPA].

Beyond the anthropomorphism, there are sound technical justifications basing computer communications on speech act theory.

**Speech Action**
: A speech action is a communication action intended to have an effect on the listener.

For example, the classic:

>I pronounce you man and wife

is a speech action. It has an effect; even though no boulders are moved directly as a result of it, it has a substantial impact on the social fabric and therefore can have unbounded consequences in the physical world.

Informally, a speech action can be considered to be a pair -- a _performative_ verb and a _content_ -- which in some formalizations takes the form of a _declarative proposition_. The performative, a communication verb like _inform_, _command_, _query_, or _declare_, indicates how the content is to be interpreted by a listener. This is highly stylized of course, but it represented a huge advance at the time regarding how communication between intelligent entities (people) should be understood.

Another aspect of speech actions is that context is very important. It matters that the agent speaking has the authority to make the pronouncement, and that it is done in the right way and in the appropriate situation. Imagine a real judge saying ''I pronounce you man and wife'' in a theatrical play.

Under normal circumstances, i.e., in the setting where the judge would typically make such a pronouncement, the result of the utterance is a new married couple. However, in this case it would not _count as_ an official action because of the fact it was a line in a play. The person making the declaration is the right person, and has the authority to perform the action but the context is wrong.

>An interesting implication here is that _within the play_ the characters should respond to the matrimonial as though it were real -- if the play is to be believable!

Speech actions are a great basis for expressing the content of communication between software agents -- they permit systematization of communication at a far higher level than purely syntactic structures (such as XML and JSON). That higher level enables us to build a common platform that addresses some key questions:

*  Is the communication valid, authenticated, and authorized?
*  Is any requested action _congruent_ with our own objectives?
*  Can I reliably route the communication to another agent -- in a way   that properly conveys the intention of the communication?

The latter issue relates to the question of _public semantics_. This is often misunderstood, but can be defined:

**Public Semantics**
: A communication has a public semantics if a third party listening to the communication would understand the communication in the same manner as the sender and receiver of the communication.

Note that public semantics does _not require_ a third party listening in to every communication; it only requires the adherence to shared standards when communicating speech actions.

Since we _are_ talking about communication in the context of software, other considerations are also important; in particular, _type safety_, _crossing machine boundaries_ and _efficiency_.

## Programming Speech[programming-speech]

A critical aspect of human communication is the vocabulary employed -- more formally the _ontology_ being referenced. The natural analog of this in software systems is the Application Programming Interface (API). An API specifies which functions you may invoke, what their types are and what the expected results of invoking the functions should be.

>The major semantic difference between an API and an Ontology is that the latter can often convey more semantics. For example, it is possible, in an ontology but not in a typical API, to express the fact that a function called `plus` adds its numbers together.[^There are definite technical limits to this specificity though.]

As it happens, **Star** has a natural way of expressing a complete API -- by using the _record type_. For example, the record type defined with the type alias:

```
type myAPI is alias of {
  products:list of (string,string)
  quantity:(string)=>integer
}
```

can be viewed as the specification of an API. We are not limited to exposing functions in APIs: we can expose literal values, variables and even types.

Having a type that can represent an entire API also allows us to be careful about distinguishing the API from _access_ to the API. We determine access to an API by computing a value whose type is the API -- for example by having a variable of the right type:

```
A:myAPI
```

Here the API is determined by the `myAPI` type; access to it is mediated via the variable `A`. We access the API by accessing `A`, as in:

```
show list of { all y where
    (y,"1in-washer") in A.products and
    A.quantity(y)>20 }
```

While perfectly serviceable, there are some substantial issues with this approach to accessing APIs. For example, we have this `A` variable showing up everywhere; and it is hard -- at first glance -- to see how this style of API can help us with building distributed systems.

### Queries

We have, in **Star**, a better, more systematic, approach to describing and implementing public APIs -- based on speech actions.[^And contracts of course.] For example, assuming that `Ag` had the appropriate type similar to that of `A` above, we could issue a speech action against `Ag` with a very similar query:

```
query Ag with list of { all y where
    (y,"1in-washer") in products and
    quantity(y)>20 }
```

One of the most obvious differences here being where the target of the API is mentioned: it is only mentioned at the top of the query. The type of `Ag`, assuming nothing else is known about it, takes the form:[^This is a simplification of the actual speech contract form.]

```
Ag:t where speech over t determines myAPI
```

This type annotation highlights two important aspects of speech actions as **Star** program fragments: the entity being queried must implement the `speech` contract and that the API of the queried entity is also baked into its type -- albeit via the `speech` contract. Actual concrete implementations of `speech` tend to show the relationship more directly -- as we shall see below when we look at [actors][actors].

As we already noted, in classical speech action theory a speech action is a combination of a performative and content. **Star** supports three performatives: `notify` which corresponds to a notification that something has happened, `query` which corresponds to a question, and `request` which corresponds to a request to perform an action. We have found that these three performatives are sufficient to cover the vast majority of communication requirements in practical software systems.

The general form of the `query` speech action is an _expression_ of the form:

`query` _Agent_ `with` _Expression_

where _Agent_ is an entity with a constrained type that implements the `speech` contract.

>The `query` is an expression -- how can it be a speech action? The straightforward response is that it is not the expression that is the action, the speech action as a whole consists of the `query` performative and the content of the action is an expression. Syntactically, because the `query` has a value, it makes the most sense for the `query` to be presented to the programmer as an expression.

#### Free Variables in Speech[free-variables-in-speech]

Although the body of a `query` speech action might be any expression, there are some syntactic restrictions on the valid forms of `query` expression. The primary reason for these restrictions is to make it simpler to determine the _scopes_ of identifiers occurring in the query expression. Specifically, we need to be able to determine for any identifier occurring in the queried expression whether or not it refers to the agent being queried or the outer context.

For example, consider the simple `query`:

```
query Ag with quantity("W-S-23")>0
```

In this query the function `quantity` is part of the API of `Ag`; but the function `>` is not -- it is actually a standard function defined as part of the `comparable` contract.

The **Star** compiler has to be able to reliably determine the scope of any identifier, including identifiers in embedded query speech actions. We address this in one of two ways: the speech action processor is able to 'understand' sufficient of the standard query notation that it can determine which of the identifiers in the query should be part of the remote agent's API and which should be local. I.e., we can use `query` speech actions like:

```
query Ag with list of { all X where ("W-S-23",X) in products }
```

and the compiler will assume that `products` refers to something that belongs to `Ag`.

The second way in which we can inform the compiler which identifiers belong to the agent is explicitly. For example, we can write:

```
query Ag's quantity with quantity("W-S-23")>0
```

>This is definitely more clumsy than one would like. Sometimes it is not possible to satisfy all requirements in the design of a programming language.

Why, one should ask, cant the compiler simply rely on the type of `Ag`? The answer is two-fold: of course, if `Ag`'s type is known then it will rely on it. However, **Star**'s type system is based on type inference -- it is quite possible that the only signal that `Ag` is a speech action correspondent is the presence of this speech action. In that scenario there is not enough information to also determine the types of all the free variables.

### Notifications[notifications]

A `notify` speech action is intended to communicate the occurrence of an event of some form. In the context of software systems it corresponds to a message being sent on a named channel; however that seems low level in comparison.

The form of a `notify` is a little different to the `query`:

`notify` _Agent_ `with` _Expression_ `on` _Channel_

To notify `Ag` that there is a new stock item might take the
form:

```
notify Ag with
  ("MS-345","3/4in Machine Screw")
  on stock
```

The content here is the tuple term

```
("MS-345","3/4in Machine Screw")
```

and `stock` is the 'channel' of communication. In order for this to be valid we have to assign a new element to `Ag`'s API interface -- one that defines `stock` and the type of event it may respond to:

```
type myAPI is alias of {
  products:list of (string,string)
  quantity:(string)=>integer
  stock:occurrence of (string,string)
}
```

Here we mark the ability to `notify` on the `stock` channel by giving `stock` an `occurrence` type. Later, when we look at how agents can be implemented, we will see how notifications are handled. For now, we note that `occurrence of (string,string)` denotes a program that can consume events whose data consists of values of tuple type `(string,string)`.

#### No Time[no-time]

The `notify` speech action does not explicitly refer to time, including the time of the event itself. This is because there may be multiple senses in which time must be conveyed: the time of the occurrence, the time of its being noticed, or the time of this speech action.

Furthermore, not all applications _need_ time to be explicitly identified. An extreme example of this would be the ticking of a clock. Any listener to a mechanical clock's ticking would confirm that neither tick nor tock is timestamped! However, each tick does announce the passing of another second. Instead, it is assumed that the listener has some other way of determining the time (by looking at the clock face). In general, it is expected that each application will incorporate an appropriate model of time for its `notify` events.

### Requests[requests]

Our final form of speech action is the `request`. A `request` is intended to denote a request that the recipient perform some action. This is subtly different to the `query` in that -- apart from answering the question -- a `query` should not cause any change of state in the recipient, whereas the `request` likely would.

>Even though the difference between `query` and `request` may seem subtle to the average programmer the key difference is in the intended use.

The form of a `request` reflects the fact that an action is involved:

`request` _Agent_ `to` _Action_

A simple request may be to invoke a procedure from the API; however complex scripts are also possible. For example, we can request that all stock items that are empty be deleted:

```
request Ag to delete (Id,_) from stocks where quantity(Id)=0
```

The action

```
delete (Id,_) from stocks where quantity(Id)=0
```

is part of the standard CRUD (Create-Read-Update-Delete) feature that allows collections to be updated.

### A Missing Performative

**Star** does not have a `declare` performative -- currently. It may be instructive to see why not, especially since we introduced speech action theory with a classic declaration. While it is not likely that a software agent will marry couples any time soon, there are legitimate reasons for wanting the ability to make declarations.

A declaration is a speech action whose effect is embedded within the speech action itself. Declarations establish new facts that are shared by the listener and potentially others in the context. Perhaps the best example comes from transaction processing: declaring that a transaction has been committed to is the same as committing to the transaction. Similarly, declaring that a couple is married is the same as marrying them.

The real reason why there is no `declare` relates to it's putative argument -- which must be a proposition. For example, in signing a contract, each party says to the other:

>I agree to be bound by this contract

where contract refers to the normal human interpretation, not **Star**'s contracts. How, we must ask, might we represent this in a way that is amenable to automated processing? To answer this, we must try to unpack what a contract is.

A legal contract has two elements: it is a statement of constraints on potential behaviors of the parties involved and it defines a _value exchange_ (I exchange my money for your house). Very few programming languages, and essentially no 'conventional languages' have any way of representing concepts like value exchange and constraints on behavior.

A more general approach is to use a logical language in which we can encode contracts and the like. At the time of this writing **Star** does not have ready access to a well developed logical language (but see [our treatment of RDF][rdf]). As a result, there is no appropriate partner for the `declare` speech action.

Developing a usable logical language is fairly substantial task; however, once it exists, we have exactly the right speech action for it!

## Actors[actors]

So far we have discussed what talkative agents say to each other but not on how they are built. The simplest structure that responds to this is the `actor`. Actors are lightweight entities that can respond to speech actions. For example, this `actor` models some aspects of a bank:

```
agentBank is actor{
  private var accts := dictionary of []
  fun balance(N) where accts[N] matches Ac is Ac.balance()
  prc transfer(F,T,Amt) do{
    def Fr is accts[F]
    def To is accts[T]
    Fr.debit(Amt)
    To.credit(Amt)
  }
}
```

The public elements of the `actor` determine the kinds of speech actions it can respond to. This `actor` can respond to a `balance` query:

```
query agentBank with balance("fred")
```

and can also respond to a `request` to transfer some money between two of its accounts:

```
request agentBank to transfer("fred","tom",100.0)
```

If we wanted our bank to be able to respond to events, such as check posting events then we need to add an occurrence handler for them. Occurrence handlers take the form of an `on...do` rule, such as:

```
on deposit(Nm,Amnt) on cashier do
  accts[Nm].debit(Amnt)
```

There are three parts to an `on...do` rule: the _pattern_ that denotes the kind of events this rule will respond to, a _channel_ identifier and an _action_ that is performed when a suitable event is received. The complete rule is effectively a program that has type: `occurrence of` _type_; or in the case of this rule:

```
cashier:occurrence of moneyTransaction
```

assuming that `deposit` was a constructor in the type:

```
type moneyTransaction is
  deposit(string,float) or
  withdraw(string,float)
```

Multiple rules for the same channel may be present, and if two or more rules fire for a given occurrence then they all will be executed -- although the relative order of performing the rules is _not_ defined. This multiple rule firing is useful at times; for example it makes it easier to implement over-arching processing as well as specific processing:

```
on Tx on cashier do
  logMsg(info,"Transaction $Tx")
on deposit(Nm,Amnt) on cashier do
  accts[Nm].debit(Amnt)
```

In this case two actions will take place when a `deposit` is received: it will be logged and the appropriate account will be debited.

>If two occurrence rules fire for a given `notify` the order of their firing is not defined: it may be either order. Therefore, you should make sure that occurrence rules that overlap should not overlap in their actions.

Actors have a type of the form `actor of` _recordType_; where _recordType_ is the actor's API. For example, if we include our occurrence processing rules in our `agentBank`; then its type will be:

```
agentBank:actor of {
  balance:(string)=>float
  transfer:(string,string)=>()
  cashier:occurrence of moneyTransaction
}
```

One common technique when programming with actors is to use functions that generate actors. One is likely to need only a single bank actor in a system, but one may well need multiple client actors.

### Performance Characteristics of Actors[performance-characteristics-of-actors]

Actors are comparatively efficient at processing speech actions; and they are trusting: that is, they do not perform any validation on the speech actions. One resulting limitation is that they are definitely not safe in a concurrent environment. Again, no interlocking checks are performed -- which means that if you use a regular actor in background tasks (say) then you will likely get inconsistent results.

Also, actors are somewhat _stateful_ in nature. They are intended to encapsulate the processing of speech actions; and that implies that they normally carry some form of state.

A corollary of `actor`s' execution profile is that they are _re-entrant_: multiple tasks can access the same actor concurrently. This can be advantageous in certain circumstances where the actor is actually stateless and performance is critical.

However, in most concurrent situations the normal `actor`'s execution model is too dangerous. To make speech action processing safer it is necessary to _serialize_ access to the actor -- something that is accomplished with concurrent actors.

### Concurrent Actors[concurrent-actors]

A _concurrent actor_ is similar to a regular light weight actor in that you can communicate with a concurrent actor using speech actions and you can define event rules for the concurrent actor.

However, a concurrent actor has an important performance guarantee: only one speech action may be processed concurrently by the actor. This makes it straightforward to ensure that the internal state of a concurrent actor is always consistent in the presence of concurrent access to the actor.

It should be noted that the internal structure of a concurrent actor is more complex than that of a regular light weight actor. This may translate into a run-time performance difference.

A `concurrent actor` is written using the `concurrent` prefix. For example, we can make our `agentBank` concurrent very straightforwardly:

```
agentBank is concurrent actor{
  private var accts := dictionary of []
  fun balance(N) is accts[N].balance()
  prc transfer(F,T,Amt) do{
    accts[F].debit(Amt)
    accts[T].credit(Amt)
  }
  on deposit(Nm,Amnt) on cashier do
    accts[Nm].debit(Amnt)
}
```

As might be clear if you have read up this point, a `concurrent actor` works by having an internal `background task` that is actually responsible for processing speech actions. This background task is responsible for actually responding to speech actions and it 'serializes' them -- ensuring that only one is performed at any one time.

Performing speech actions on concurrent actors is identical to performing them on regular actors. However, concurrent actors have a different type -- `concActor of` _t_ -- which means that one has to be careful when constructing functions that are to work with both kinds of actor. For example, the `balQuery` function:[^Like other references to the `speech` contract, the types in this function are slightly simplified.]

```
balQuery:for for all t,a ~~
    (t,string)=>float where
      speech over t determines a and
      a implements { balance:(string)=>float }
balQuery(A,U) is query A with balance(U)
```

will work with either of `actor`, `concurrent actor` or any entity that implements `speech` and whose API includes the `balance` function -- because it's type is carefully circumscribed. However, functions that have been type-specialized to work with `actor`s will not type check when used with `concurrent actor`s.

## Summary
