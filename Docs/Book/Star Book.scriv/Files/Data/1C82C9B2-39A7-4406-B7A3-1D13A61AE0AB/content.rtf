{\rtf1\ansi\ansicpg1252\cocoartf1561\cocoasubrtf200
{\fonttbl\f0\froman\fcharset0 Palatino-Roman;}
{\colortbl;\red255\green255\blue255;\red0\green0\blue0;}
{\*\expandedcolortbl;;\cssrgb\c0\c0\c0;}
\pard\tx360\tx720\tx1080\tx1440\tx1800\tx2160\tx2880\tx3600\tx4320\fi360\sl264\slmult1\pardirnatural\partightenfactor0

\f0\fs26 \cf2 \expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Like other values, tasks are first class: they can be assigned to variables, kept in data structures, passed to and from functions and so forth. This flexibility leads to great expressive power \'97 many patterns of computations can be readily encoded as task-valued functions.\
For example, consider the mp function \'97 which is a facsimile of the standard map function specialized for list values:\
mp:all s,t ~~ ((s)=>t,list[s])=>list[t].\
mp(F,[]) => [].\
mp(F,[X,..Y]) => [F(X),..mp(Y)].\
In this mp function,\{\\SCRV_FN=Notice that we do not need to mark the sequence expressions as list sequences \'96 type inference takes care of this for us.\\END_SCRV_FN\} the functional variable F denotes the computation to be applied to each element of the input list. Suppose that each computation of F were non-trivial, and we wanted to spread the load across multiple cores \'97 i.e., to perform the map operations in parallel. The task notation, in particular background tasks will help us to achieve that.\
Recall that map is a standard 
\b Star
\b0  function that is defined in the mappable contract and is implemented for many different collection types.\
We will first of all transform mp to use tasks rather than simply calling the function:\
taskmap:all s,t ~~ ((s)=>t,list[s])=>list[t].\
taskmap(F,[]) => [].\
taskmap(F,[X,..Y]) => [valof task\{ valis F(X) \} ,.. taskmap(F,Y)].\
As it stands, this function has very similar performance characteristics to mp; except that we are using the task expression notation. In order to run the different elements in parallel we need to also use the background operator:\
parmap1:all s,t ~~ ((s)=>t,list[s])=>list[t].\
parmap1(F,[]) => [].\
parmap1(F,[X,..Y]) => [valof background task\{valis F(X)\} ,.. parmap1(F,Y)].\
This program computes each element of the result in a separate background task. However, it is not a true parallel map because we wait for each element before continuing to the next element.\
A better approach is to first of all construct a list of tasks and then to separately collect their values in a second phase:\
parmap2:all s,t ~~ ((s)=>t,list[s])=>list[t].\
parmap2(F,L) => let\{\
  spread:(list[s])=>list[task[t]].\
  spread([]) => [].\
  spread([X,..Y]) => [background task\{ valis F(X)\} ,.. spread(Y)].\
\
  collect:(list[task[t]])=>list[t].\
  collect([]) => [].\
  collect([T,..Ts]) => [valof T,..collect(Ts)].\
\} in collect(spread(L))\
This function does not wait for any task to complete until they have all been spun out into background activities. This gives the maximum opportunity for the independent tasks to complete before we actually need their values.\
A good rule of thumb is:\
when you are programming with tasks, everything that is not a completely task-less subcomputation should be enclosed in task brackets.\
So, a more idiomatic way of writing the parmap function is to make it a task valued function; we also generalize away from the specific list collection type and use the standard map function to allow for any collection type:\
parmap:all s,t,c/1 ~~ mappable[c] |: ((s)=>t,c[s])=>task[c[t]].\
parmap(F,L) => let\{\
  spread:()=>list[task[t]].\
  spread() => map((X)=>background task\{valis F(X)\},L).\
  collect:(list[task[t]])=>list[t].\
  collect(Lt) is map((T)=>valof T,Lt).\
\} in task\{\
  valis collect(spread())\
\}}