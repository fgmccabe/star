{\rtf1\ansi\ansicpg1252\cocoartf1561\cocoasubrtf200
{\fonttbl\f0\froman\fcharset0 Palatino-Roman;\f1\fswiss\fcharset0 Helvetica;\f2\fnil\fcharset0 Menlo-Regular;
}
{\colortbl;\red255\green255\blue255;\red0\green0\blue0;\red0\green0\blue233;}
{\*\expandedcolortbl;;\cssrgb\c0\c0\c0;\cssrgb\c0\c0\c93333;}
\pard\tx360\tx720\tx1080\tx1440\tx1800\tx2160\tx2880\tx3600\tx4320\fi360\sl264\slmult1\pardirnatural\partightenfactor0

\f0\fs26 \cf2 \expnd0\expndtw0\kerning0
We wrap up our exposition on collections with an example that highlights how we can combine many of the collection manipulation features; with a specific goal of statistical processing of data.\
Statistics is, of course, one of the key application areas of computers in general. However, there is often a substantial gap between the theoretical aspects of statistical processing and the pragmatics of collecting and processing data. We aim to demonstrate 
\b \cf2 Star
\b0 \cf2 \'92s power in both areas.\
One fecund source of statistics is the web; we can even get statistics about the web. The on-line tool {\field{\*\fldinst{HYPERLINK "http://www.webpagetest.org/"}}{\fldrslt \cf3 \ul \ulc3 Web Page Test}} can be used to generate a lot of data about how a browser responds to a website. Furthermore, we can down this data as a file of comma separated values (CSV). The first few lines of this file shows the detail of the data collected:\
\pard\tx720\tx1080\tx1440\tx1800\tx2160\li720\pardirnatural\partightenfactor0

\f1\fs24 \cf0 \kerning1\expnd0\expndtw0 <$Scr_Ps::0>
\f2\fs22 Date,...,URL,Response Code,Time to Load (ms),...,Bytes In,...\
9/12/14,...,/,302,397,...1272,...\
\pard\tx360\tx720\tx1080\tx1440\tx1800\tx2160\tx2880\tx3600\tx4320\fi360\sl264\slmult1\pardirnatural\partightenfactor0

\f1\fs24 \cf2 \expnd0\expndtw0\kerning0
<!$Scr_Ps::0>
\f0\fs26 There are over 70 columns there. Suppose that we wanted to process this to find out how much time is spent loading Javascript data. Our first step is to introduce the CSV file to 
\b \cf2 Star
\b0 \cf2  which we can do with a special macro:\
\pard\tx720\tx1080\tx1440\tx1800\tx2160\li720\pardirnatural\partightenfactor0

\f1\fs24 \cf0 \kerning1\expnd0\expndtw0 <$Scr_Ps::0>
\f2\fs22 import metaCSV.\
worksheet\{\
  generateCSV Wpt from "file:WPT_Sample.csv".\
\
  ...\
\}\
\pard\tx360\tx720\tx1080\tx1440\tx1800\tx2160\tx2880\tx3600\tx4320\fi360\sl264\slmult1\pardirnatural\partightenfactor0

\f1\fs24 \cf2 \expnd0\expndtw0\kerning0
<!$Scr_Ps::0>
\f0\fs26 The generateCSV line is a {\field{\*\fldinst{HYPERLINK "scrivlnk://2BB80CC2-1EE6-4A27-B426-3E4F17CB5C64"}}{\fldrslt macro}} that parses the sample CSV file, constructs a type (Wpt) that reflects the entries in the file and a parser that can parse similar CSV files into Wpt entries. The generated Wpt type looks like:\
\pard\tx720\tx1080\tx1440\tx1800\tx2160\li720\pardirnatural\partightenfactor0

\f1\fs24 \cf0 \kerning1\expnd0\expndtw0 <$Scr_Ps::0>
\f2\fs22 Wpt ::= Wpt\{\
    Date:string.\
    ...\
    URL:string.\
    'Response Code':integer.\
    'Time to Load (ms)':integer.\
    ...\
    'Bytes In':integer.\
    ...\
  \};\
\pard\tx360\tx720\tx1080\tx1440\tx1800\tx2160\tx2880\tx3600\tx4320\fi360\sl264\slmult1\pardirnatural\partightenfactor0

\f1\fs24 \cf2 \expnd0\expndtw0\kerning0
<!$Scr_Ps::0>
\f0\fs26 One immediate feature to notice is that some of the field names are quoted. 
\b \cf2 Star
\b0 \cf2  allows a variable (and by extension a field) identifier to have any characters in them \'97 so long as the identifier is quoted. This allows us to access \'91foreign\'92 data structures like this CSV file in a straightforward way.\
Given the implicit generation of the type, and of a parser, we can use this to process real data files. For example, we can extract out from the CSV file records containing just the URLs, the file sizes and the load times using a query:\
\pard\tx720\tx1080\tx1440\tx1800\tx2160\li720\pardirnatural\partightenfactor0

\f1\fs24 \cf0 \kerning1\expnd0\expndtw0 <$Scr_Ps::0>
\f2\fs22 import metaCSV.\
worksheet\{\
  generateCSV Wpt from "file:WPT_Sample.csv".\
\
  wptData:Wpt.\
  wptData = WptParser("http:www.webpagetool.org/...csv").\
\
  extracted:list[\{URL:string. size:integer. loadTime:integer\}].\
  extracted = list of \{ all\
    \{ URL=D.URL\
     size=D.'Bytes In'\
     loadTime=D.'Time to Load (ms)'\} where\
    D in wptData\}\
  ...\
\}\
\pard\tx360\tx720\tx1080\tx1440\tx1800\tx2160\tx2880\tx3600\tx4320\fi360\sl264\slmult1\pardirnatural\partightenfactor0

\f1\fs24 \cf2 \expnd0\expndtw0\kerning0
<!$Scr_Ps::0>
\f0\fs26 We used the generated parser to reach out to the website for the data and to parse the resulting content \'97 in a single high-powered statement.\
A single run of the web page test may involve many separate browser actions \'97 the purpose of the tool is to test the performance of a website, which needs many trials to achieve statistical significance. So a better organization of the data is to categorize the raw data by URL. We can do this using a group by query:\
\pard\tx720\tx1080\tx1440\tx1800\tx2160\li720\pardirnatural\partightenfactor0

\f1\fs24 \cf0 \kerning1\expnd0\expndtw0 <$Scr_Ps::0>
\f2\fs22 import metaCSV.\
worksheet\{\
  generateCSV Wpt from "file:WPT_Sample.csv".\
\
  wptData:Wpt.\
  wptData = WptParser("http:www.webpagetool.org/...csv").\
\
  extracted:list[\{URL:string. size:integer. loadTime:integer\}].\
  extracted = list of \{ all\
    \{ URL=D.URL.\
     size=D.'Bytes In'.\
     loadTime=D.'Time to Load (ms)'\} where\
    D in wptData\} group by ((X)=>X.URL)\
  ...\
\}\
\pard\tx360\tx720\tx1080\tx1440\tx1800\tx2160\tx2880\tx3600\tx4320\fi360\sl264\slmult1\pardirnatural\partightenfactor0

\f1\fs24 \cf2 \expnd0\expndtw0\kerning0
<!$Scr_Ps::0>
\f0\fs26 The 
\f1\fs24 \cf0 \kerning1\expnd0\expndtw0 <$Scr_Cs::1>
\f2\fs22 group by
\f1\fs24 \cf2 \expnd0\expndtw0\kerning0
<!$Scr_Cs::1>
\f0\fs26  operator takes a collection, and a categorization function, are produces a dictionary of collections.\
We want to produce average load times and standard deviations of the load times \'97 to smooth out the vagaries of the Internet. For now, we will assume that we have average and stddev functions that have type signatures:\
\pard\tx720\tx1080\tx1440\tx1800\tx2160\li720\pardirnatural\partightenfactor0

\f1\fs24 \cf0 \kerning1\expnd0\expndtw0 <$Scr_Ps::0>
\f2\fs22 average:all c,e ~~ sequence[c->>e] |:(c,(e=>float))=>float.\
stddev:all c,e ~~ sequence[c->>e] |:(c,(e=>float))=>float.\
\pard\tx360\tx720\tx1080\tx1440\tx1800\tx2160\tx2880\tx3600\tx4320\fi360\sl264\slmult1\pardirnatural\partightenfactor0

\f1\fs24 \cf2 \expnd0\expndtw0\kerning0
<!$Scr_Ps::0>
\f0\fs26 I.e., we are assuming functions that take collections, and an \'91accessor\'92 function, and return the average and standard deviation respectively.\
Given these functions, we can compute our statistics using:\
\pard\tx720\tx1080\tx1440\tx1800\tx2160\li720\pardirnatural\partightenfactor0

\f1\fs24 \cf0 \kerning1\expnd0\expndtw0 <$Scr_Ps::0>
\f2\fs22 import metaCSV.\
import stats.\
worksheet\{\
  generateCSV Wpt from "file:WPT_Sample.csv".\
\
  wptData:Wpt.\
  wptData = WptParser("http:www.webpagetool.org/...csv").\
\
  extracted:list[\{URL:string. size:integer. loadTime:integer\}].\
  extracted = list of \{ all\
    \{ URL=D.URL.\
     size=D.'Bytes In'.\
     loadTime=D.'Time to Load (ms)'\} where\
    D in wptData\} group by ((X)=>X.URL)\
\
  ldTime:(Wpt)=>float.\
  ldTime(D) => D.loadTime::float.\
\
  show list of \{ all (K,average(V,ldTime),stddev(V,ldTime)) where\
        K->V in extracted \}\
\}\
\pard\tx360\tx720\tx1080\tx1440\tx1800\tx2160\tx2880\tx3600\tx4320\fi360\sl264\slmult1\pardirnatural\partightenfactor0

\f1\fs24 \cf2 \expnd0\expndtw0\kerning0
<!$Scr_Ps::0>
\f0\fs26 The query condition:\
\pard\tx720\tx1080\tx1440\tx1800\tx2160\li720\pardirnatural\partightenfactor0

\f1\fs24 \cf0 \kerning1\expnd0\expndtw0 <$Scr_Ps::0>
\f2\fs22 K->V in extracted\
\pard\tx360\tx720\tx1080\tx1440\tx1800\tx2160\tx2880\tx3600\tx4320\fi360\sl264\slmult1\pardirnatural\partightenfactor0

\f1\fs24 \cf2 \expnd0\expndtw0\kerning0
<!$Scr_Ps::0>
\f0\fs26 is analogous to the regular search condition:\
\pard\tx720\tx1080\tx1440\tx1800\tx2160\li720\pardirnatural\partightenfactor0

\f1\fs24 \cf0 \kerning1\expnd0\expndtw0 <$Scr_Ps::0>
\f2\fs22 D in wptData\
\pard\tx360\tx720\tx1080\tx1440\tx1800\tx2160\tx2880\tx3600\tx4320\fi360\sl264\slmult1\pardirnatural\partightenfactor0

\f1\fs24 \cf2 \expnd0\expndtw0\kerning0
<!$Scr_Ps::0>
\f0\fs26 except that it is used to search within a dictionary-based collection. The pattern 
\f1\fs24 \cf0 \kerning1\expnd0\expndtw0 <$Scr_Cs::1>
\f2\fs22 K->V
\f1\fs24 \cf2 \expnd0\expndtw0\kerning0
<!$Scr_Cs::1>
\f0\fs26  matches the successive key/value pairs in the dictionary.\
That is it! The final query should get output along the lines of:\
\pard\tx720\tx1080\tx1440\tx1800\tx2160\li720\pardirnatural\partightenfactor0

\f1\fs24 \cf0 \kerning1\expnd0\expndtw0 <$Scr_Ps::0>
\f2\fs22 ...\
("/o/oauth2/auth?...", 337.0, 0.0),\
("/main-thumb-58380181-100-yqpttun...", 101.18518518519, 24.41468441456),\
("/main-thumb-49759239-100-pcgldxn...",93.48148148148, 19.03285636867),\
...\
\pard\tx360\tx720\tx1080\tx1440\tx1800\tx2160\tx2880\tx3600\tx4320\fi360\sl264\slmult1\pardirnatural\partightenfactor0

\f1\fs24 \cf2 \expnd0\expndtw0\kerning0
<!$Scr_Ps::0>
\f0\fs26 Notice that most of the remaining complexity in this example related to selecting the right parts of the data to pick up and {\field{\*\fldinst{HYPERLINK "scrivcmt://60757320-5CA3-4C8E-93E5-EA0B2D5E315D"}}{\fldrslt process.}}}