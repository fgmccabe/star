@node Collections
@chapter Collections

Modern programming -- whether it is OO programming, functional
programming or just plain C programming -- relies on a rich standard
library. Given that nearly every program needs to be able to manage
collections of @emph{things}, the central pearl of any standard
library is the @emph{collections} library. Recalling our mantra of
hiding recursion; a well designed collections library can make a huge
difference to the programmer's productivity, often by hiding many of
the recursions and iterations required to process collections.

The collections architecture has four main components:
@enumerate
@item
a range of standard collection types -- including array-like lists,
cons lists, first-in first-out queues, and ideal hash trees;
@item
a range of standard functions -- mostly defined in contracts -- that
define the core capabilities of functions over collections;
@item
special notations that make programming with collections in a type
independent way more straightforward; and
@item
the final major component of the collections architecture is
@emph{queries}. There is a simple yet powerful set of features aimed at
simplifying querying collections.
@end enumerate

The query component is sufficiently involved to merit a chapter of its
own.

@node Sequence notation
@section Sequence notation

@noindent
A sequence is an ordered collection; a sequence expression is an
expression involving a complete or partial enumeration of the values
in the collection. Star has a straightforward notation for expressing
sequences of any underlying type; for example, a @code{cons} sequence of
integers from 1 through 5 can be written:
@example
cons of [1, 2, 3, 4, 5]
@end example
In situations where we do not know or do not wish to specify the
collection type, we can write instead:
@example
[1, 2, 3, 4, 5]
@end example
This term -- it could be either an expression or a pattern -- denotes
the sequence @emph{without} specifying the underlying collection
type. The difference in the types of the two terms is telling:
@example
cons[integer]
@end example
and
@example
sequence[c->>integer] |: c
@end example
respectively -- where @code{c} is a type variable. The first is a
concrete type expression, the second is a constrained type -- in this
case @code{c} must implement the @code{sequence} contract.

Although the second type expression is longer, and a bit more complex
to read, it is also actually less constraining. The type expression
@code{cons[integer]} does not allow for variation of the underlying
collection type; the second type expression allows the term to be used
in contexts that require different concrete types.

@node Partial sequence notation
@subsection Partial sequence notation
The sequence notation also allows for the specification of partial
sequences; this is particularly useful in writing functions that
construct and traverse sequences. The sequence term:
@example
[1,2,..X]
@end example
denotes the sequence whose first two elements are @code{1} and
@code{2} and whose remainder is denoted by the variable @code{X} --
which must also be a sequence of the appropriate type. Similarly, the
term:
@example
[F..,23]
@end example
denotes the sequence obtained by gluing @code{23} to the back of the
sequence @code{F}.

There is a strong relationship between the normal sequence notation
and the partial sequence notation. In particular, the sequence
expression
@example
cons of [1,2]
@end example
is equivalent to:
@example
cons of [1,..cons of [2,..cons of []]]
@end example
where @code{cons of []} is actually just @code{.nil}.

We are not permitted to use both of @code{,..} and @code{..,}
in the same expression:
@example
[F..,2,3,..B]
@end example
is not permitted (since it amounts to a concatenation of two sequences
which, in turn, implies a non-deterministic decomposition when used as
a pattern).

The major benefit of general sequence notation is that it allows us to
construct programs involving collections that are independent of type
@emph{and} to do so in a syntax which is concise.

For example, we can use sequence notation to write functions over
sequences; such as the @code{concat} function that concatenates two
sequences:
@example
concat:all c,e ~~ stream[c->>e], sequence[c->>e] |: (c,c)=>c.
concat([],X) => X.
concat([E,..X],Y) => [E,..concat(X,Y)].
@end example
This function will work equally well with @code{cons} lists, lists,
strings, even your own collection types. All that is required is that
there is an implementation of the @code{stream} and the
@code{sequence} contracts for the actual type being concatenated.

@quotation
There are two contracts here: the @code{stream} contract is used when
decomposing sequences and the @code{sequence} contract is used when
building them.
@end quotation

@node The @code{stream} and @code{sequence} contracts
@subsection The @code{stream} and @code{sequence} contracts

@noindent
Underlying the sequence notation are two contracts: the @code{sequence}
contract and the @code{stream} contract. These contracts contains
type signatures that can be used to construct and to match against
sequence values. The sequence notation is realized by the compiler
translating sequence terms to a series of calls to those functions.

The standard @code{stream} contract is
@example
contract stream[t->>e] ::= @{
  _eof:()=>boolean.   -- is stream empty
  _hdtl:(t)=>option[(e,t)]. -- match front of stream
  _back:(t)=>option[(t,e)]. -- match back of stream
@}
@end example
and the standard @code{sequence} contract is:
@example
contract stream[t->>e] ::= @{
  _nil:t.     -- empty stream
  _cons:(e,t)=>t. -- add to front
  _apnd:(t,e)=>e. -- add to back
@}
@end example

The entries in the @code{sequence} contract should be fairly self-evident:

@itemize
@item
@code{_nil} is the empty sequence;
@item
@code{_cons} is a function that `glues' a new element to the front of
the sequence; and
@item
@code{_apnd} appends elements to the *back* of the sequence.
@end itemize

The compiler uses these three functions to transform sequence
expressions into function calls.

For example, the sequence expression:
@example
[1,2,3]
@end example
is transformed into
@example
_cons(1,_cons(2,_cons(3,_nil)))
@end example
If a sequence expression has an explicit type marker on it, then its
translation is slightly different -- to allow the type checker to make
use of the type information. For example,
@example
cons of [1,2]
@end example
is translated as:
@example
_cons(1,_cons(2,_nil())):cons[_]
@end example
This annotation is all that is needed to force the compiler to treat
the result as a concrete cons list. Type inference does the rest of
the hard work.@footnote{The type expression @code{_} is a special type
that denotes an anonymous type: each occurrence of the type expression
denotes a different unknown type. It is useful in situations, like
this one, where only some of the type information is known.}

@node Stream patterns
@subsection Stream patterns
The the @code{stream} contract is used in @emph{patterns} to match and
decompose sequences. For example, the signature for @code{hdtl} --
which is used to decompose sequences into a head and tail -- is:
@example
_hdtl:(t)=>option[(e,t)].
@end example
This function will be applied to a sequence in the attempt to split it
into a head and remainder. The question is how can a function be used
in a pattern?

The term @code{[1,2,..X]} @emph{as a pattern} is rewritten as:
@example
_hdtl^(1,_hdtl^(2,X))
@end example
where the @code{^} is syntactic sugar for the more elaborate form:
@example
S0 where (1,S1) ^= _hdtl(S0) && (2,X)^=_hdtl(S1)
@end example
which is, in turn, syntactic sugar for:
@example
S0 where some((1,S1)) .= _hdtl(S0) && some((2,X)) .= _hdtl(S1)
@end example
I.e., the sequence pattern becomes a series of progressive
decompositions of the stream; at each stage an @code{option}-valued
function is applied to peel off elements from the stream.

We can now straightforwardly give the translation for sequence
patterns. Syntactically, there is no distinction between sequence
expressions and stream patterns -- what distinguishes them is context:
stream patterns show up as patterns in functions and sequence
expressions show up in the expression context.

A stream pattern, as in the pattern @code{[E,..X]} for the non-empty
case in @code{concat}:
@example
concat([E,..X],Y) => [E,..concat(X,Y)]
@end example
is transformed into the pattern:
@example
_hdtl^(E,X)
@end example
and the entire @code{concat} equation becomes:
@example
concat(_hdtl^(E,X),Y) => _cons(E,concat(X,Y))
@end example
which, as we noted above, is actually equivalent to:
@example
concat(S0,Y) where some((E,X)).=S0 =>
  _cons(E,concat(X,Y)).
@end example

The @code{sequence} and @code{stream} contracts are two of the most
important and commonly used contracts. As we shall see further, many
of the standard collections functions are built on top of it.

@quotation
We have two contracts -- one for composing and another for decomposing
sequences -- because not all collections are equally amenable to
decomposing and/or composing. For example, the @code{map} type we
describe below does not have a natural notion of decomposing (because
ordering within a @code{map} is not preserved); even though it does
have a natural form of describing actual @code{map} collections.
@end quotation

@node Notation and contracts
@subsection Notation and contracts
One of the distinctive features of the sequence notation is that it is
an example of @emph{syntax} that is underwritten by a semantics
expressed as a @emph{contract}. 

This has a parallel in modern OO languages like Java and C# where
important contracts are expressed as interfaces rather than concrete
types. However, we extend the concept by permitting special notation
as well as abstract interfaces -- as many mathematicians understand, a
good notation can sometimes make a hard problem easy. We further
separate interfaces from types by separating the type definition from
any contracts that may be implemented by it.

The merit of this combination of special syntax and contracts is that
we can have the special notation expressing a salient concept -- in
this case the sequence -- and we can realize the notation without
undue commitment in its lower-level details. In the case of sequence
notation, we can have a notation of sequences without having to commit
to the type of the sequence itself.

@node Indexing
@section Indexing
Accessing collections conveniently is arguably more important than a
good notation for representing them. There is a long standing
traditional notation for accessing arrays:
@example
L[ix]
@end example
where @code{L} is some array or other collection and @code{ix} is an
integer offset into the array. We use a notation based on this
for accessing collections with random indices; suitably generalized to
include dictionaries (collections accessed with non-numeric indices)
and @emph{slices} (contiguous sub-regions of collections).

Before we explore the indexing notation it is worth looking at the
contract that underlies it -- the @code{indexed} contract.

@node The indexed contract
@subsection The indexed contract
The indexed contract captures the essence of accessing a collection in
a random-access fashion. There are functions in the contract to access
a directly accessed element, to replace and to delete elements from
the collection:

@example
contract all s,k,v ~~ indexed[s->>k,v] ::= @{
  _index:(s,k)=>option[v].
  _insert:(s,k,v)=>s.
  _replace:(s,k,v)=>s.
  _remove:(s,k)=>s.
@}
@end example
There are several noteworthy points here:

@itemize
@item
the form of the contract itself; the signature for @code{_index} which
accesses elements; and
@item
the signatures for @code{_insert}, @code{_replace} and @code{_remove}
which return new collections rather than modifying them in-place.
@end itemize

Recall that the @code{stream} contract had the form:
@example
contract all s, e ~~ stream[s->>e] ::= ...
@end example
the @code{s->>e} clause allows the implementation of the contract to
functionally determine (sic) the type of the elements of the
collection.

In the case of @code{indexed}, the contract form determines @emph{two}
types denoted by @code{k} and @code{v}. The type @code{k} denotes the
type of the key used to access the collection and @code{v} denotes the
type of the elements of the collection. Each individual implementation
of indexed is free to specify these types; usually in a way that best
reflects the natural structure of the collection.

For example, the implementation of @code{indexed} for strings starts:
@example
implementation indexed[string ->> integer,integer] => ...
@end example
reflecting the fact that the natural index for strings is integer and
the natural element type is integer (neither being explicitly part of
the string type name).  @footnote{Note that we use @code{integer} to
denote the type of string characters because the complexities of
Unicode representation make a consistent character encoding very
difficult.}

On the other hand, the implementation of @code{indexed} for the
concrete type @code{map} starts:
@example
implementation all k,v ~~
  indexed[map[k,v] ->> k,v] => @{ @dots{} @}
@end example
reflecting the fact that dictionaries are naturally generic over both
the key and value types.

If we look at the signature for @code{_index} we can see that this
function does not directly return a value from the collection, but
instead returns an @code{option} value. This bears further
explanation.

The great unknown of accessing elements of a collection is `is it
there?'. Its not guaranteed of course, and we need to be able to
handle failure. In the case of the @code{_index} function, its
responsibility is to either return a value wrapped as a @code{some}
value -- if the index lookup is successful -- or the signal
@code{none} if the index lookup fails. Just to be clear: @code{_index}
can act both as a lookup @emph{and} as a test for membership in the
collection.

@node Adding and removing elements
@subsubsection Adding and removing elements
The function @code{_insert} is used to add an element to a collection
associating it with a particular index position; and the function
@code{_remove} removes an identified element from the collection. The
function @code{_replace} is similar to @code{_insert} except that it
is expected that an existing element is replaced rather than a new
value being inserted.

These functions have a property often seen in functional programming
languages and not often seen elsewhere: they are defined to return a
complete new collection rather than simply side-effecting the
collection. This is inline with an emphasis on @emph{persistent data
structures}@footnote{A persistent structure is one which is never
modified -- changes are represented by new structures rather than
modifiying existing ones.} and on @emph{declarative programming}.

One might believe that this is a bit wasteful and expensive --
returning new collections instead of side-effecting the
collection. However, that is something of a misconception: modern
functional data structures have excellent computational properties and
approach the best side-effecting structures in efficiency. At the same
time, persistent data structures have many advantages -- including
substantially better correctness properties and behavior in parallel
execution contexts.

@quotation
It should also be stressed that the @code{indexed} contract allows and
encourages persistence but does not @emph{enforce} it. It is quite
possible to implement indexing for data structures that are not
persistent.
@end quotation

@node The index notation
@subsection The index notation
Given the indexed contract we can now show the specific notation for
accessing elements of a collection. Accessing a collection by index
follows conventional notation:
@example
C[ix]
@end example
will access the collection @code{C} with element identified by
@code{ix}. For example, given a @code{map} @code{D} of strings to
strings, we can access the entry associated with “alpha” using:
@example
D["alpha"]
@end example
Similarly, we can access the third character in a string @code{S} using:
@example
S[2]
@end example
As might be expected, given the discussion above, the type of an index
expression is optional.

The most natural way of making use of an index expression is to use it
in combination with a @code{^=} condition or an @code{^|} expression
-- which allows for smooth handling of the case where the index
fails. For example, we might have:

@example
nameOf(F) where N ^= names[F] => N.
nameOf(F) default => ...
@end example

We will take a deeper look at exceptions and more elaborate management
of tentative computation in @var{Computation Expressions}.

We also have a specific notation to represent modified
collections. For example, the expression
@example
D["beta"->"three"]
@end example
denotes the map @code{D} with the entry associated with @code{"beta"}
replaced by the value @code{"three"}. Note that the value of this
expression is the updated map.

For familiarity's sake, we also suppose a form of assignment for the
case where the collection is part of a read-write variable. The
action:
@example
D["beta"] := "three"
@end example
is entirely equivalent to:
@example
D := D["beta"->"three"]
@end example
always assuming that the type of @code{D} permits assignment.

Similarly, the expression:
@example
D[\+"gamma"]
@end example
which denotes the map @code{D} where the value associated with the key
@code{"gamma"} has been removed.

Although, in these examples, we have assumed that @code{D} is a map
value (which is a standard type); in fact the index
notation does not specify the type. As with the sequence notation, the
only requirement is that the @code{indexed} contract is implemented
for the collection being indexed.

In particular, as well as the @code{map} type, index notation is
supported for the built-in @code{list} type, and is even supported for
the @code{string} type.

In addition to the indexed access notation described so far, there is
also a variant of the sequence notation for constructing indexed
literals (aka dictionaries). In particular, an expression of the form:
@example
["alpha"->1, "beta"->2, "gamma"->3]
@end example
is equivalent to a sequence of tuples, or to:
@example
_cons(("alpha",1),_cons(("beta",2),_cons(("gamma",3),_nil))
@end example
which is understood by indexed types as denoting the contruction of a
literal.

Note that there are two levels of domain-specific notation here: the
representation of indexed literals in terms of a sequence of
two-tuples and the implicit rule governing indexed types: they should
implement a specific form of @code{sequence} contract. Both are
actually part of the semantics of representing indexed literals.

@node Implementing indexing
@subsection Implementing indexing

@noindent
Of course, this includes our own types. For example, before, when
looking at generic types we saw the tree type:
@example
all t ~~ tree[t] ::= tEmpty | tNode(tree[t],t,tree[t]).
@end example
We can define an implementation for the indexed contract for this type
-- if we arrange for the tree to be a tree of key-value pairs:
@example
implementation all k,v ~~
    order[k], equality[k] |: indexed[tree[(k,v)]->>k,v] => @{
  _index(T,K) => findInTree(T,K).
  _insert(T,K,V) => setKinTree(T,K,V).
  _replace(T,K,V) => setKinTree(T,K,V).
  _remove(T,K) => removeKfromTree(T,K).
@}
@end example
The form of the type expression @code{tree[(k,v)]} is required to
avoid confusion -- @code{tree} takes a single type argument that, in
this case, is a tuple type. The extra set of parentheses ensures that
@code{tree} is not interpreted (incorrectly) as a type that takes two
type arguments.

With this statement in scope, we can treat appropriate @code{tree}
expressions as though they were regular arrays or dictionaries:
@example
T = tNode(tEmpty,("alpha","one"),tEmpty)
assert "one" ^= T["alpha"].
U = T["beta"->"two"]. -- Add in "beta"
assert "one" ^= U["alpha"].
@end example
The implementation statement relies on another feature of the
type system -- we need to constrain the implementation of indexed to a
certain subset of possible instances of tree types -- namely, where
the element type of the tree is a @emph{pair} -- a two-tuple -- and
secondly we require that the first element of the pair is comparable
-- i.e., it has the @code{order} contract defined for it.

This is captured in the contract clause of the implementation
statement:
@example
implementation all k,v ~~ order[k], equality[k] |:
      indexed[tree[(k,v)]->>k,v] => ...
@end example
This implementation contract qualifier is fairly long, and the type
constraints are fairly complex; but it is exquisitely targeted at
precisely the right kind of tree without us having to make any
unnecessary assumptions.@footnote{It is also true that most
programmers will not be constructing new implementations of the
indexed contract very frequently.}

Implementing the indexed contract requires us to implement three
functions: @code{findInTree}, @code{setKinTree} and
@code{removeKfromTree}. The @code{findInTree} function is quite
straightforward:
@example
findInTree:all k,v ~~ equality[k], order[k] |: (tree[(k,v)],k)=>option[v].
findInTree(tEmpty,_) => none.
findInTree(tNode(_,(K,V),_),K) => some(V).
findInTree(tNode(L,(K1,_),_),K) where K1>K => findInTree(L,K).
findInTree(tNode(_,(K1,_),R),K) where K1<K => findInTree(R,K).
@end example
Notice that each `label' in the tree is a 2-tuple -- consisting of the
key and the value. This function is also where we need the key type to
be both comparable and supporting equality. The comparable constraint
has an obvious source: we perform inequality tests on the key.

The @code{equality} constraint comes from a slightly less obvious
source: the repeated occurrence of the @code{K} variable in the second
equation. This repeated occurrence means that the equation is
equivalent to:
@example
findInTree(tNode(_,(K,V),_),K1) where K==K1 => some(V).
@end example
We leave the implementations of @code{setKinTree} and
@code{removeKfromTree} as an exercise for the reader.

Along with the implementation of @code{indexed}, we should also
implement @code{sequence} for our trees:
@example
implementation all k,v ~~ order[k], equality[k] |:
  sequence[tree[(k,v)]->>(k,v)] => @{
    _nil = tEmpty.
    _cons((K,V),T) => setKinTree(T,K,V).
    _apnd(T,(K,V)) => setKinTree(T,K,V).
@}
@end example
@quotation Notice
that adding a pair to the front of a @code{tree} is semantically the
same as adding it to the back -- since the @code{tree} is ordered.
@end quotation

The reason for implementing @code{sequence} is that that will allow
users of the tree to use the indexed variant of the sequence notation
for writing tree literals; as in:
@example
tree of [1->”alpha”, 2->”beta”]
@end example
We do not implement the companion @code{stream} contract for our
@code{tree} because its semantics would be somewhat
problematic. However, there is nothing preventing the reader from
experimenting with an appropriate tree-ordering.

@node Index slices
@subsection Index slices
Related to accessing and manipulating individual elements of
collections are the @emph{indexed slice} operators. An indexed slice
of a collection refers to a bounded subset of the collection. The
expression:
@example
C[fx:tx]
@end example
denotes the subsequence of @code{C} starting with -- and including --
the element indexed at @code{fx} and ending -- but @emph{not}
including the element indexed at @code{tx}.

As might be expected, the index slice notation is also governed by a
contract -- the @code{sliceable} contract. This contract defines the
core functions for slicing collections and for updating subsequences
of collections:
@example
contract all s,k ~~ sliceable[s->>k] ::= @{
  _slice:(s,k,k)=>s.
  _tail:(s,k)=>s.
  _splice:(s,k,k,s)=>s.
@}
@end example
The @code{_slice} function is used extract a slice from the
collection, @code{_tail} is a variant that returns the `rest' of the
collection, and @code{_splice} is used to replace a subset of the
collection with another collection.

Like the indexing notation, there is notation for each of the three
cases:
@example
C[fx:]
@end example
denotes the tail of the collection -- all the elements in @code{C}
that come after @code{fx} (including @code{fx} itself);@footnote{The
complement of the tail slice is simple: @code{C[0:tx]}}. and
@example
C[fx:tx->D]
@end example
denotes the result of splicing @code{D} into @code{C}. This last form
has an additional incarnation -- in the form of an assignment
statement:
@example
C[fx:tx] := D
@end example
This action is equivalent to the assignment:
@example
C := _splice(C,fx,tx,D)
@end example
which, of course, assumes that @code{C} is defined as a read/write
variable.

The slice notation is an interesting edge case in domain specific
languages. It is arguably a little obscure, and, furthermore, the use
case it represents is not all that common. On the other hand, without
specific support, the functionality of slicing is hard to duplicate
with the standard indexing functions.

@node Doing stuff with collections
@section Doing stuff with collections

@noindent
One of the most powerful features of collections is the ability to
treat a collection as a whole. We have already seen a little of this
in our analysis of the visitor pattern @ref{Going even further}. Of
course, the point of collections is to be able to operate over them as
entities in their own right. As should now be obvious, most of the
features we discuss are governed by contracts and it is paradigmatic
to focus on contract specifications rather than specific
implementations.

The number of things that people want to do with collections is only
limited by our imagination; however, we can summarize a class of
operations in terms several patterns:

@itemize
@item
Filtering
@item
Transforming into new collections
@item
Summarizing collections
@item
Querying collections
@end itemize

Each of these patterns has some support from the standard repertoire
of functions.

@node Filtering
@subsection Filtering

@noindent
The simplest operation on a collection is to subset it. The standard
filter function -- @code{^/} -- allows us to do this with some
elegance. Using filter is fairly straightforward; for example, to
remove all odd numbers from a collection we can use the expression:
@example
Nums^/((X)=>X%2==0)
@end example
For example, if @code{Nums} were the list:
@example
list of [1,2,3,4,5,6,7,8,9]
@end example
then the value of the filter expression would be
@example
list of [2,4,6,8]
@end example
The right hand argument to @code{^/} is a @emph{predicate}: a function
that returns a @code{boolean} value. The @code{^/} function (which is
part of the standard @code{filter} contract) is required to apply the
predicate to every element of its left hand argument and return a
@emph{new} collection of every element that satisfies the
predicate.@footnote{The original collection is unaffected by the
filter.}

Note that the @code{%} function is arithmetic remainder, and the
expression @code{X%2==0} amounts to a test that @code{X} is even (its
remainder modulo 2 is 0).

The @code{^/} operator allows us to represent many filtering
algorithms whilst not making any recursion explicit. However, not all
filters are easily handled in this way; for example, a prime number
filter @emph{can} be written
@example
N^/isPrime
@end example
but such an expression is likely to be very expensive (the
@code{isPrime} test is difficult to do well).

@node The @code{filter} contract
@subsubsection The @code{filter} contract

@noindent
As noted above, the @code{^/} function is governed by a contract, the
@code{filter} contract:
@example
contract all c,e ~~ filter[c->>e] ::= @{
  (^/):(c,(e)=>boolean) => c.
@}
@end example

@node The sieve of Erastosthneses
@subsection The sieve of Erastosthneses

@noindent
One of the classic algorithms for finding primes that can be expressed
using filters is the so-called @emph{sieve of Eratosthenes}. This
algorithm works by repeatedly removing multiples of primes from a list
of natural numbers. We cannot (yet) show how to deal with infinite
lists of numbers but we can capture the essence of this algorithm
using a cascading sequence of filter operations.

The core of the sieve algorithm involves taking a list of numbers and
removing multiples of a given number from the list. This is very
similar to our even-number finding task, and we can easily define a
function that achieves this:
@example
filterMultiples(K,N) => N^/((X)=>X%K=!=0).
@end example
The overall Eratosthenes algorithm works by taking the first element
of a candidate list of numbers as the first prime, removing multiples
of that number from the rest, and recursing on the result:
@example
sieve([N,..rest]) => [N,..sieve(filterMultiples(N,rest))].
@end example
There is a base case of course, when the list of numbers is exhausted
then we have no more primes:
@example
sieve([]) => [].
@end example
The complete prime finding program is hardly larger than the original
filter specification:
@example
primes(Max) => let@{
  sieve([]) => [].
  sieve([N,..rest]) => [N,..sieve(filterMultiples(N,rest))].

  filterMultiples(K,N) => N^/((X)=>X%K=!=0).

  iota(Mx,St) where Mx>Max => [].
  iota(Cx,St) => [Cx,..iota(Cx+St,St)].
@} in [2,..sieve(iota(3,2))]
@end example
The @code{iota} function is used to construct a list of numbers, in
this case the integer range from @code{3} through to Max with an
increment of @code{2}. We start the @code{sieve} with @code{2} and the
list of integers with @code{3} since we are making use of our prior
knowledge that @code{2} is prime.

It should be emphasized that the sieve of Eratosthenes hardly counts
as an efficient algorithm for finding primes. For one thing, it
requires that we start with a list of integers; most of which will be
discarded. In fact, each `sweep' of the list of numbers results in a
new list of numbers; many of which too will eventually be
discarded. Furthermore, the @code{filterMultiples} function examines
every integer in the list; it does not make effective use of the fact
that successive multiples occupy predictable slots in the list of
integers.

@quotation
In fact, building a highly optimized version of the sieve of
Eratosthenes is not actually the main point here -- our purpose is to
illustrate the power of collections processing functions.
@end quotation

We might ask whether the @code{sieve} function can also be expressed
as a filter. The straightforward answer is that it cannot: the sieve
@emph{is} a kind of filter, but the predicate being applied depends on
the entire collection; not on each element. The standard filter
function does not expose the entire collection to the
predicate. However, we will see at least one way of achieving the
sieve without any explicit recursion below when we look at folding
operations.

@node Mapping to make new collections
@subsection Mapping to make new collections

@noindent
One of the limitations of the filter function is that it does not
create new elements: we can use it to subset collections but we cannot
transform them into new ones. The @code{fmap} function -- part of the
@code{functor} contract -- can be used to perform many transformations
of collections.

For example, to compute the lengths of strings in a list we can use
the expression:
@example
fmap(size,list of ["alpha","beta","gamma"])
@end example
which results in the list:
@example
list of [5,4,5]
@end example
The @code{fmap} function is defined via the @code{functor} contract --
thus allowing different implementations for different collection
types:
@example
contract all c/1 ~~ functor[c] ::= @{
  fmap:all a,b ~~ ((a)=>b,c[a])=>c[b].
@}
@end example
Notice how the contract specifies the collection type -- @code{c} --
without specifying the type of the collection's element type. We are
using a different technique here than we used for the @code{stream}
and @code{filter} contracts. Instead of using a functional dependency
to connect the type of the collection to the type of the element, we
denote the type of the input and output collections using a @emph{type
constructor} variable as in @code{c[a]} and @code{c[b]}.@footnote{This
also means that the collection type in @code{fmap} must be generic: it
is not possible to implement @code{functor} for strings.}

We are also using a variant of the quantifier. A quantified type
variable of the form @code{c/1} denotes a type constructor variable
rather than a regular type variable. In this case, @code{c/1} means
that the variable @code{c} must be a type constructor that takes one
argument.

The reason for this form of contract is that @code{functor} implies
creating a new collection from an old collection; with a possibly
different element type. This is only possible if the collection is
generic and hence the type expressions @code{c[a]} for the second
argument type of @code{fmap} and @code{c[b]} for its return type.

One might ask whether we could not have used functional dependencies
in a similar way to @code{stream} and @code{filter}; for example,
a contract of the form:
@example
contract all c,e,f ~~ mappable[c->>e,f] ::=  @{
  mmap:((e)=>f,c)=>c.
@}
@end example
However, @emph{this} contract forces the types of the result of the
@code{mmap} to be identical to its input type, it also allows the
implementer of the @code{mappable} contract to fix the types of the
collection elements -- not at all what we want from a @code{fmap}.

It is not all that common that we need to construct a list of sizes of
strings. A much more realistic use of @code{fmap} is for
@emph{projection}. For example, if we wanted to compute the average
age of a collection of people, which is characterized by the type
definition:
@example
person ::= someOne@{
  name:string.
  age:()=>float.
@}
@end example
Suppose that we already had a function @code{average} that could
average a collection of numbers; but which (of course) does not
understand people. We can use our average by first of all projecting
out the ages and then applying the average function:
@example
average(fmap((X)=>X.age(),People))
@end example
In this expression we project out from the @code{People} collection
the ages of the people and then use that as input to the average
function.

@node More Type Inference Magic
@subsubsection More Type Inference Magic

@noindent
There is something a little magic about the lambda function in this
expression: how does the type checker `know' that @code{X} can have a
field @code{age} in it? How much does the type checker know about
types anyway?

In this particular situation the type checker could infer the type of
the lambda via the linking between the type of the @code{fmap}
function and the type of the @code{People} variable. However, the type
checker is actually capable of giving a type to the lambda even
without this context. Consider the function:
@example
nameOf(R) => R.name
@end example
This function takes an arbitrary record as input and returns the value
of the @code{name} field. The @code{nameOf} function @emph{is} well
typed, its type annotation just needs a slightly different form than
that we have seen so far:@footnote{Note that the type system
will not @emph{infer} this generalized type.}
@example
nameOf:all r,n ~~ r <~ @{name:n@} |: (r)=>n
@end example
This is another example of a @emph{constrained type}: in this case,
the constraint on @code{r} is that it has a field called @code{name}
whose type is the same as that returned by @code{nameOf} itself.

The type constraint:
@example
r <~ @{name:n@}
@end example
means that any type bound to @code{r} must have a @code{name} field
whose type is denoted by the type variable @code{n} in this case.

With this type signature, we can use @code{nameOf} with any type that
that a @code{name} field. This can be a record type; it can also be a
type defined with an algebraic type definition that includes a record
constructor.

@node Compressing collections
@subsection Compressing collections

@noindent
Another way of using collections is to summarize or aggregate over
them. For example, the @code{average} function computes a single
number from an entire collection of numbers -- as do many of the other
statistical functions. We can define average using the standard
@code{foldLeft} function, which is part of the standard @code{folding}
contract:
@example
average(C) is foldLeft((+),0,C)::float/size(C)::float
@end example

@quotation
This definition of the @code{average} function is about as close to a
specification of average as is possible in a programming language!
@end quotation

@quotation Notice
the use of coercion here -- coercing both the result of the
@code{foldLeft} and @code{size} to float. The reason for doing this is
that functions like @code{average} are `naturally' real
functions.@footnote{Real as in the ℝeal numbers.} Without the explicit
coercion, averaging a list of integers will also result in an integer
value -- which is likely to be inaccurate.
@end quotation

Of course, in our definition of @code{average} we need to coerce
@emph{both} the numerator and denominator of the division because
@Star{} does not have implicit coercion.

The @code{foldLeft} function applies a binary function to a
collection: starting from the first element and successively `adding
up' each of the elements in the collection using the supplied
operator.

@float Figure,leftFold
@caption{Left Folding a Collection}
@image{images/leftfold}
@end float

As we noted above, @code{foldLeft} is part of the @code{folding}
contract. Like the @code{functor} contract, this uses some more subtle
type constraints:
@example
contract all c,e ~~ folding[c->>e] ::= @{
  foldRight:all x ~~ (((e,x)=>x),x,c) => x.
  foldLeft:all x ~~ (((x,e)=>x),x,c) => x.
@}
@end example
The @code{folding} contract uses quantifiers in two places: once in
the contract specification and once in the type signature for
@code{foldLeft} (and @code{foldRight}). What we are trying to express
here is that any implementation of @code{folding} must allow for a
generic function to process the collection.

The @code{foldLeft} (and @code{foldRight}) functions have an
`accumulator' (of type @code{x}) which need not be the same as the
type of the elements of the collection.@footnote{We saw something
similar with the visitor pattern.} This argument acts as a kind of
linking thread during the entire computation -- and represents the
returned value when the fold is complete.

But we can do much more than computing averages with a fold. Recall
that when we realized the sieve of Eratosthenes, we still had a
recursive structure to the program. Furthermore, the way our original
program was written each filter results in a new list of numbers being
produced. Instead of doing this, we can construct a cascade of filter
functions - each level in the cascade is responsible for eliminating
multiples of a specific prime.

The complete cascade filters by checking each level of the cascade:
for example, after encountering 3, 5 and 7, there will be a cascade of
three functions that check each incoming number: one to look for
multiples of 3, one for multiples of 5 and one for multiples of
7. When we encounter the next prime (11) then we glue on to the
cascade a function to eliminate multiples of 11.

Consider the task of adding a filter to an existing cascade of
filters. What is needed is a new function that combines the effect of
the new filter with the old one. The @code{cascade} function takes a
filter function and a prime as arguments and constructs a new function
that checks both the prime @emph{and} the existing filter:
@example
cascade:((integer)=>boolean,integer)=>((integer)=>boolean).
cascade(F,K) => (X)=>F(X) && X%K=!=0.
@end example

@quotation
This is a truly higher-order function: it takes a function as argument
and returns another function.
@end quotation

Given @code{cascade}, we can reformulate the @code{sieve} function
itself as a @code{foldRight} -- at each new prime step we `accumulate'
a new cascaded filter function:
@example
stp:(integer,(integer)=>boolean)=>((integer)=>boolean).
stp(X,F) where F(X) => cascade(F,X).
stp(X,F) => F.
@end example
At each step in the fold we want to know whether to continue to
propagate the existing filter or whether to construct a new filter.

The @code{sieve} function itself is now very short: we simply invoke
@code{foldRight} using @code{stp} and an initial `state' consisting of
a function that checks for odd numbers:
@example
sieve(C) => foldRight(stp,(K)=>K%2=!=0,C).
@end example
This version of @code{sieve} is not quite satisfactory as, while it
does find prime numbers, it does not report them. A more complete
version has to also accumulate a list of primes that are found. We can
do this by expanding the accumulated state to include both the
cascaded filter function and the list of found primes. The main
alteration is to the @code{step} function:
@example
step:((list[integer],(integer)=>boolean),integer) => (list[integer],(integer)=>boolean).
step(X,(P,F)) where F(X) => ([P..,X],cascade(F,X)).
step(_,(P,F)) => (P,F).
@end example
and the initial state has an empty list:
@example
sieve(C) is fst(foldRight(step,([],(K)=>K%2=!=0),C)).
@end example
where @code{fst} and @code{snd} are standard functions that pick the
left and right hand sides of a tuple pair:
@example
fst:all s,t ~~ ((s,t))=>s.
fst((L,R)) => L
snd:all s,t ~~ ((s,t))=>t.
snd((L,R)) => R
@end example
There is one final step we can make before leaving our sieve of
Eratosthenes -- we can do something about the initial list of
integers. As it stands, while the sieve program does not construct any
intermediate lists of integers, it still requires an initial list of
integers to filter. However, this particular sequence can be
represented in a very compact form -- as a @code{range} term.

@code{range} terms are special forms of collections that denote ranges
of numeric values. For example, the expression
@example
range(0,100,2)
@end example
denotes the sequence of integers starting at zero, not including 100,
each succesive integer being incremented by 2.

Using a similar @code{range} term, we can denote the list of primes
less than 1000 with
@example
primes(Max) => let@{
  cascade:((integer)=>boolean,integer) => ((integer)=>boolean).
  cascade(F,K) => (X)=>(F(X) && X%K=!=0).

  step(X,(P,F)) where F(X) => ([P..,X],cascade(F,X)).
  step(_,(P,F)) => (P,F).

  sieve:(range[integer])=>list[integer].
  sieve(R) => fst(foldRight(step,([],(K)=>true),R)).
@} in sieve(range(3,Max,2)).

show primes(1000)
@end example
This final program has an important property: there are no explicit
recursions in it -- in addition, apart from the @code{foldRight}
function, there are no recursive programs at all in the definition of
@code{primes}.

@quotation
Of course, it still would not count as the @emph{most efficient}
primes finding program; but that was not the goal of this discussion.
@end quotation

@node Different types of collection
@section Different types of collection

@noindent
Just as there are many uses of collections, so there are different
performance requirements for collections themselves. The most
challenging aspects of implementing collections revolves around the
cost of @emph{adding} to the collection, the cost of @emph{accessing}
elements of the collection and the cost of @emph{modifying} elements
in the collection.

There is a strong emphasis on @emph{persistent} semantics for the
types and functions that make up the  collections
architecture. This is manifest in the fact, for example, that
functions that add and remove elements from collections @emph{do not}
modify the original collection.

However, even without that constraint, different implementation
techniques for collections tend to favor some operations at the cost
of others. Hence, there are different types of collection that favor
different patterns of use.

@node The @code{cons} type
@subsection The @code{cons} type

@noindent
This is the simplest collection type; and is perhaps the original
collection type used in functional programming languages. It is
defined by the type declaration:
@example
all t ~~ cons[t] ::= nil | cons(t,cons[t]).
@end example
Cons lists have the property that adding an element to the front of a
list is a constant-time operation; similarly, splitting a @code{cons}
list into its head and tail is also a constant time
operation. However, almost every other operation is significantly more
expensive: putting an element on to the end of a @code{cons} list is
linear in the length of the list.

The main merit of the @code{cons} list is the sheer simplicity of its
definition. Also, for small collections, its simple implementation may
outweigh the advantages that more complex collections offer.

@node The @code{list} type
@subsection The @code{list} type

@noindent
The list type offers a different trade-off to the @code{cons} type:
where the latter is optimal for ease of constructing and for
traversing complete lists, the list type offers constant-time access
to random elements within the array -- at the potential cost of more
expensive construction of lists.

Unlike the @code{cons} type, the @code{list} type does not have a
straightforward definition as an algebraic type. Internally, a list
structure consists of an array of locations with a `control pointer'
giving the portion of the array block that represents a given list
value. This is sometimes called a Copy on Write (COW) structure.

The @code{list} type is optimized for random access and for shared
storage -- recall that collection types are persistent: that means
that different values can share some or all of their internal
structure. The diagram below shows two list values that overlap in
their elements and consequently share some of their structure.

@float Figure,twoarrays
@caption{Two lists Sharing Structure}
@image{images/twoarrays}
@end float

@node The @code{map} type
@subsection The @code{map} type

@noindent
Unlike the @code{cons} or @code{list} type, the @code{map} type is
oriented for access by arbitrary keys. The @code{map} is also quite
different to hash maps as found in Java (say), the @code{map} type is
@emph{persistent}: the functions that access dictionaries such as by
adding or removing elements return new dictionaries rather than
modifying a single shared structure. However, the efficiency of
@code{map} is quite comparable to Java's HashMap.

The template for the @code{map} type is:
@example
all k,v ~~ equality[k], hash[k] |: map[k,v]
@end example
Notice that there is an implied constraint here: the @code{map}
assumes that the keys in the map can be compared for equality, and
that they are hashable -- have a @code{hash} function.

A @code{map} value can be written using the sequence notation, using
tuple pairs for the key-value pairs:
@example
map of [(1,"alpha"),(2,"beta”)]
@end example
As we saw before, @code{map}s also have a special variant of the
sequence notation; instead of writing the pairs as tuples we can use
an arrow notation for @code{map} terms:
@example
map of [1->"alpha", 2->"beta"]
@end example
Maps also have their own special variant of a @emph{query search
condition}. A condition of the form
@example
K->V in D
@end example
where D is a @code{map} will be satisfied if there is a key/value pair
in D corresponding to K and V. For example, the condition:
@example
K->V in map of [1->"alpha", 2->"beta"] && V=="alpha"
@end example
is satisfied for only one pair of @code{K} and @code{V}: namely
@code{1} and @code{"alpha"} respectively.

For the curious, dictionaries are implemented using techniques similar
to, as described by Bagwell in @cite{Ideal Hash Trees, P. Bagwell}. This
results in a structure with an effective O(1) cost for accessing
elements @emph{and} for modifying the @code{map} -- all the while
offering an applicative data structure.

@node The @code{set} type
@subsection The @code{set} type

@noindent
There are many instances where a programmer needs a collection but
does not wish specify any ordering or mapping relationship. The
standard @code{set} type allows you to construct such entities.

Using a @code{set} type offers the programmer a signal that minimizes
assumptions about the structures: the set type is not ordered, and
offers no ordering guarantees. It does, however, offer a guarantee
that operations such as element insertion, search and set operations
like set union are implemented efficiently.

Like @code{map}, the @code{set} type is not publicly defined using an
algebraic type definition: its implementation is private. It's type is
given by the template:
@example
all t ~~ equality[t] |: set[t]
@end example

@node Collecting it together
@section Collecting it together

@noindent
Collections form an important part of any modern programming
language. The suite of features that make up the collections
architecture consists of a number of data types, contracts and special
syntax that combine to significantly reduce the burden of the
programmer.

The collections facility amounts to a form of DSL -- Domain Specific
Language -- that is, in this case, built-in to the language. We shall
see later on that, like many DSLs, this results in a pattern where
there is a syntactic extension to the language that is backed by a
suite of contracts that define the semantics of the DSL.
