{\rtf1\ansi\ansicpg1252\cocoartf1561\cocoasubrtf200
{\fonttbl\f0\froman\fcharset0 Palatino-Roman;}
{\colortbl;\red255\green255\blue255;}
{\*\expandedcolortbl;;}
\pard\tx360\tx720\tx1080\tx1440\tx1800\tx2160\tx2880\tx3600\tx4320\fi360\sl264\slmult1\pardirnatural\partightenfactor0

\f0\fs26 \cf0 [[types]]\
= Types\
(((type system)))\
Star is a strongly, statically, typed language. That means that all values and all variables must have a unique well-defined type that is determinable by inspecting the text of the program -- effectively at `compile time'.\
\
The type system of Star consists of a method for declaring new types, for annotating variables (and by extension programs) with their types and a system of verifying the type consistency of programs.\
\
== What is a Type?\
A <<Type>> is an expression that denotes a set of values.\
\
[TIP]\
Although a type is an expression, type expressions should not be confused with normal expressions. Types generally play no part in evaluation.\
\
Viewed as sets, types have some particular properties: no value may be a member of more than one type set; all values are members of exactly one type set.\
\
A <<TypeDefinition>> introduces a new type and defines what values belong to the type. A <<TypeAnnotation>> is an assertion that a particular expression -- usually a variable -- has a certain type.\
\
For many simple cases, a type is denoted by an identifier. For example, the type identifier `string` denotes the set of all strings. More explicitly, a value has type `string` iff footnote:[The term "iff" means "if and only if".] it belongs to the set denoted by the symbol `string`.\
\
Many value-sets are effectively infinite in size: the size of the set of ``string``s is essentially unbounded; as is the set of `integer` values.\
\
In addition to sets of values denoted by identifiers; there are other kinds of value sets that have more complex type expressions. For example, the set of _function values_ is denoted not by a single type expression but a _schema_ of type expressions -- each taking a form such as:\
\
[listing]\
(t1,..,tn)=>t\
\
For example, the type expression\
[listing]\
(integer)=>string\
\
denotes the set of functions that take an `integer` as an argument and produce a `string` value. Like the set of all integers, this set is also infinite in size.\
\
The language for denoting types is quite expressive. It is possible to have types that are parameterized; that is they are composed from other type expressions. It is also possible to have types that are not explicitly named but are defined by constraints.\
\
A simple example of a parameterized type is the `cons` type: a `cons` type expression always involves the mention of another type -- the type of elements of the list. The type expression\
[listing]\
cons[string]\
\
denotes the type expression associated with lists whose elements are all string values. Other examples of `cons` type include lists of integers:\
[listing]\
cons[integer]\
\
and even lists of lists of string valued functions:\
[listing]\
cons[cons[(integer)=>string]]\
\
[NOTE]\
====\
Technically, the `cons` symbol in:\
[listing]\
cons[integer]\
\
(((type function)))\
is a <<TypeConstructor>>: it takes a type as an argument and returns another type as result.\
====\
Often it is convenient to be able to `talk' about types without being specific about the type itself; for this purpose we use <<TypeVariable>>s.\
\
A type variable is distinguished by an explicit quantifier -- either a <<UniversalType>> or a <<ExistentialType>> . The type expression:\
[listing]\
all t ~~ cons[t]\
\
denotes a list type of some unspecified element type -- identified by the type variable `t`.\
\
[TIP]\
The value set associated with this type expression is a little more difficult to visualize than the set of lists of integers (say). `cons[t]` denotes a set of cons values; but without more information _we cannot say_ what the complete values look like -- it is dependent on the meaning of the type variable `t`.\
\
In order to properly understand the interpretation of a type variable one must understand how the type variable is 'bound'. In general, there are three possibilities: the type variable may be identified with (equal to) another type; the type variable may be bound by a universal quantifier or by an existential quantifier.\
\
A universally quantified type (see <<universalType>>) denotes a type that allows all possible instantiations for the type variable. For example, function types often involve universal types. A universally typed function is expected to work `for all values' of the type variable -- which, in turn, means that the function definition can make no assumptions about the actual type.\
\
Existentially quantified types (see <<existentialType>>) are  used to denote _abstract types_; i.e., the existential quantifier signals that there is a type that should be treated as an opaque `black box'.\
\
==== Type Safety\
The connection between the argument type of a `cons` type expression and the actual elements of lists is denoted by a _type inference rule_. Type inference rules are rules for relating expressions and statements in the language to the types associated with that statement. For example, the rule:\
\\begin\{prooftree\}\
\\AxiomC\{\\typeprd\{E\}\{El\\sub1\}\{T\}\\sequence\{\\ \}\\typeprd\{E\}\{El\\subn\}\{T\}\}\
\\UnaryInfC\{\\typeprd\{E\}\{`cons of [`El\\sub1\\sequence\{,\}El\\subn`]`\}\{`cons of `T\}\}\
\\end\{prooftree\}\
says that if the expressions _El\\sub1_ through _El\\subn_ all have type _T_, then the list expression\
[listing]\
cons of [_El\\sub1_\\sequence\{,\}_El\\subn_]\
\
has type `cons of` T. This is the formal way of stating that all elements of a list must have the same type.\
\
The general form of a type inference rule that is determining a type (sometimes called a type judgment) is:\
\\begin\{prooftree\}\
\\AxiomC\{\\mbox\{_Condition_\}\}\
\\UnaryInfC\{\\typeprd\{E\}\{X\}\{T\}\}\
\\end\{prooftree\}\
This should be read as\
\\begin\{quote\}\
If _Condition_ is satisfied, then we can infer from the context _E_ that _X_ has type _T_\
\\end\{quote\}\
where the symbol \\tinfers\{\} can be read as `type implication'. In general, the type of an expression depends on the context that it is found.\
\
\\paragraph\{Type Annotations\}\
In most cases it is not necessary to explicitly declare the type of a variable. However, it is good practice to declare explicitly the types of programs; especially within <<thetaEnvironment>>s.\
\
For example, a generic function `consLength` that takes a `cons` list and returns an integer would have the declaration:\
[listing]\
consLength:all t ~~ (cons[t])=>integer\
\
This is an example of a universally quantified type -- see <<universalType>> for more details.\
\
==== Kind Annotations\
[[kindAnnotation]]\
Just as values have types, and the language system arranges to ensure that types are preserved, so types have _kinds_. A <<Kind>> is a `kind of type'.\
\
[NOTE]\
Type <<Kind>>s allow the language to keep track of the expected arity of a type: i.e., how many type arguments the type expected.\
\
\
== Type Expressions\
[[typeExpressions]]\
(((forms of types)))\
(((type expressions)))\
\
<<typeFig>> illustrates the top-levels of the different kinds of type expressions that the Star programmer will encounter.\
\
\
[[typeFig]]\
.Types of Types\
:hardbreaks:\
****\
[[Type]]Type::=<<TypeExpression>>\
  | <<TypeVariable>> | <<ReferenceType>>\
  | <<TupleType>> | <<RecordType>>\
  | <<FunctionType>> | <<PatternType>> | <<ConstructorType>>\
  | <<TypeQuantifier>> `~~` <<Type>>\
  | <<TypeConstraint>> ``|:`` <<Type>>\
  | `(` <<Type>> `)`\
  | <<EncapsulatedType>>\
\
[[TypeQuantifier]]TypeQuantifier ::= <<UniversalQuantifier>> | <<ExistentialQuantifier>>\
****\
\
There are two main kinds of type expressions -- so-called _structural_ type expressions and _named_ type expression. A structural type expression encodes by convention the permitted _forms_ of values of that type. By contrast, a named type expression is defined via some form of <<TypeDefinition>>.\
\
A classic example of a structural type expression is the function type. A function type expression defines both the types of the arguments and result type of the function. But, more importantly, it signals that the value is a function.\
\
A good example of a named type is the standard `integer` type. The word `integer` does not signal by itself that the allowable operations on integer values include arithmetic, comparison and so on. That information must come from additional statements and declarations.\
\
One of the other differences between structural and named type expressions is that the latter may be used to denote _recursive_ types, whereas the former cannot.\
\
[TIP]\
A recursive type is one whose values may contain elements that are themselves of the same type. For example, in a `tree` type: the nodes of the tree are typically themselves trees.\
\
=== Type Expressions\
[[typeNames]]\
(((type)))\
\
\
[[typeExpressionFig]]\
.Type Expressions\
:hardbreaks:\
****\
[[TypeExpression]]TypeExpression ::= <<TypeConstructor>> `[`<<Type>> ,..., <<Type>> `]`\
  | <<Identifier>>\
\
[[TypeConstructor]]TypeConstructor ::= <<Identifier>> | <<TypeVar>>\
****\
\
A <<TypeExpression>> is a term that identifies a class of values by name. The name may or may not have <<TypeArgument>>s -- in which case, the type is said to be _parameterized_.\
(((type,parameterized)))\
(((parameterized types)))\
\
==== Simple Types\
[[simpleType]]\
(((type,simple)))\
A simple type is <<TypeExpression>> with no type arguments. Some simple types are pre-defined, <<predefinedTypes>> gives a table of such types.\
(((standard,simple types)))\
\
[[predefinedTypes]]\
.Standard Pre-defined Types\
[cols="1,3"]\
|===\
| Type | Description\
| `boolean` | used for logical values and conditions\
| `float` | type of floating point numbers\
| `integer` | type of integer values\
| `string` | type of string values\
| `quoted` | type of abstract syntax\
| `astLocation` | type of location marker\
| `exception` | type of exception token\
|===\
\
==== Parameterized Types\
[[parameterizedType]]\
(((type,parameterized)))\
(((parameterized type)))\
\
A parameterized <<TypeExpression>> consists of a <<TypeConstructor>> applied to one of more <<Type>> arguments. For example, the standard `cons` type constructor has one type argument -- the type of elements of the `cons`.\
\
A parameterized type has a _type arity_ -- the number of type arguments it expects. This is defined when the type itself is defined. It is an error to write a type expression involving an incorrect number of type arguments.\
\
Parameterized types may be defined using a <<TypeDefinition>> statement.\
\
==== Variable Type Constructors\
[[variableConstructor]]\
(((type,variable constructor)))\
(((type constructor expression)))\
\
A type expression of the form:\
[listing]\
c[t1,...,tn]\
\
where `c` is a\
type variable -- i.e., bound by a quantifier -- denotes a rather special form of type: a type constructor expression. Like other parameterized type expressions, this expression does not denote a single type; but a set of types. For example, the type expression:\
[listing]\
c of integer\
\
denotes a type `something of `integer`'.\
\
A subsequent constraint on `c` may cause it to be bound to the <<TypeConstructor>> `cons` (say), in which case the type expression becomes ground to the parameterized type expression ``cons[integer]``.\
\
Such type expressions are of most use in certain forms of <<Contract>> where the contract is about a certain form of parameterized type.\
\
[NOTE]\
A variable constructor is equivalent to a regular type variable with a <<HasKind>> constraint.\
\
=== Tuple Types\
[[tupleType]]\
A tuple type is a tuple of types; written as a sequence of type expressions enclosed in parentheses.\
\
.Tuple Type\
[[tupleTypeFig]]\
****\
[[TupleType]]TupleType ::= `()`\
  | ``\\((`` <<Type>> ``))``\
  | `(`<<Type>> ,.., <<Type>>``)``+2\
****\
\
A tuple type denotes a fixed grouping of elements. Each element of the tuple may have a different type.\
\
There are two special cases in <<TupleType>>s: the empty tuple and the singleton tuple type.\
\
==== Empty Tuple\
(((tuple,empty tuple type)))\
\
The empty tuple type:\
[listing]\
()\
\
refers to the empty tuple. It is useful primarily for writing function types where the function has no arguments:\
[listing]\
()=>string\
\
When used as the return type of a function, the `()` type denotes a void result:\
[listing]\
(integer)=>()\
\
[TIP]\
The `()` type -- sometimes referred to as the _unit type_ -- is also used to denote the return type of some actions.\
\
==== Singleton Tuple\
(((tuple,singleton tuple type)))\
\
A singleton tuple must be written with two parentheses. This is to disambiguate such terms from simple expression parentheses. A type expression of the form:\
[listing]\
(integer)\
\
is equivalent to just the `integer` type; whereas\
[listing]\
((integer))\
\
denotes the single element tuple type whose element type is `integer`.\
\
[[recordType]]\
=== Record Type\
A <<RecordType>> is a type expression that denotes a named association of fields and types. A record type is written as a sequence of type annotations enclosed in braces.\
\
\
[[recordTypeFig]]\
.Record Type\
****\
[[RecordType]]RecordType ::= `\{`<<Annotation>> ; .. ;<<Annotation>> `\}`\
\
[[TypeEquality]]TypeEquality ::= `type` <<Identifier>> `=` <<Type>>\
****\
\
Record types are used as the type of anonymous records (see <<anonRecord>>). They are also the basis of other features of the type language -- including the <<ConstructorType>> and <<Contract>>s.\
\
Two record types are equivalent if their elements are pair-wise equivalent. Note that the _order_ of elements is not important. For example, given the types:\
[listing]\
\{a:string ; b:integer \}\
\
and\
[listing]\
\{b:integer ; a:t \}\
\
these types unify -- assuming that `t` is a bound type variable, provided that `t` is unifiable with `string`.\
\
[NOTE]\
All user-defined types -- i.e., types defined by an <<AlgebraicType>> definition -- have a <<RecordType>> interface associated with them. This, as is detailed in <<algebraicInterface>>, defines a type for all of the fields in any of the constructors for the type. In turn, this permits a <<RecordAccess>> expression to apply to a user-defined type as well as a <<RecordType>>.\
\
[[functionType]]\
=== Function Type\
(((function type)))(((type,function)))A function type denotes a function value. It takes the form of a possibly empty sequence of argument types -- denoting the types of the arguments to the function -- enclosed in parentheses; followed by the result type of the function. <<functionTypeFig>> highlights the form of the function type:\
\
\
[[functionTypeFig]]\
.Function Type\
****\
[[FunctionType]]FunctionType ::= <<TupleType>> `\\=>` <<Type>>\
****\
\
For example, a function of two arguments -- an `integer` and a `string` that returns a list of `string`s has a type that takes the form:\
[listing]\
(integer,string) => cons[string]\
\
\
==== Procedure Type\
[[procedureType]]\
(((procedure type)))\
(((type,procedure)))\
\
A procedure is an abstraction of an action. I.e., a procedure is a function that does not return a value but is executed purely for its side effect(s). This is expressed in the form of procedure types, which take the form of a function type that returns an empty tuple:\
\
****\
<<TupleType>> `\\=> ()`\
****\
\
For example, a procedure that takes `string` and `integer` arguments would have the type signature:\
[listing]\
(string,integer)=>()\
\
And the type:\
[listing]\
()=>()\
\
denotes the type of a procedure that takes no arguments.\
\
\
=== Pattern Abstraction Type\
A <<PatternAbstraction>> is an abstraction of a pattern. Pattern abstractions allow patterns to be treated as first class values -- i.e., passed in as arguments to programs and bound to variables -- and they may be applied in contexts where patterns are valid.\
\
The form of a pattern abstraction type is defined in <<patternAbTypeFig>>.\
\
[[patternAbTypeFig]]\
.Pattern Type\
****\
[[PatternType]]PatternType ::= <<TupleType>> `\\<=` <<Type>>\
****\
\
Pattern abstractions match a pattern, and extract values from that pattern; values that, in turn, may be matched against where the pattern abstraction is applied.\
For example, a <<PatternAbstraction>> that matches ``string``s that are intended to denote `integer` literals, and extracts such an `integer` would have the type\
[listing]\
(integer) <= string\
\
\
=== Constructor Type\
[[constructorType]]\
(((constructor type)))\
(((type,constructor)))\
\
A constructor is a special function that is introduced in an <<AlgebraicType>> definition.\
\
[NOTE]\
Constructors are special because they can be viewed simultaneously as a function and as a pattern. Hence the form of the constructor reflects that bidirectionality.\
\
The form of a constructor type is given in <<constructorTypeFig>>.\
\
[[constructorTypeFig]]\
.Constructor Type\
****\
[[ConstructorType]]ConstructorType::=<<Type>> `\\<\\=>` <<Type>>\
****\
\
The left hand side of a constructor type should either be a <<TupleType>> or an <<RecordType>> -- depending on whether the denoted constructor is a term constructor constructor or a record constructor.\
\
[TIP]\
<<ConstructorType>>s are most used in the context of the signatures of _abstract data types_: where a type and its constructors are `exported' from a record.\
\
=== Reference Type\
[[referenceType]]\
(((reference type)))\
(((type,ref@`ref`)))\
\
A re-assignable variable is given a ``ref``erence type.\
\
\
[[referenceTypeFig]]\
.Reference Type\
****\
[[ReferenceType]]ReferenceType ::= `ref` <<Type>>\
****\
\
Reference types allow the programmer to distinguish re-assignable variables from other values; in particular they allow one to distinguish between binding to the _value_ of a re-assignable variable or to its _name_.\
\
[NOTE]\
The latter is not as common, but is important to support abstractions involving re-assignable variables.\
\
=== Type Variables\
[[typeVariable]]\
(((type,variable)))\
\
A type variable is a variable which may be bound to a type. Depending on whether the scope of a type variable is explicitly determined or implicitly determined, type variables are written as regular identifiers -- they are distinguished from regular named types by virtue of the quantifier they are bound by.\
\
[[typeVariableFig]]\
.Type Variables\
****\
[[TypeVariable]]TypeVariable ::= <<Identifier>>\
****\
\
==== Type Variable Kind\
Type variables are associated with a <<Kind>> -- which constrains the kinds (sic) of types that the type variables may be bound to. For example, a <<Kind>> of `type` implies that the type variable may be bound to any valid type -- but may not be bound to a <<TypeConstructor>>.\
\
[NOTE]\
The different kinds of type variable may not be mixed: it is not permissible to bind a type variable to a <<TypeConstructor>>, and vice versa.\
\
For example, given:\
[listing]\
all t ~~ cons[t] ::= nil | cons(t, cons[t]);\
\
The type variable `t` may be bound to a type expression such as `cons[string]` but not to a higher-kinded type (such as `cons` itself).\
\
\
==== Scope of Type Variables\
[[typeVarScope]]\
(((type,variable!scope)))\
\
All type variables have a scope which generally follows the scoping rules for normal variables.\
\
There are two particular cases that are important: type variables introduced via <<TypeDefinition>>s and those introduced via explicitly quantified type expressions.\
\
A variable introduced in the head of an <<AlgebraicType>> definition, or in the head of a <<Contract>> definition are in scope throughout the definition or contract respectively.\
\
=== Universally Quantified Types\
[[universalType]]\
(((types,universally quantified)))\
(((universally quantified type)))\
\
A universal type denotes a type that is valid for all substitutions of a type variable.\
\
[[universalTypeFig]]\
.Universal Type Expression\
****\
[[UniversalType]]UniversalType::= `all` <<BoundType>>,..,<<BoundType>>\\ `~~` <<Type>>\
\
[[BoundType]]BoundType ::= <<Identifier>> | <<Identifier>>``/``<<Decimal>>\
****\
\
The first form of <<BoundType>> introduces a regular type variable -- i.e., a variable of <<Kind>> `type`. The second form is used to introduce a higher-kinded type variable.\
\
For example, the quantification:\
\
[listing]\
all c/1 ~~ ...\
\
denotes a type variable of kind `type[type]`.\
\
[TIP]\
Higher kinded type variables are most commonly used in the context of <<Contract>> definitions.\
\
Star will infer the type of expressions; but does _not_ infer the types associated with defined variables -- i.e., variables defined in `let` environments and at the top-level of a package.\
\
Furthermore, the type checker _never_ infers a so-called generic type (a type that has universally or existentially quantified variables)\
\
One consequence of this is that all top-level definitions must have an explicit type annotation; and all generically typed expressions footnote:[This can happen if function-valued argument to a function is going to be used in different situations within the function then that argument needs to explicitly marked as universal.] must be explicitly quantified.\
\
[NOTE]\
The reason for this is that explicit types provide superior documentation to programs -- especially where the actual type is complex.\
\
For example, the  `dblFilter` function in Program~\\vref\{dblFilter\} applies a `map` function in two different situations -- one for each element of each pair in the input list.\
\
[[dblFilter]]\
.A `double` filter\
[listing]\
dblFilter:all u,v ~~\
     (all t~~(t)=>t, cons[(u,v)])=>cons[(u,v)]\
dblFilter(M,[]) => []\
dblFilter(M,[(A,B),..L]) =>\
      [(M(A),M(B)),..dblFilter(M,L)]\
\
It is important to note that any actual function argument supplied to `dblFilter` will itself have to be generic -- i.e., its type will also be universally quantified.\
\
\
[[existentialType]]\
=== Existentially Quantified Types\
(((types,existentially quantified)))\
(((existentially quantified type)))\
(((exists`exists`)))\
\
An existential type denotes an _abstract_ type.\
\
[[existentialTypeFig]]\
.Existential Type Expression\
****\
[[ExistentialType]]ExistentialType ::= `exists` <<BoundType>>,..,<<BoundType>> `~~` <<Type>>\
****\
\
An existentially quantified type denotes a type within which there is an _abstract type_: i.e., the type exists but the expression is not explicit about which type.\
\
Existential types are most often used in the type signatures of abstract data types. For example, the term in the statement:\
[listing]\
R = \{\
  type el = integer\
  op(X,Y) => X+Y\
\}\
\
has type:\
[listing]\
exists el ~~ \{ el :: type; op:(el,el)=>el \}\
\
[NOTE]\
Note that the fact that within the record the type `el` is identified as `integer` does not escape the record itself. Externally, the existence of the type is known but not what it is.\
\
It is permissible to refer to the type within the record by a dot reference.\
\
[TIP]\
Existentially quantified types are generally not inferred for variables: i.e., if a variable has an existential type then that must be explicitly annotated.\
\
Existential types are inferred, however, for <<Record>>s that contain a <<TypeDefinition>> statement.\
\
==== Encapsulated Types\
[[encapsulatedType]]\
(((encapsulated type)))\
(((type,encapsulated in record)))\
(((existential type)))\
(((heterogenous types)))\
\
An <<EncapsulatedType>> is a reference to a type that is embedded within a record.\
\
\
[[encapsulatedTypeFig]]\
.Encapsulated Type\
****\
[[EncapsulatedType]]EncapsulatedType::=<<Expression>>``.``<<Identifier>>\
****\
\
As noted above, record literals may have types embedded within them. Such a record type is existentially quantified.\
\
It is possible to access the type embedded within such a record -- albeit with some restrictions:\
\
The form of an <<EncapsulatedType>> reference is limited to terms of the form:\
[listing]\
R.t\
\
where `R` is a <<Variable>> whose type interface contains the type `t`.\
\
More generally, an <<EncapsulatedType>> reference may involve a sequence of field names where each intermediate field name refers to a sub-record:\
[listing]\
R.f1.f2.t\
\
The `value' of an encapsulated type is strictly opaque: it is assumed to be different to all other types. Which means that effectively _only_ the other fields of the record variable `R` contain functions and values that can be used in conjunction.\
\
For example, consider the `group` type defined in:\
\
[[groupExample]]\
.The `group` Type\
[listing]\
----\
group ::= group\{\
  el :: quality[el] |: type\
\
  zero : el\
  op : (el,el)=>el\
  inv : (el)=>el\
\}\
----\
\
[TIP]\
====\
A `group` literal is analogous to a mathematical group: a set which is closed under a binary operation and whose elements have an inverse.\
\
The contents of a `group` literal contain the definitions of the elements, the binary operation, the zero element and the inverse function.\
====\
\
The qualification of the `el` type that it supports `equality` allows convenient access to equality of group elements. Without such a qualification, equality would not be possible for programs using `group` values.\
\
An additional requirement for a group is that its operation is associative. Such a property cannot be expressed in terms of type constraints.\
\
A `group` literal that implements the group for `integer`s is shown in:\
\
[[integerGroup]]\
.The `integer` `group` Record\
[listing]\
IG = group\{\
  type el = integer\
  zero = 0\
  op = (+)\
  inv(X) => -X\
\}\
\
The `IG` value contains the elements of a group value. We can, for example, access the `zero` of `IG` using the statement:\
[listing]\
IZ : IG.el\
IZ = IG.zero\
\
This asserts that `IZ`'s type is whatever the encapsulated type within `IG` is -- without being explicit about what that type is.\
\
It is possible to construct functions over `group`s that refer to encapsulated types. For example, the `invertGroup` function below constructs a new group by `inverting' the operation.\
\
[[invertGroupProgram]]\
.A `group` Inverting Function\
[listing]\
invertGroup : (group)=>group\
invertGroup(G) => group\{\
  type el = G.el\
  zero = G.zero\
  op(X,Y) => G.op(G.inv(X),G.inv(Y))\
  inv(X) => G.inv(X)\
\}\
\
== Type Constraints\
[[typeConstraints]]\
(((type,constraints)))\
\
A <<TypeConstraint>> is a constraint on a <<Type>>; usually implying a constraint on the possible binding of a <<TypeVariable>>.\
\
Generally, a <<TypeConstraint>> on a <<TypeVariable>> restricts in some sense the possible bindings for that type variable. For example, a <<Contract>> refers to a named collection of functions and a <<TypeVariable>> constrained by a <<ContractConstraint>> means that any concrete instantiation of the <<TypeVariable>> must be to a <<Type>> that `implement`s the <<Contract>>.\
\
Similarly, a <<FieldConstraint>> constrains the <<TypeVariable>> so that any binding must be to a <<Type>> that has the named field in its definition.\
\
For example, using `arithmetic` as a constraint allows us to say `the type can be anything that implements a form of arithmetic'. The type expression:\
[listing]\
arithmetic[t] |: t\
\
denotes this kind of constrained type.\
\
[NOTE]\
It is possible to view a type variable binding itself as a form of constraint: if we bind the type variable `t` to the type `integer` then we are constraining the type `t` to be equal to `integer`.\
\
\
[[typeConstraintFig]]\
.Type Constraints\
****\
[[TypeConstraint]]TypeConstraint ::= <<ContractConstraint>>\
  | <<FieldConstraint>>\
  | <<InstanceConstraint>>\
  | <<HasKindConstraint>>\
  | <<TupleConstraint>>\
  | <<TypeConstraint>> ,.., <<TypeConstraint>>\
****\
\
A type expression of the form:\
[listing]\
comparable[t], arithmetic[t] |: (t)=>t\
\
denotes a unary function type for any type that implements both the `comparable` and the `arithmetic` contracts (see <<comparisonPredicates>> and <<arithmeticContract>>).\
\
[NOTE]\
In many cases type inference will automatically result in constraints being added to type expressions.\
\
It is possible mix different forms of <<TypeConstraint>>; for example, if a <<TypeVariable>> must be bound to a type that implements the `comparable` contract as well as having the `integer`-typed `ident` attribute, the type expression:\
[listing]\
comparable[t], t <~ \{ ident:integer \}\
\
captures this.\
\
[NOTE]\
If a constrained type variable is unified with another type variable, then the constraints of the two variables are merged. It may be that such a merging of constraints is not possible; in such a case, the unification will fail.\
\
=== Contract Constraints\
[[contractContraint]]\
(((type,constraints!contract)))\
(((contract constraint)))\
\
A <<ContractConstraint>> is a requirement on a <<Type>> -- or tuple of <<Type>>s -- that whatever type it is, that there must exist an `implementation` of the <<Contract>> for the <<Type>> (see <<contracts>>).\
\
For example, the type constraint expression:\
[listing]\
comparable[t]\
\
means that the type variable `t` may only unify with concrete types that implement the `comparable` contract.\
[NOTE]\
If `t` is unified with another type variable, then the constraints on both type variables are _merged_.\
\
[NOTE]\
Since only named types may implement <<Contract>>s, it is also not permissible to unify the constrained variable with an structural type -- such as a function type.\
\
\
[[contractConstraintFig]]\
.Contract Constraint\
****\
[[ContractConstraint]]ContractConstraint ::= <<Identifier>>``[``<<TypeArgument>>``]``\
  | <<Identifier>>``[``<<TypeArgument>> \\->> <<TypeArgument>>``]``\
****\
\
It is possible for <<ContractConstraint>>s to reference more than one type. For example, the standard `coercion` contract (see <<typeCoercionContractFig>>) references two types. A `coercion` <<ContractConstraint>> will therefore look like:\
[listing]\
coercion[T1,T2]\
\
where `T1` represents the source type of the coercion and `T2` represents the destination type.\
\
If the `\\->>` clause is used, then the <<Contract>> being referenced must have a _functional dependency_\
(((functional dependency)))\
associated with it.\
\
[NOTE]\
Conversely, if a <<Contract>> has a functional dependency, then any constraint referring to it must also have a `\\->>` clause.\
\
The `\\->>` clause identifies which type(s) are dependent on the type argument(s) of the <<Contract>>. (See <<ContractFunctionalDependency>>).\
\
=== Field Constraints\
[[attributeConstraint]]\
(((type,field)))\
(((type,constraints!field)))\
\
A _FieldConstraint_ is a requirement on a variable that whatever type it is, it should have particular attributes of particular types defined for it.\
\
\
[[attributeConstraintFig]]\
.Field Constraint\
****\
[[FieldConstraint]]FieldConstraint ::= <<Type>> `<~` \{ <<TypeAnnotation>> ;..; <<Annotation>> \}\
****\
\
For example, in\
[listing]\
r <~ \{ alpha : string; beta : long \}\
\
if `r` is unified against a concrete type then that type's <<RecordType>> interface (see <<algebraicInterface>>) must contain both of `alpha` and `beta`. In addition, the fields must be of the right types.\
\
[NOTE]\
====\
It is also possible to require that an <<EncapsulatedType>> exists. For example, the constraint:\
[listing]\
s <~ \{ type elem \}\
====\
requires that any actual binding for type `s` must include the embedded type `elem`.\
\
\
=== Instance Constraint\
[[instanceConstraint]]\
(((type,constraints!instance)))\
\
An <<InstanceConstraint>> is a requirement on a variable that any instantiation of the variable is an `instance of' a type -- typically that is a universally quantified type.\
\
\
[[instanceConstraintFig]]\
.Instance Type Constraint\
****\
[[InstanceConstraint]]InstanceConstraint ::= <<TypeVar>> `instance of` <<Type>>\
****\
\
For example, in\
[listing]\
r instance of (all t ~~ (t)=>t)\
\
we establish a constraint on `r` that any binding of `r` must be some specialization of the function type:\
[listing]\
all t ~~ (t)=>t\
\
Note that this would permit, for example, `r` to be bound to the `integer` function type:\
[listing]\
(integer)=>integer\
\
because this type is an instance of the <<UniversalType>>.\
\
\
=== Has Kind Constraint\
[[hasKindConstraint]]\
(((type,constraints!has kind)))\
\
An <<HasKindConstraint>> is a requirement on a variable that any instantiation of the variable `has the right kind'.\
\
The kind of a type refers to whether the type is a regular type or a type constructor. It also encodes the expected number of type arguments -- in the case that the variable should be bound to a type constructor.\
\
[[hasKindConstraintFig]]\
.Has Kind Type Constraint\
****\
[[HasKindConstraint]]HasKindConstraint::=<<TypeVar>>\\ `::` <<Kind>>\
****\
\
For example, in\
[listing]\
c :: type\
\
we establish a constraint on `c` that any binding of `c` must be a <<Type>> (in particular, it may not be bound to a type constructor.\
\
The constraint:\
[listing]\
d :: type[type,type]\
\
establishes the constraint that `d` must be bound to a type constructor (_not_ a <<Type>>) of arity two. Given this constraint, it would not be legal to bind `d` to the standard type constructor `cons` (say) -- because `cons` is a type constructor of one argument.\
\
\
== Type Annotations\
[[typeAnnotation]]\
An <<Annotation>> is a statement that declares a variable to have a certain <<Type>> or a <<Type>> to have a certain <<Kind>>.\
\
For example,\
[listing]\
alpha:all t ~~~ (t)=>string\
\
is a <<TypeAnnotation>>, whereas\
[listing]\
el :: type\
\
is a <<KindAnnotation>>.\
\
[[typeAnnotationFig]]\
.Type Annotations\
****\
[[Annotation]]Annotation ::= <<TypeAnnotation>> | <<KindAnnotation>>\
\
[[TypeAnnotation]]TypeAnnotation ::= <<Identifier>> `:` <<Type>>\
\
[[KindAnnotation]]KindAnnotation ::= <<Identifier>> `::` <<Kind>>\
   | <<Identifier>> `::` <<TypeConstraint>> `|:` <<Kind>>\
\
[[Kind]]Kind::=`type` | `type/`<<Decimal>> | `type[type,..,type]`\
****\
\
\
== Type Definitions\
[[typeDefinitions]]\
(((type,definition)))\
\
A type definition is a statement that introduces a new type into the current scope. There are two forms of type definition statement: the <<TypeAlias>> definition and the <<AlgebraicType>> definition. In addition, the <<TypeWitness>> is used to `declare' a type.\
\
.Type Definition Statements\
[[typeDefinitionFig]]\
****\
[[TypeDefinition]]TypeDefinition ::= <<TypeAlias>> | <<AlgebraicType>> | <<TypeWitness>>\
****\
\
=== Type Alias\
[[typeAlias]]\
(((type,alias)))\
A type alias is a statement that introduces a new type name by mapping it to an existing type expression.\
\
.Type Alias Definition Statement\
[[typeAliasDefinitionFig]]\
****\
[[TypeAlias]]TypeAlias::=`type` <<TypeSpec>> `\\=>` <<Type>>\
****\
\
[NOTE]\
====\
Type aliases may be parameterized -- in the sense that the type being defined may be parameterized and that the definiens may also be parameterized.\
\
Note that the any type variables on the right hand side of a <<TypeAlias>> statement must also have been mentioned on the left hand side.\
====\
\
For example, the statement:\
[listing]\
type time => integer\
\
declares a new type that is an alias for `time` -- i.e., that it is actually equivalent to the `integer` type.\
\
[TIP]\
Type aliases allow the programmer to signal that a particular type is being used in a special way. In addition, during program development, type aliases are useful to provide markers for types that will be elaborated further with a regular algebraic definition.\
\
Type aliases have no run-time presence. In fact, they may be viewed as a simple form of type macro -- type expressions that match the left hand side are replaced by the type expression on the right hand side. However, type aliases have some definite constraints: a type alias may not be, directly or indirectly, recursive.\
\
=== Algebraic Type Definitions\
[[algebraicTypeDefinitions]]\
An algebraic type definition is a statement that introduces a new type; it also defines the possible values associated with the type.\
\
As illustrated in <<algebraicDefinitionFig>>, an algebraic type definition introduces the new type and defines one or more <<Constructor>>s -- separated by the `|` operator.\
\
A <<Constructor>> is a specification of a value of a type; i.e., constructors `paint a picture' of the shape of potential values of the type.\
\
There are three kinds of <<Constructor>>: enumerated symbols, term constructor constructors and labeled record constructors.\
\
[[algebraicDefinitionFig]]\
.Algebraic Type Definition Statement\
****\
[[AlgebraicType]]AlgebraicType::= <<TypeQuantifier>>   [`|:` <<TypeConstraint>>] <<TypeSpec>> `::=` <<Constructor>> | ... | <<Constructor>>\
\
[[TypeSpec]]TypeSpec ::= <<Identifier>>\
   | <<Identifier>> `[`<<TypeVariable>> ,...,<<TypeVariable>>``]``\
\
[[Constructor]]Constructor::=<<EnumeratedSymbol>>\
  | <<TermConstructor>>\
  | <<RecordConstructor>>\
****\
\
[NOTE]\
Most standard built-in types have type-specific constructors. For example, lists have a list notation, ``dictionary``s have a dictionary notation and so on. Such constructors may not be defined using the algebraic type definition notation -- for example, the constructors for the `integer` type are denoted by the normal decimal notation for integers.\
\
As elaborated below, each `arm' of an algebraic type definition defines a value or set of values that belong to the type. There is a slightly more formal way of expressing this: an algebraic type definition induces a set of free functions.\
\
(((constructor,bijection)))\
Free functions are technically bijections -- they are one-to-one -- i.e., they have inverses. In programming languages, free functions are used as data structuring tools; but mathematically they are functions.\
\
For example, the type definition:\
[listing]\
person ::= noone | someone(string,integer)\
\
induces the constructor function for `someone`:\
[listing]\
someone : (string,integer) <=> person;\
\
The enumerated symbol has a simpler type:\
[listing]\
noone : person;\
\
The complete set of constructor functions introduced within an algebraic type definition is complete: i.e., they define all the possible values of the type.\
\
\
[NOTE]\
A given label, whether it is used as an <<EnumeratedSymbol>>, the label of a <<LabeledType>> or a <<LabeledRecord>> can be defined only once. I.e., it is not permitted to `share' constructor labels across different types.\
\
==== Enumerated Symbol\
[[enumSymbol]]\
(((constructor,enumerated symbol)))\
(((enumerated symbol)))\
(((type,enumerated)))\
\
An enumerated symbol is written as an identifier. The fact that an identifier has been mentioned in a type definition is sufficient to `mark' it as a value -- and not as a variable for example.\
\
[[enumSymbolFig]]\
.Enumerated Symbols\
****\
[[EnumeratedSymbol]]EnumeratedSymbol::=<<Identifier>>\
****\
\
The standard type `boolean` is defined in terms of two enumerated symbols: `true` and `false`:\
[listing]\
boolean ::= true | false\
\
\
[NOTE]\
An enumerated symbol must be unique across all types within the scope of the type definition.\
\
==== Type Safety\
An enumerated symbol occurring within a type definition has the defined type.\
\
[NOTE]\
A particular consideration should be made for the case where an enumerated symbol is part of a universally quantified type.\
\
==== Term Constructor\
[[conFun]]\
(((constructor,positional constructor)))\
(((positional constructor)))\
(((type,positional constructor)))\
\
A term constructor expression or pattern is written in the style of a function call. The specification of the term constructor uses _types_ in argument positions to denote the type of the corresponding argument.\
\
[[positionalConFig]]\
.Term Specifier\
****\
[[TermConstructor]]TermConstructor ::= <<Identifier>> `(` <<Type>> ,.., <<Type>> `)`\
****\
\
For example, a type definition for wrapping return values with an error code could have a definition:\
[listing]\
all t ~~ returnType[t] ::= error(string) | ok(t)\
\
A function returning a value of type `returnType` would either return `ok(_value_)` or `error("_message_")`, where the message explained the error.\
\
term constructors are well suited to situations where the number of arguments is limited and fairly obvious.\
\
[NOTE]\
Any type variables that are referred to within a <<TermConstructor>> constructor must either be bound by explicit quantifiers or must appear in the head of the <<AlgebraicType>> definition itself.\
\
\
==== Record Constructor\
[[aggCon]]\
(((constructor,record constructor)))\
(((record constructor)))\
(((type,record constructor)))\
\
Labeled records denote constructors whose elements are addressed by name rather than by argument position. A labeled record specification consists of a collection type annotations (see <<typeAnnotationFig>>), separated by semicolons. In addition, the record specification may include _default_ values for some (or all) of the attributes of the record.\
\
\
[[aggregateConFig]]\
.Labeled Record Constructor\
****\
[[RecordConstructor]]RecordConstructor ::= <<Identifier>> `\{` <<ElementType>> ;..; <<ElementType>> `\}`\
\
[[ElementType]]ElementType ::= <<Annotation>>\
  | <<Identifier>> `default` `=` <<Expression>>\
  | <<Identifier>> `default` `:=` <<Expression>>\
  | <<DefltEquation>>\
  | `assert` <<Condition>>\
****\
\
If there is more than one record constructor for a type then any attributes that they have in common must have the same type associated with them. For example, the type definition for a two-three tree structure is illustrated in <<twoThree>>.\
\
[[twoThree]]\
.A `twoThree` tree type\
[listing]\
all s ~~ twoThree[s] ::=\
  three\{left:twoThree[s];\
        label:s;\
        right:twoThree[s]\
       \}\
  | two\{left:twoThree[s]; right:twoThree[s] \}\
  | empty;\
\
The `left` and `right` attributes in the two constructors are required to have the same type because they are shared by the two records.\
\
[TIP]\
Notice how the type annotations for the `left` and `right` sub-tree uses the same type identifier as in the definition itself. This marks `twoThree` as a _recursive_ type.\
\
\
==== Default Values\
[[defaultValues]]\
(((type,record constructor!default values)))\
(((default values,record constructor)))\
\
It is permitted to associate a _default value_ with a field of an record constructor. A default value is simply an expression for an attribute that is used should a particular record literal expression (see <<recordLiteral>>) not contain a value for that field.\
\
For example, for convenience, we might add `default` annotations in the `twoThree` type defined above, resulting in the type definition in <<twoThreeDef>>.\
\
[[twoThreeDef]]\
.A `twoThree` tree type with defaults\
[listing]\
all s ~~ twoThree[s] ::=\
  three\{ left:twoThree[s];\
         left default = empty;\
         label:s;\
         right:twoThree[s];\
         right default = empty;\
       \}\
  or two\{ left:twoThree[s];\
         left default = empty;\
         right:twoThree[s];\
         right default = empty;\
       \}\
  or empty;\
\
\
[NOTE]\
(((expressions,default)))\
(((variable,scope)))\
A default value expression for an attribute is evaluated in the scope that is valid for the type definition itself. The default value expression may reference variables that are in scope at the point of type definition. The default value expression may also reference _other_ fields of the record constructor -- as though they were variables -- provided that they themselves do not have `default`s associated with them.\
\
For example, in this definition of `Person`:\
[listing]\
Person ::= someone\{\
  name:string;\
  dob:date;\
  age:()=>float;\
  age() default => now()-dob;\
\}\
\
there is a `default` definition of the `age` field that is used if a given `someone` record literal does not mention a value for `age`. This `default` definition makes use of the `dob` field as though it were a free variable of the `age` function.\
\
\
==== Defaults of `ref` Fields\
(((expressions,default!assignable field)))\
(((ref field@`ref` field,default value)))\
\
To declare a `default` value for a `ref` field, the form:\
****\
<<Identifier>> default := <<Expression>>\
****\
\
should be used. For example, in the type:\
[listing]\
account ::= account\{\
  balance:ref integer;\
  balance default := 0\
\}\
\
the `balance` field is a `ref` field, and its default value is `0`.\
\
==== Type Variables and Safe Algebraic Type Definitions\
(((type variables in an algebraic type definition)))\
(((constructor type variables)))\
\
For an <<AlgebraicType>> definition to be safe requires a constraint on type variables within the definition. In particular, it is not permitted to `introduce' a type variable in any of the constructors in the definition.\
\
[NOTE]\
Specifically, any unbound type variables mentioned in a type definition must also occur within the <<TypeSpec>> or be bound by an enclosing type quantifier.\
\
\
For example, the type definition:\
[listing]\
opaque ::= op(t)\
\
is not valid because the type variable `t` mentioned in the `op` constructor is not mentioned in the <<TypeSpec>> -- unless `t` is actually bound by a quantifier in an enclosing form.\
\
[NOTE]\
The reason for this is that type safety cannot be guaranteed for such constructors. For example, consider the invalid function:\
[listing]\
badOp(op(23)) is false;\
\
The type signature for `badOp` is\
[listing]\
badOp:(opaque)=>boolean\
\
and, according to type inference rules, an expression such as:\
[listing]\
badOp(op("alpha"))\
\
would be type safe. However, this expression will lead to a run-time failure when the integer 23 is compared against the string `"alpha"`.\
\
[NOTE]\
Note that the converse case, where a type variable is mentioned in the <<TypeSpec>> is not mentioned in a constructor defined within the type definition is perfectly valid.\
\
It _is_ possible to have type variables mentioned in a constructor that are not defined in the <<TypeSpec>>. The constraint is that such type variables must be closed by quantification.\
\
For example, the type definition:\
[listing]\
univ ::= univ(all t ~~ t)\
\
is a legally valid <<AlgebraicType>> definition; albeit one that is quite restricted. Locally quantified types are usually associated with function types:\
[listing]\
uniFun ::= uniFun(all t ~~ (t,t)=>t)\
\
which describes a term constructor `uniFun` that expects a generic function as an argument.\
\
=== Automatic Synthesis of Contract Implementations\
(((automatically synthesizing implementations)))\
(((implementing contracts@`implementing` contracts)))\
\
In some cases, the `regular' implementation of a contract by be predicted by examining the algebraic type definition itself. The Star compiler automatically generates implementations of the `equality` and the `pPrint` contracts, for example, by inspecting the type definition itself.\
\
A programmer may extend this system of atomically implementing contracts by implementing a special macro whose name is of the form `implement\\_\\q\{name`\}. A type definition that is marked:\
[listing]\
person ::= some\{\
  name:string;\
\} | noOne\
  implementing Spec\
\
will result in the macro `implement_Spec` being invoked on the type definition.\
\
This is used, for example, to allow coercion between types and the standard `quoted` type to be synthesized, instead of being constructed manually.\
\
=== Algebraic Interface Record\
[[algebraicInterface]]\
An <<AlgebraicType>> definition induces an interface that is composed of all the fields in any of the <<RecordConstructor>>s that are defined within the definition.\
\
This interface -- which takes the form of a <<RecordType>> -- contains a <<Annotation>> for every <<Annotation>> that is present in a <<RecordConstructor>>.\
\
For example, the interface for the `account` type above consists of:\
[listing]\
\{\
  balance:ref integer;\
\}\
\
This interface is used when determining the type soundness of a <<RecordAccess>> expression.\
\
[NOTE]\
The condition noted above that two fields of the same name in two <<RecordConstructor>>s of the same <<AlgebraicType>> must have the same type can be formalized by declaring that the interface of an <<Algebraic>> type must be well formed (which is only possible if there is only a single <<Annotation>> for a given field).\
\
=== Type Witness Definition\
[[countsAs]]\
\
A <<TypeWitness>> definition declares that a given type exists. It is used to assert that a given existential type exists.\
\
\
[[typeCountsAsFig]]\
.Type Witness Statement\
****\
[[TypeWitness]]TypeWitness ::= `type` <<Identifier>> `=` <<Type>>\
****\
\
For example, in the expression:\
[listing]\
group\{\
  type elem = integer;\
  inv(X) => -X;\
  op(X,Y) => X+Y;\
  zero = 0;\
\}\
\
the statement:\
[listing]\
type elem = integer;\
\
asserts that the type `integer` is a witness for the existentially quantified type `elem`.\
[NOTE]\
<<TypeWitness>> statements are inherently internal statements: the witness type itself is not exposed by the record that contains the <<TypeWitness>> statement.\
\
== Contracts\
[[contracts]]\
(((type,contracts)))\
\
A contract is a specification of a set of functions and action procedures that form a coherent collection of functionality. Associated with a <<Contract>> are one or more <<Type>>s -- the contract is said to be `over' those types.\
\
=== Contract Definition\
[[ContractDefinition]]\
(((type,contracts!definition)))\
\
A contract definition is a statement that defines the functions and action procedures associated with a contract. As can be seen in <<ContractFig>>, a contract statement associates a contract name -- together with a set of type variables -- with a set of <<TypeAnnotation>>s that define the elements of the contract. Within the <<Contract>> statement, a <<TypeAnnotation>> may refer to the type(s) in the contract head.\
\
[[ContractFig]]\
.Contract Statement\
****\
[[Contract]]Contract ::= `contract` <<ContractSpec>> `<~` <<RecordType>>\
\
[[ContractSpec]]ContractSpec ::= [ <<TypeQuantifier>> ] <<Identifier>> [ <<TypeArgSpec>> [`\\->>` <<TypeArgSpec>> ]]\
****\
\
For example, the contract that underlies type coercion (see <<typeCoercionExpression>>) is:\
[listing]\
contract all s,t ~~ coercion[s,t] <~ \{\
  coerce:(s)=>t\
\}\
\
(((default values,contract)))\
A contract statement may also include _defaults_ for the names defined in the contract. If a given contract implementation does not give an implementation for a name that has a default associated for it, then the default is used.\
\
[NOTE]\
Default specifications may use variables that are in scope at the point of the contract specification. footnote:[This is generally not the same scope as where a contract implementation is given.]\
\
\
[TIP]\
====\
An important usage pattern for contracts is to represent _abstract types_. An abstract type is one defined by its contract rather than one defined by an explicit type definition.\
\
For example, the `arithmetic` contract in <<arithmeticContractProg>> defines a set of arithmetic functions. However, it can also be interpreted as a definition of an abstract type of arithmetic values -- the values that implement the `arithmetic` contract.\
====\
\
==== Functional Dependencies\
[[ContractFunctionalDependency]]\
(((type,contracts!functional dependencies)))\
(((functional dependencies in contracts)))\
(((determines@`determines`)))\
\
For certain forms of contract, it may be that the type parameters may not all be independent of each other. For example, consider the standard `iterable` contract (defined in <<iterateContractProg>>) which reads:\
[listing]\
contract all coll, el ~~ iterable[coll ->> el] <~ \{\
  iterate: all r ~~\
      (coll,(el,IterState[r])=>IterState[r],IterState[r]) =>\
        IterState[r];\
\}\
\
The intention of the `iterable` contract is to support processing collections of elements in a sequential manner. The type parameter `coll` identifies the collection to be iterated over; and the type parameter `el` identifies the type of each element.\
\
However, the collection's type uniquely determines the type of each element: the element type is not independent of the collection. For example, to iterate over a `cons[t]`, each element will be of type `t`; and to iterate over a `string` each element will be a `integer` even though the `string` type does not mention `integer`.\
\
[NOTE]\
Each `integer` represents a unicode code point in the `string`.\
\
Using a `\\->>` clause in a `contract` -- and in corresponding contract `implementation` statements -- allows the contract designer to signal this relationship.\
\
=== Contract Implementation\
[[ContractImplementation]]\
(((type,contracts!implementation)))\
\
A contract implementation is a specification of how a contract may be implemented for a specific type combination.\
\
[[ContractImplementationFig]]\
.Contract Implementation Statement\
****\
[[Implementation]]Implementation::=`implementation` <<ContractSpec>> [`default`] `=` <<Expression>>\
****\
\
The <<Type>>s mentioned in <<ContractSpec>> must be either <<TypeExpression>>s or, in the case of a `default` implementation, <<TypeVariable>>s.\
[NOTE]\
====\
In particular, it is not permitted to define an `implementation` of a contract for <<FunctionType>>s, <<PatternType>>s, nor for <<UniversalType>>s or <<ExistentialType>>s.\
\
It is permissible, however, to implement <<Contract>>s for <<TupleType>>s and <<RecordType>>s.\
====\
\
The body of a contract `implementation` must be an expression that gives a definition for each of the elements of the `contract` specification.\
\
[NOTE]\
A `contract` implementation may either take the form of a regular <<AnonymousRecord>> or an anonymous <<ThetaRecord>>.\
\
Usually, the implementation of a `contract` is fairly straightforward. Program~\\vref\{consSize\}, for example, gives the implementation of the standard `sizeable` contract for the `cons` type.\
\
[[consSize]]\
.Implementation of `sizeable` for `cons` values\
[listing]\
implementation all e ~~ sizeable[cons[e]] <= \{\
  size(nil) => 0\
  size(cons(_,T)) => size(T)+1\
  isEmpty(nil) => true\
  isEmpty(_) default => false\
\}\
\
\
==== Implementing Contracts with Functional Dependencies\
[[implContractFunctionalDependency]]\
(((type,contracts!functional dependencies)))\
\
Implementing a contract which has a functional dependency is exactly analogous to implementing a regular contract. The dependent type(s) must be identified in the `implementation` statement. For example, the initial part of the implementation of the `sequence` contract over ``string``s and ``integer``s is:\
[listing]\
implementation sequence[string->>integer] = \{\
  ...\
\
\
Note that this `implementation` implies that a ``sequence`` over a `string` fixes the element type to `integer` -- i.e., a unicode CodePoint.\
\
==== Default Contract Implementation\
[[defaultImplementation]]\
(((default implementation of contracts)))\
(((type,contracts!implementation!default)))\
(((default@`default`)))\
\
A `default` implementation for a contract denotes an implementation to use for a contract when there is no known implementation. This can occur in two common situations: where a contract function is used that references a type that does not have an implementation for the contract, and where there is no type information.\
\
[TIP]\
It is strongly recommended that the `default` implementation is generic; i.e., that the definition of the individual functions are generic. The contract type should be denoted by a variable and all the contract functions should be generic.\
\
For example, the implementation statement:\
[listing]\
implementation all r ~~ equality[r] default = \{\
  L=R => __equal(L,R)\
\}\
\
uses a generic internal definition of `__equal`.\
\
\
As noted above, a `default` implementation is only used in restricted circumstances:\
\
No available implementation::\
If a contract is referenced for a type that does not implement the contract then the `default` implementation will be used.\
+\
For example, given a contract:\
[listing]\
----\
contract foo over t is \{\
  bar has type (t)=>boolean;\
\}\
----\
and the functional expression:\
[listing]\
----\
bar("fred")\
----\
then, if `foo` is not implemented for `string`s then the `default` implementation will be used for this expression. Of course, if there is no `default` implementation then a compile error will be flagged.\
\
\
Variable type::\
In a few circumstances a reference may be made to a contract involving no known types. For example, in the condition:\
[listing]\
XX = nil\
\
there is a hidden type variable associated with the enumerated symbol `nil`.\
\
The symbol `nil` is from the standard definition of `cons`:\
[listing]\
all t ~~ cons[t] ::= nil | cons(t,cons[t])\
\
Since the type of `nil` is under-constrained -- i.e., the type of `nil` as an expression involves a type variable that is not constrained at all by the `nil` symbol -- even if `equality` is implemented for many types there is no way of knowing which implementation to use in this situation. In this case, a `default` implementation will be used if provided.\
\
\
==== Recursive Contract Implementations\
\
More complex contract implementations may require the use of auxiliary function definitions; and hence may involve the use of `let` or `using` expressions.\
\
For example, this is an implementation of the `comparable` contract for `cons` values.\
\
[[consCompare]]\
.Implementation of `comparable` for `cons` values\
----\
implementation all t ~~ comparable[t], equality[t] |: comparable[cons[t]] =\
  let\{\
    consLess : all t ~~ (cons[t],cons[t])=>boolean\
    consLess([],[_ ,.. _]) => true\
    consLess([X,..L1],[X,..L2]) => consLess(L1,L2)\
    consLess([X,.._], [Y,.._]) :: X<Y => true\
    consLess(_,_) default => false\
\
    consLessEq : all t ~~ (cons[t],cons[t])=>boolean\
    consLessEq([],_) => true\
    consLessEq([X,..L1],[Y,..L2]) :: X=<Y =>\
          consLessEq(L1,L2)\
    consLessEq(_,_) default => false\
  \} in \{\
    X < Y => consLess(X,Y)\
    X =< Y => consLessEq(X,Y)\
    X > Y => consLess(Y,X)\
    X >= Y => consLessEq(Y,X)\
  \}\
----\
[NOTE]\
The implementation of `comparable` for `cons` types is based on a requirement that the individual elements of lists must also be compared. Hence the clause\
\
[listing]\
comparable[t], equality[t] |: comparable[cons[t]]\
\
in the head of the contract `implementation` statement. The primary job of the definition of `<` within <<consCompare>> is to show how `cons` values may be compared. Our definition of inequality for `cons` values assumes that:\
\
\
. empty lists are less than any non-empty list;\
. one non-empty list is less than another if the first element is less than the first element of the second; and finally\
. if the first elements of the two lists are identical then we consider the tails of each list.\
\
[TIP]\
The curious reader may wonder why we introduce a new name `consLessEq` in order to define `=<` (and, by extension `consLess` for `<` etc.). The reason for this has to do with limitations on type inference in the context of recursive programs: within the equations that define a function, any _use_ of the function symbol must represent a recursive use.\
\
For example, in the equation:\
\
[listing]\
consLessEq([X,..L1],[Y,..L2]) :: X=<Y =>\
      consLessEq(L1,L2)\
\
the occurrence of `consLessEq` in the right hand side of the equation represents a recursive call to the function (`consLessEq`) being defined.\
\
\
However, if we tried to define `=<` without the use of the auxiliary name we would get two occurrences of `=<` which really represent different functions:\
[listing]\
[X,..L1] =< [Y,..L2] where X=<Y => L1 =< L2\
\
However, the two occurrences of `=<` refer to _different_ kinds of use: one is as a `normal' overloaded occurrence of `=<` and once as a recursive call to the function being defined.\
\
Normally, outside of the definition of the function, it is permitted to allow a given function to be used in different uses -- always assuming that the types are consistent. However, within the definition of a function, all occurrences of the function symbol must refer to the same function.\
\
In the case of the `=<` equation above, the type inference system would not be able to distinguish a recursive call from a call to a different overloaded function of the same name; and would assume that both uses of `=<` are intended to be part of the definition. This, in turn, would result in a type error being generated.\
\
In summary, when defining an overloaded function like `=<`, we often have to introduce an auxiliary function to `carry' the recursion.\
\
In defining the implementation of a contract, each of the variables that are part of the contract must either be defined or have a default definition within the `contract` specification itself.\
\
=== Resolving Overloaded Definitions\
[[overloading]]\
(((type,contracts!resolving)))\
(((overloading)))\
(((resolving overloaded definitions)))\
\
When a program refers to a contract-defined function -- i.e., a variable that is declared within a `contract` -- then that reference must be _resolved_ to an actual program before the program can be said to be executable.\
\
For example, consider the expression:\
[listing]\
A+3\
\
The `(+)` function is part of the `arithmetic` contract (see <<arithmeticContract>>) which means that we need to resolve the call to `(+)` to an actual implemented function.\
\
The type signature for `(+)` is:\
[listing]\
all t ~~ arithmetic[t] |: (t,t)=>t\
\
where the constraint\
[listing]\
arithmetic[t]\
\
is satisfied for any `t` for which there is an `implementation` of `arithmetic`.\
\
In this case we know, because `3` is an `integer` that the type of `A` must also be `integer` -- as is the type of the whole expression. So, the actual constraint after taking type inference into account is:\
[listing]\
arithmetic[integer]\
\
which _is_ satisfied because there is a standard implementation of `arithmetic` for `integer`.\
\
Implementations can be viewed as functions whose value is a record of all the elements of the defined contract. For example, the implementation function of `arithmetic` over `integer` has a definition that is similar to:\
[listing]\
arithmetic#integer() is arithmetic\{\
  X+Y => _integer_plus(X,Y)\
  ...\
  \}\
\
Resolving the expression `A+3` is achieved by replacing the abstract function `(+)` with an actual function:\
[listing]\
arithmetic#integer().+(A,3)\
\
In some cases, there is not sufficient information about the types of variables to fully resolve the appropriate definition to use. In this case, it must be true that the type(s) involved must be variable and that they `surface' to a point where the type variable(s) are generalized.\
\
Consider the lambda:\
[listing]\
(X,Y) => X+Y*Y\
\
The type of `X` and `Y` may not be completely known, and are denoted by the same type variable (`t`) say; `t` is, however, a constrained type that is bound by the scope of the function itself.\
\
Ultimately, in some larger scope, either the `t` type becomes grounded into some specific type, or it is bound by an explicit quantifier. The quantifier must reflect the contract constraint -- otherwise the compiler will report an error. For example, it might be that we defined a variable in a `let` <<ThetaEnvironment>>:\
[listing]\
addSq : all t arithmetic[t] |: (t,t)=>t\
addSq = ((X,Y)=>X+X*Y)\
\
The `arithmetic` contract constraint is surfaced to the same level where the type variable `t` is bound.\
\
In general, where an overloaded name is used, there are two permitted possibilities: the type constraints implied by the overloaded name are subsumed by an explicit type equality or the type variable is bound in some <<thetaEnvironment>>.\
\
[NOTE]\
The third possibility -- where the constrained type is a type variable but is not bound by a <<thetaEnvironment>> is an error -- an unresolved overloaded identifier error.\
\
In the case of the `addSq` definition, there is not enough information here to `fix' an actual implementation to use; and so we resolve this by rewriting the `addSq` function to take an additional argument -- the `arithmetic` dictionary represented by the variable `D`:\
[listing]\
addSq#(D) => let\{\
  addSq'(X,Y) => D.+(X,D.*(Y,Y));\
\} in addSq'\
\
In addition (sic), we will have to also resolve all _calls_ to `addSq` as well. A call to `addSq` such as:\
[listing]\
addSq(A,3)\
\
will be rewritten to:\
[listing]\
addSq#(arithmetic#integer())(A,3)\
\
because we know from the presence of the literal integer that `addSq` is being used with `integer` arguments.\
\
Resolving for contract implementations `pushes out' from expressions such as `A+3` outward until all references to contracts have been resolved by explicit implementations.\
\
[NOTE]\
It is an error for the top-level of a program -- i.e., package-level -- to contain unresolved references to contracts.\
\
The formal rules for satisfying (and hence resolving) contract constraints are shown in <<overloading>>.\
\
\
=== Standard Contracts\
[[standardContracts]]\
(((type,contracts!standard)))\
(((standard,contracts)))\
\
The language defines a few contracts as standard. These cover, for example, the concepts of `equality`, `comparable`, and `sizeable` entities and the `arithmetic` operations. These contracts are integral to the semantics of the language.\
\
[[standardContractTable]]\
.Standard Contracts\
[cols="1,5,2"]\
|===\
|Contract | Description | Reference\
\
|`equality[t]` |Definition of equality |  <<equalityPredicate>>\
\
|`comparable[t]` |Definition of comparability| <<comparisonPredicates>>\
\
|`arithmetic[t]`|Basic arithmetic| <<arithmeticContract>>\
\
|`math[t]` | Misc math functions | <<mathContract>>\
\
|`trig[t]` | Trigonometry functions| <<trigContract>>\
\
|`bitstring[t]` | Bitwise functions| <<bitString>>\
\
|`sizeable[t]` | Definition of `size` and `empty`| <<sizeableContract>>\
|`sequence[t]` | Sequences of values| <<sequenceContract>>\
|`indexable[t]` | Random access| <<indexableContract>>\
|`iterable[t]` | Iteration over collections| <<iterableContract>>\
|`coercion[s,t]` | Coerce between types| <<typeCoercionContract>>\
|`speech[a]` | Actor speech actions| <<speechContract>>\
|`pPrint[t]` | Pretty Print Display| <<pPrintContract>>\
|`computation[c]` | Computation Expressions| <<computationContractProg>>\
|`execution[c]` | Computation Expressions| <<executionContractProg>>\
|===\
\
[[typeSystem]]\
== Type System\
(((type,system)))\
\
The type system consists of a language of type expressions and a set of rules for showing consistency between types and programs.\
\
The foundation of these rules are the rules that relate one type to another; and the primary relationship involved here is subsumption.\
\
In addition there are rules for determining when various constraints are satisfied and there are rules that relate specific expressions to types.\
\
=== Type Subsumption\
[[typeSubsumption]]\
\
The type system is based on the concept of type _subsumption_. One type subsumes another if either it is already equivalent under some substitution or it is `more general' than the other.\
\
The intuition is that if a function expects a certain kind of argument then either a value of exactly that type or one that is more general may be supplied.\
\
We express this formally in terms of a subsumption relation `subsume`:\
\\[\
T\\sub1\\subsume\{\}T\\sub2\
\\]\
is read as\
\\begin\{quote\}\
$T\\sub1$ subsumes, or is more general than, $T\\sub2$.\
\\end\{quote\}\
In general, type checking takes place in a certain context. For subsumption, this context defines available implementations of contracts as well as recording the types of variables. Furthermore, subsumption is likely to lead to the instantiation of type variables. Hence, in general, the predicate that we establish takes the form:\
\\[\\entail\{E,\\theta\\sub\{in\}\}\{T\\sub1\\subsume\{\}T\\sub2\}\\leadsto\\theta\\sub\{out\}\\]\
where \\ensuremath\{\\theta\}\
takes the form \\ensuremath\{\\\{x\\sub1/t\\sub1\\sequence\{,\}x\\subn/t\\subn\}\\\}\
and defines a substitution of types t\\subi\{\} for type variables x\\subi\{\} where a given variable occurs at most once in the left hand side of a $x\\subi/t\\subi$ pair.\
\
\\begin\{aside\}\
We do not take account of constraints at this time.\
\\end\{aside\}\
\
==== Subsumption of Basic Types\
\
\\begin\{itemize\}\
\\item One <<TypeExpression>> subsumes another if they have the same arity, and if their type constructors and type arguments pairwise subsume:\
\\begin\{prooftree\}\
\\AxiomC\{\\entail\{E,\\theta\\sub0\}\{t\\sub1\\subsume u\\sub1\\leadsto\\theta\\sub1\}\\sequence\{\\ \}\\entail\{E,\\theta\\sub\{n-1\}\}\{t\\subn\\subsume u\\subn\\leadsto\\theta\\subn\}\}\
\\AxiomC\{\\entail\{E,\\theta\\subn\}\{C\\sub1\\subsume C\\sub2\\leadsto\\theta\}\}\
\\BinaryInfC\{\\entail\{E,\\theta\\sub0\}\{C\\sub1\\ `of`\\ (t\\sub1\\sequence\{,\}t\\subn)\\ \\subsume\\ C\\sub2\\ `of`\\ (u\\sub1\\sequence\{,\}u\\subn)\\leadsto\\theta\}\}\
\\end\{prooftree\}\
where $t\\subi$ and $u\\subi$ are <<Type>> expressions  and $C\\sub1$ and $C\\sub2$ are <<TypeConstructor>>s.\
\
\\item If a type variable $v$ is already in the unifier then we look it up:\
\\begin\{prooftree\}\
\\AxiomC\{\\ensuremath\{v/t\\sub1\\in\\theta\\subi\}\}\
\\AxiomC\{\\entail\{E,\\theta\\subi\}\{t\\sub1\\subsume\{\}t\\sub2\\leadsto\\theta\\sub\{o\}\}\}\
\\BinaryInfC\{\\entail\{E,\\theta\\subi\}\{v\\subsume\{\}t\\sub2\\leadsto\\theta\\sub\{o\}\}\}\
\\end\{prooftree\}\
\
\\begin\{prooftree\}\
\\AxiomC\{\\ensuremath\{v/t\\sub2\\in\\theta\\subi\}\}\
\\AxiomC\{\\entail\{E,\\theta\\subi\}\{t\\sub1\\subsume\{\}t\\sub2\\leadsto\\theta\\sub\{o\}\}\}\
\\BinaryInfC\{\\entail\{E,\\theta\\subi\}\{t\\sub1\\subsume\{\}v\\leadsto\\theta\\sub\{o\}\}\}\
\\end\{prooftree\}\
\
\\item A type variable $v$ may be inserted into the unifier:\
\\begin\{prooftree\}\
\\AxiomC\{\\ensuremath\{v/t\\notin\\theta\\subi\}\}\
\\AxiomC\{\\ensuremath\{v\\notin\{\}t\\sub2\}\}\
\\BinaryInfC\{\\entail\{E,\\theta\}\{v\\subsume\{\}t\\sub2\\leadsto\\theta\\cup\\\{v/t\\sub2\\\}\}\}\
\\end\{prooftree\}\
where the condition \\ensuremath\{v\\notin\{\}t\} means that $v$ does not occur free in type $t$.\
\\begin\{prooftree\}\
\\AxiomC\{\\ensuremath\{v/t\\notin\\theta\\subi\}\}\
\\AxiomC\{\\ensuremath\{v\\notin\{\}t\\sub1\}\}\
\\BinaryInfC\{\\entail\{E,\\theta\}\{t\\sub1\\subsume\{\}v\\leadsto\\theta\\cup\\\{v/t\\sub1\\\}\}\}\
\\end\{prooftree\}\
\
\\end\{itemize\}\
\
==== Subsumption of Tuples and Records\
\\begin\{itemize\}\
\
\\item One <<TupleType>> subsumes another if they are of the same length and each of their successive elements pairwise subsume.\
\\begin\{prooftree\}\
\\AxiomC\{\\entail\{E,\\theta\\sub0\}\{t\\sub1\\subsume u\\sub1\\leadsto\\theta\\sub1\}\\sequence\{\\quad\}\\entail\{E,\\theta\\sub\{n-1\}\}\{t\\subn\\subsume u\\subn\\leadsto\\theta\\subn\}\}\
\\UnaryInfC\{\\entail\{E,\\theta\\sub0\}\{(t\\sub1\\sequence\{,\}t\\subn)\\ \\subsume\\ (u\\sub1\\sequence\{,\}u\\subn)\\leadsto\\theta\\subn\}\}\
\\end\{prooftree\}\
where $t\\subi$ and $u\\subi$ are types.\
\
\
\\item One <<RecordType>> subsumes another if every element of the first pairwise subsumes a corresponding element of the second. For the purposes of this exposition we assume that neither type contains any encapsulated types: this case is dealt with below under existential quantification.\
\
\
\\begin\{prooftree\}\
\\AxiomC\{\\entail\{E,\\theta\\sub0\}\{t\\sub0\\subsume u\\sub1\\leadsto\\theta\\sub1\}\\sequence\{\\quad\}\\entail\{E,\\theta\\sub\{n-1\}\}\{t\\subn\\subsume\{\} u\\subn\\leadsto\\theta\\subn\}\}\
\\UnaryInfC\{\\entail\{E,\\theta\\sub0\}\{`\\\{`f\\sub1=t\\sub1\\sequence\{;\}f\\subn=t\\subn`\\`\}\\ \\subsume\\ `\\\{`f\\sub1=u\\sub1\\sequence\{;\}f\\subn=u\\subn`;..\\`\}\\leadsto\\theta\\subn\}\}\
\\end\{prooftree\}\
where the $f\\subi$ are distinct labels of fields and the trailing `;..` is intended to signify that there may be additional elements that are not considered.\
\
\\end\{itemize\}\
\
==== Subsumption of Function Types\
\
The rules for subsumption for function types introduces the concept of _contravariance_.\
\
\\begin\{itemize\}\
\
\\item A function type $F\\sub1$ subsumes $F\\sub2$ if the result types subsume and the argument types contra-subsume:\
\
\\begin\{prooftree\}\
\\AxiomC\{\\entail\{E,\\theta\\subi\}\{r\\sub1\\subsume\{\}r\\sub2\\leadsto\\theta\\sub0\}\}\
\\AxiomC\{\\entail\{E,\\theta\\sub0\}\{a\\sub2\\subsume\{\}a\\sub1\\leadsto\\theta\\sub\{o\}\}\}\
\\BinaryInfC\{\\entail\{E,\\theta\\subi\}\{a\\sub1`=>`r\\sub1\\subsume\{\}a\\sub2`=>`r\\sub2\\leadsto\\theta\\sub\{o\}\}\}\
\\end\{prooftree\}\
\
The subsumption relation is inverted for the argument types of the two function types. This reflects the intuition that for one function type to subsume another its result type must subsume the latter but the argument type of the latter should subsume (be more general than) the former.\
\\begin\{aside\}\
Without contravariance it becomes difficult and awkward to combine functions together.\
\\end\{aside\}\
\
\\item The subsumption relation for pattern types is similar to that for function types:\
\\begin\{prooftree\}\
\\AxiomC\{\\entail\{E,\\theta\\subi\}\{r\\sub1\\subsume\{\}r\\sub2\\leadsto\\theta\\sub0\}\}\
\\AxiomC\{\\entail\{E,\\theta\\sub0\}\{a\\sub2\\subsume\{\}a\\sub1\\leadsto\\theta\\sub\{o\}\}\}\
\\BinaryInfC\{\\entail\{E,\\theta\\subi\}\{r\\sub1`<=`a\\sub1\\subsume\{\}r\\sub2`<=`a\\sub2\\leadsto\\theta\\sub\{o\}\}\}\
\\end\{prooftree\}\
\
\\item Subsumption for constructor types requires equivalence rather than subsumption. This is because a constructor may be used both as a pattern and as a function. We use the \\equivt\{\} to denote this. We do not need to introduce a completely new definition for \\equivt\{\}, instead we can define it in terms of \\subsume:\
\
\\begin\{prooftree\}\
\\AxiomC\{\\entail\{E,\\theta\\subi\}\{t\\sub1\\subsume\{\}t\\sub2\\leadsto\\theta\\sub0\}\}\
\\AxiomC\{\\entail\{E,\\theta\\sub0\}\{t\\sub2\\subsume\{\}t\\sub1\\leadsto\\theta\\sub\{o\}\}\}\
\\BinaryInfC\{\\entail\{E,\\theta\\subi\}\{t\\sub1\\equivt\{\}t\\sub2\\leadsto\\theta\\sub\{o\}\}\}\
\\end\{prooftree\}\
\
Given this definition of \\equivt\{\}, we can define subsumption for constructor types:\
\\begin\{prooftree\}\
\\AxiomC\{\\entail\{E,\\theta\\subi\}\{r\\sub1\\equivt\{\}r\\sub2\\leadsto\\theta\\sub0\}\}\
\\AxiomC\{\\entail\{E,\\theta\\sub0\}\{a\\sub2\\equivt\{\}a\\sub1\\leadsto\\theta\\sub\{o\}\}\}\
\\BinaryInfC\{\\entail\{E,\\theta\\subi\}\{r\\sub1`<=>`a\\sub1\\subsume\{\}r\\sub2`<=>`a\\sub2\\leadsto\\theta\\sub\{o\}\}\}\
\\end\{prooftree\}\
\
Clearly, this definition is symmetric wrt the two constructor types, and we can also establish:\
\\begin\{prooftree\}\
\\AxiomC\{\\entail\{E,\\theta\\subi\}\{r\\sub1\\equivt\{\}r\\sub2\\leadsto\\theta\\sub0\}\}\
\\AxiomC\{\\entail\{E,\\theta\\sub0\}\{a\\sub2\\equivt\{\}a\\sub1\\leadsto\\theta\\sub\{o\}\}\}\
\\BinaryInfC\{\\entail\{E,\\theta\\subi\}\{r\\sub2`<=>`a\\sub2\\subsume\{\}r\\sub1`<=>`a\\sub1\\leadsto\\theta\\sub\{o\}\}\}\
\\end\{prooftree\}\
\
\\end\{itemize\}\
\
==== Subsumption of Quantified Types\
Subsumption of quantified types must take into account the implied semantics of the quantifiers: a <<UniversalType>> is less general than its bound type and so on.\
\
For simplicity of presentation we assume that all quantified types have been alpha-renamed so that no two quantified terms have the same bound variable.\
\
\\begin\{itemize\}\
\\item Any type subsumes its universally quantified variant if its subsumes a `refreshed' variant of the latter:\
\
\\begin\{prooftree\}\
\\AxiomC\{\\entail\{E,\\theta\\subi\}\{t\\sub1\\subsume\{\}t'\\sub2\\leadsto\\theta\\sub\{o\}\}\}\
\\AxiomC\{\\ensuremath\{t'\\sub2=t\\sub2[x/x']\}\}\
\\BinaryInfC\{\\entail\{E,\\theta\\subi\}\{t\\sub1\\subsume`for all x such that `t\\sub2\\leadsto\\theta\\sub\{o\}\}\}\
\\end\{prooftree\}\
where $x'$ is a variable not occurring elsewhere and $t[x/u]$ refers to the result of replacing occurrences of $x$ in $t$ with $u$.\
\
\
\\item A universally quantified type subsumes a type if the bound type of the former subsumes the latter without binding the bound variable.\
\
\\begin\{prooftree\}\
\\AxiomC\{\\entail\{E,\\theta\\subi\}\{t\\sub1\\subsume\{\}t\\sub2\\leadsto\\theta\\sub\{o\}\}\}\
\\AxiomC\{\\ensuremath\{x/t\\notin\\theta\\sub\{o\}\}\}\
\\BinaryInfC\{\\entail\{E,\\theta\\subi\}\{`for all x such that `t\\sub1\\subsume\{\}t\\sub2\\leadsto\\theta\\sub\{o\}\}\}\
\\end\{prooftree\}\
\
\\item An existentially quantified type subsumes a type if a `refreshed' variant of the\
former subsumes the latter:\
\
\\begin\{prooftree\}\
\\AxiomC\{\\entail\{E,\\theta\\subi\}\{t'\\sub1\\subsume\{\}t\\sub2\\leadsto\\theta\\sub\{o\}\}\}\
\\AxiomC\{\\ensuremath\{t'\\sub1=t\\sub1[x/x']\}\}\
\\BinaryInfC\{\\entail\{E,\\theta\\subi\}\{`exists x such that `t\\sub1\\subsume\{\}t\\sub2\\leadsto\\theta\\sub\{o\}\}\}\
\\end\{prooftree\}\
\
\\item A type subsumes its existentially quantified variant if\
the former subsumes the bound type of the latter without affecting the bound variable.\
\
\\begin\{prooftree\}\
\\AxiomC\{\\entail\{E,\\theta\\subi\}\{t\\sub1\\subsume\{\}t\\sub2\\leadsto\\theta\\sub\{o\}\}\}\
\\AxiomC\{\\ensuremath\{x/t\\notin\\theta\\sub\{o\}\}\}\
\\BinaryInfC\{\\entail\{E,\\theta\\subi\}\{t\\sub1\\subsume\{\}`exists x such that `t\\sub2\\leadsto\\theta\\sub\{o\}\}\}\
\\end\{prooftree\}\
\
\\end\{itemize\}\
\
\
%=== Satisfying Constraints\
%\
%==== Satisfying Contract Constraints\
%[[satisfyingContracts]]\
%(((contract constraint,satisfiability)))\
%(((satisfiability,contract constraint)))\
%(((resolving contract constraints)))\
%\
%A <<ContractConstraint>> of the form:\
%[listing][mathescape=true]\
%_Contract_ over (_Type\\sub1_\\sequence\{,\}_Type\\subn_) ...\
%\
%or\
%[listing]\
%_Contract_ over (_Type\\sub1_\\sequence\{,\}_Type\\subn_) determines (_Type\\sub\{n+1_\}\\sequence\{,\}_Type\\sub\{n+m_\}) ...\
%\
%(((determines@`determines`)))\
%is satisfiable if all of _Type\\sub1_ through _Type\\subn_ are <<TypeExpression>>s and there is an `implementation` for the types denoted. I.e., the constraint is satisfiable if there is a statement of the form:\
%[listing]\
%implementation _Contract_ over (_T\\sub1_\\sequence\{,\}_T\\subn_) ...\
%\
%or\
%[listing]\
%implementation _Contract_ over (_T\\sub1_\\sequence\{,\}_T\\subn_) determines (_T\\sub\{n+1_\}\\sequence\{,\}_T\\sub\{n+m_\}) ...\
%\
%respectively; where _Type\\subi_ unifies with _T\\subi_ for each $i$.\
%\
%\\begin\{aside\}\
%The determined types (_T\\sub\{n+1_\}\\sequence\{,\}_T\\sub\{n+m_\}) take part in the satisfiability of a contract; but they do not determine the applicability of a contract implementation. I.e. only the types mentioned before the `determines` clause actually affect the selection of the implementation.\
%\
%The intuition is that there is a dependency between the determined types and the main types: they are not independent.\
%\\end\{aside\}\
%\
%A `default` implementation of the form:\
%[listing]\
%implementation _Contract_ over (_V\\sub1_\\sequence\{,\}_V\\subn_) default is ...\
%\
%or, for contracts with functional dependencies, if it takes the form:\
%[listing]\
%implementation _Contract_ over (_V\\sub1_\\sequence\{,\}_V\\subn_)\
%         determines (_V\\sub\{n+1_\}\\sequence\{,\}_V\\sub\{n+m_\}) default is ...\
%\
%where all of `_V\\subi_` are <<TypeVariable>>s satisfies the <<ContractConstraint>> for `_Contract_` if _Type\\subi_ unify with _V\\subi_.\
%\
%\\begin\{aside\}\
%A <<ContractConstraint>> that has a `determines` clause can only be satisfied by an `implementation` that also has a matching `determines` clause. Conversely, a <<ContractConstraint>> that does not have a `determines` clause can only be satisfied by implementations that also do not have a `determines` clause.\
%\\end\{aside\}\
%\
%\\begin\{aside\}\
%This unification may induce other constraints, including constraints that require resolution of contracts.\
%\\end\{aside\}\
%\
%It is an error if there are more than one non-`default` candidates for satisfying a contract constraint. It is also an error if there are no candidates to satisfy the constraint.\
%\
%\\begin\{aside\}\
%One of the less obvious requirements in satisfying contract constraints is that the contract constraint must already be partially determined. In particular, the 'top-level' of the types in the constraint must be known -- unless the `default` implementation is used.\
%\\end\{aside\}\
%\
%==== Consistency of Contract Constraints\
%A <<TypeVariable>> may not be constrained by inconsistent type constraints.\
%\
%Two <<ContractConstraint>>s are consistent if either they are about different contracts, or if they are about the same contract the corresponding contract types are unifiable. In the latter case, the determined types (if present) must also unify.\
%\
%==== Satisfying Attribute Constraints\
%An <<FieldConstraint>> takes the form:\
%[listing]\
%<<Type>> implements \\\{ <<Identifier>>\\sub1 has type <<Type>>\\sub1\\sequence\{;\}<<Identifier>>\\subn has type <<Type>>\\subn \\\}\
%\
%An <<FieldConstraint>> is satisfiable if the left-hand <<Type>> is an <<AlgebraicType>> whose definition is such that for each <<Identifier>>\\subi\{\} has a <<LabeledRecord>> that includes a <<TypeAnnotation>> for the <<Identifier>> and whose corresponding type also unifies with <<Type>>\\subi.\
%\
%==== Consistency of Attribute Constraints\
%Two <<FieldConstraint>>s are consistent if either they are about different fields, or if they are about the same fields then corresponding field types must be unifiable.\
%\
%A <<TypeVariable>> can be constrained by any number of <<FieldConstraint>>s -- provided that they are consistent with each other. Similarly, a <<TypeVariable>> can be constrained by combinations of <<ContractConstraint>>s and <<FieldConstraint>>s.\
\
%=== Type Inference\
%[[typeConstraints]]\
%(((type,constraints)))\
%A type inference constraint is a predicate relating elements of the program and any type expressions; the general form of which is:\
%\\begin\{prooftree\}\
%\\AxiomC\{\\mbox\{_Condition_\}\}\
%\\UnaryInfC\{\\typeprd\{E\}\{X\}\{T\}\}\
%\\end\{prooftree\}\
%This should be read as\
%\\begin\{quote\}\
%If _Condition_ is satisfied, then we can infer from the context _E_ that _X_ has type _T_\
%\\end\{quote\}\
%where the symbol \\tinfers\{\} can be read as `type implication'. In general, the type of an expression depends on the context that it is found. The context of a type expression can be defined as a set of _bindings_ of names to values. Mostly these values are types -- the types of the names involved. But the environment also contains type definitions -- where the binding is from a name to a type.\
%\
%For example, the rule that determines if a function application is type-safe, and what resulting type of the expression is, is:\
%\\begin\{prooftree\}\
%\\AxiomC\{\\typeprd\{E\}\{F\}\{`(`t\\sub1,...,t\\subn`)``=>`\}_R_\}\
%\\AxiomC\{\\typeprd\{E\}\{`(`a\\sub1,...,a\\subn`)`\}\{`(`t\\sub1,...,t\\subn`)`\}\}\
%\\BinaryInfC\{\\typeprd\{E\}\{F`(`a\\sub1,...,a\\subn`)`\}\{R\}\}\
%\\end\{prooftree\}\
%This type rule implicitly calls for the unification of the type associated with the function and the types associated with the arguments to the function.\
%\
%The type rule for a variable bears some explanation:\
%\\begin\{prooftree\}\
%\\AxiomC\{$X:T\\in\{\}E$\}\
%\\UnaryInfC\{\\typeprd\{E\}\{X\}\{\\rm\{refresh\}(T)\}\}\
%\\end\{prooftree\}\
%This can be read as\
%\\begin\{quote\}\
%if the variable _X_ has type _T_ in the environment _E_, then the type of an _occurrence_ of the variable is refresh(T).\
%\\end\{quote\}\
%(((refreshing type variables)))\
%(((type,variable!refreshing)))\
%(((renaming type variables)))\
%(((variable,type of)))\
%refresh(T) is the result of rewriting a universally quantified types with a new type with new type variables. For example, the type\
%[listing]\
%cons of \\pcent\{\}t\
%\
%is better understood as being\
%[listing]\
%for all \\pcent\{\}t such that cons of \\pcent\{\}t footnote:[See Section \\vref\{universalType\}.]\
%\
%and refreshing this type means stripping the quantifier and replacing all occurrences of `\\pcent\{`t\} with a new variable:\
%[listing]\
%_refresh_(for all \\pcent\{\}t such that cons of \\pcent\{\}t) = cons of \\pcent\{\}t2341\
%\
%where `\\pcent\{`t2341\} is a `new' type variable that does not occur anywhere else.\
%\\begin\{aside\}\
%This procedure of refreshing a universally quantified type is equivalent to the logical operation of _variable renaming_. In this process, type variables are replaced with new type variables that do not occur elsewhere. In addition, the universal quantifiers within a logical formula are moved to the outermost left-hand side of the formula.\
%\\end\{aside\}\
\
%=== Type Generalization\
%[[typeGeneralization]]\
%(((type,generalization)))\
%(((generalized types)))\
%The complement of refreshing types is type _generalization_. Like refreshing, generalizing a type involves moving type quantifiers; in this case, quantifiers are moved inward rather than outward.\
%\
%(((theta environment)))\
%In a <<thetaEnvironment>>, definitions of programs -- functions, procedures and patterns -- involve a combination of inferring types based on the forms of the expressions and patterns and type generalization.\
%\
%For example, the rules of type inference will give a function expression such as:\
%[listing]\
%(function(X) is X)\
%\
%a type assignment of:\
%[listing]\
%(\\pcent\{\}t)=>\\pcent\{\}t\
%\
%\
%However, if a variable (`f`) within a <<thetaEnvironment>> is bound to such a value then the variable is given the type:\
%[listing]\
%for all \\pcent\{\}t such that (\\pcent\{\}t)=>\\pcent\{\}t\
%\
%\\begin\{aside\}\
%This assumes that the type variable `\\pcent\{`t\} is not referenced by any expression in the containing scope.\
%\
%It also assumes that the variable is not a re-assignable variable -- which in any case has a non-program type: a `ref` function type rather than a function type.\
%\\end\{aside\}\
%This is justified by the possibility of safely re-using the `f` function. For example, suppose that the <<thetaEnvironment>> also contains other definitions that reference `f`:\
%[listing]\
%foo(X) is f(X)+1;\
%...\
%bar(A) is f(A)++"a"\
%\
%The function `f` is used twice, but with different types for its argument; in one case `f` is used with an `integer` argument, in the other it is used with a `string` argument. It is safe to do so because the defining equation for `f` does not rely on the actual type of its argument.\
%\
%The formal description of this involves several steps:\
%\\begin\{enumerate\}\
%\\item A program definition -- such as a function definition -- of the form:\
%[listing]\
%f(_Ptn\\sub1_\\sequence\{,\}_Ptn\\subn_) is _Exp_\
%\
%is equivalent to the variable definition:\
%[listing]\
%f is (function(_Ptn\\sub1_\\sequence\{,\}_Ptn\\subn_) is _Exp_)\
%\
%I.e., in what follows, we are only concerned with variable definitions whose type is a program type. footnote:[A function may be defined by multiple equations. This does not materially alter this analysis.]\
%\
%\\item For such a variable definition, type safety requires that the value has a program type. For brevity we deal with the function case only, but this analysis applies to all program definitions.\
%\
%\\item\
%The defined variable is given a quantified type according to the type inference rule:\
%\\begin\{prooftree\}\
%\\AxiomC\{\\typeprd\{E\}\{Ex\}\{T\\sub\{Ex\}\}\}\
%\\AxiomC\{(`f`,\\ `for all \\pcent\{`t\\subi\{\} such that \}_T\\sub\{Ex_\})$\\in\\ $E\}\
%\\BinaryInfC\{\\typesafe\{E\}\{`f is `Ex\}\}\
%\\end\{prooftree\}\
%where `\\pcent\{`t\\subi\} is the subset of the type variables occurring in $T\\sub\{Ex\}$ that do not occur otherwise in _E_.\
%\\end\{enumerate\}\
%\
%\\begin\{aside\}\
%Logically, generalization is valid for _any_ type. However, the generalization rule is only applied to programmatic types -- such as function types, procedure types and pattern types.\
%\
%The reason is that these elements are inherently re-usable and their values do not `carry stateful information'.\
%\\end\{aside\}\
%\
%\\begin\{aside\}\
%Generalization of types is not applied to certain kinds of definition within a <<thetaEnvironment>>. In particular, it is not applied to re-assignable variables and it is not applied to <<MemoFunction>> defined variables.\
%\
%In the case of <<MemoFunction>>s, their execute-once semantics is not consistent with the re-usability assumption behind type generalization.\
%\\end\{aside\}\
}