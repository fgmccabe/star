= Programs

This chapter focuses on the organization of programs using functions,
types and other computational forms. Definitions occur at the
top-level of a package, but also within functions in
<<letExpression>>s and <<letAction>>s.

[#package]
== Package Structure
(((package)))

Packages represent compilation units for the Star compiler: a
source file should contain exactly one package.

A package consists of the package identifier and a set of
definitions enclosed in braces. For example, the text:

[source,star]
----
hello{
  hello() => "hello".
}
----

defines a `package` -- called `hello` -- that contains a
single function -- also called `hello`.

Typically, however, package identifiers take the form of a dotted
sequence of identifiers:

[source,star]
----
hello.example{
  hello() => "hello".
}
----

The body of a package may contain definitions and
may also include import statements.

[#packageFig]
.Package Structure
[source,star]
----
package --> packageName , ["{"], thetaEnvironment, ["}"].

packageName --> identifier, packageSuffix*.

packageSuffix >> Nm --> ["."], identifier.
----
(((package,name)))

Package names are not first class entities in Star: they are
refered to in some external structures -- such as catalogs and
repositories. They are also referred to within programs in the context
of import statements.

=== Managing Exposed Elements of a Package

By default, all the elements that are defined in a package are
_not_ exported as part of the package. Only those elements that
are marked `public` will be exported.footnote:[An element in a
package may be marked `private` -- which will also ensure that it
is not visible outside the package.]

[#thetaEnvironment]
== Environments and Definitions

The various types, functions, contracts and implementations
that make up a package are defined in the context of a _theta environment_. A
theta environment is a potentially mutually recursive collection of definitions.

[#definition]
(((program, declaration)))
The contents of a package consists of a set of definitions of types,
programs and variables.

[#statementFig]
.Theta Environment
[source,star]
----
thetaEnvironment --> definition * [dotSpace].

definition  --> typeAnnotation.
definition  --> typeDefinition.
definition  --> variableDefinition.
definition  --> functionDefinition.
definition  --> contractDefinition.
definition  --> contractImplementation.
definition  --> openStatement.
definition  --> importStatement.
----

NOTE: Theta environments also form the body of recursive let expressions and
actions and also form the contents of a recursive record.

There are a few differences between a package's theta environment and that of
recursive let expressions etc. In particular, the `importStatement` is only
valid at the package level.

Another difference is notational: recursive theta environments in expressions
are marked by special braces: `{.` and `.}`; whereas a package just uses regular
braces.

[#typeAnnotation]
=== Type Annotations

(((type, annotation)))
In most cases it is not necessary to explicitly declare the type of a
variable -- or any expression. However, it is good practice to declare
explicitly the types of programs; especially at the top level of a
package, and it is required if the type of the variable is intended to
be quantified.

[#typeAnnotationFig]
.Type Annotation
[source,star]
----
typeAnnotation >> (V:T) --> variable>>B [`:`], type>>T
----

For example, a generic function `consLength` that takes a
`cons` list and returns an integer would have the declaration:

[source,star]
----
consLength:all t ~~ (cons[t])=>integer
----

[#variableDefinition]
=== Variable Definition

(((variable definition)))
(((declaration, variable)))
A variable definition is a definition or an
action that explicitly denotes the declaration of a
variable. <<variableDefinition>>s may appear in packages, 
<<letExpression>>s and <<letAction>>s.

[#variableDeclararionFig]
.Variable Definition
[source,star]
----
variableDefition >> (V = E) --> variable >> V, [`=`], expression>>E.
variableDefition >> (P = E) --> varTuple >> P, [`=`], expression>>E.
variableDefition >> (V := E) --> variable >> V, [`:=`], expression>>E.

varTuple >> Vs --> [`(`], variable* >> Vs, [`)`].
----

The left-hand side of a variable declaration may be a tuple
of variables. This permits multiple variables to be declared
in a single statement. This, in turn, facilitates the handling of
functions that return more than one value.

For example, assuming that `split` partitions a `list` into a front half and a
back half, returning both in a 2-tuple, the declaration:

[source,star]
----
(L,R) = split(Lst)
----

will bind the variables `L` and `R` to the front and back
halves respectively.

A re-assignable variable is declared using the form:
[source,star]
----
variable := Expression
----

NOTE: Unlike single assignment variable declarations, the re-assignable
variable declaration is restricted to defining individual variables.

NOTE: It is not possible to declare a variable without also giving it a
value.

==== Variable Scope

(((variable, scope)))
(((scope of variable)))
In general, the scope of a variable extends to include the 
context in which it is declared:

let expression:: the scope of variables in a let expression includes the bound
expression, _but not the other definitions in the let expression_
let rec expression:: the scope of variables defined in a <<letRecExpression>>
includes the other definitions in the let rec -- and, of course, the bound
expression.
action:: variables declared as part of an action sequence are in scope from
immediately after the definition itself, up until the end of the sequence.
patterns:: variables that are defined in patterns have their scope limited to
the element that is associated with the pattern:
* variables defined in the head of an equation or other rule are scoped to that
  equation or rule.
* variables defined as part of a conditional expression or action have their
  scope extended to the _then_ part of the conditional, but not to any _else_
  part.
* variables defined in negated conditions do _not_ escape the negation.
* variables defined in patterns that govern a `for` loop or a `while` loop are
  in scope within the body of the loop -- but not outside the loop.
package:: variables that are defined in a `variableDefinition` in a package are
in scope for the entire package. In particular, package-level variables may be
mutually recursive.
+
NOTE: It is _not_ permissible for a non-program variable to
be involved in a mutually recursive group of variables. I.e., if a group of
mutually recursive of variables occurs in a package -- or in the body of a let
rec expression -- then all the variables must be bound to functions or other
program elements.
+
imported variables:: are in scope for the entire package.

NOTE: It is not permitted for a variable to be declared more than once in a
given action block.

===== Scope Hiding
(((scope, hiding)))
(((variable, hiding)))

It is not permitted to define a variable with the same name as another
variable that is already in scope. This applies to variables declared
in patterns as well as variables declared in
<<letExpression>>s.

For example, in the function:
[source,star]
----
hider(X) => let{
  X = 1
} in X
----

the inner declaration of `X` effectively amounts to an equality
test that the the `X` that occurs in the head of the function is
equal to `1`.

=== Re-assignable Variables

(((variable, re-assignable)))
Re-assignable variables serve two primary roles within programs: to
hold and represent state and to facilitate several classes of
algorithms that rely on the manipulation of temporary state in order
to compute a result.

In order to facilitate program combinations -- including procedural
abstraction involving re-assignable variables -- there are additional
differences between re-assignable variables and single-assignment
variables.

(((ref type)))
In particular, re-assignable variables have a distinguished type
compared to single-valued variables -- they must be <<referenceType>>.

In addition to the different type, there are two operators that are
associated with re-assignable variables: `ref` and `!`
(pronounced _shriek_). The former is used in situations where a
variable's name is intended to mean the variable itself -- rather than
its value. The latter is the converse: where an expression denotes a
reference value that must be `dereferenced'.

=== Functions and Equations

(((function)))
A function is a program for computing values; organized as a set of equations.

[#functionFig]
.Functions
[source,star]
----
functionDefinition --> equation*.

equation --> ruleHead, ["=>"], expression.
equation --> ruleHead, guardCondition, ["=>"], expression.
equation --> ruleHead, ["default"], ["=>"], expression.

ruleHead --> identifier, ["("], pattern, ([","], pattern)*, [")"].

guardCondition --> ["where"], condition.
----

NOTE: The rules in <<#functionFig>> are written assuming that the function's
name is not also an operator. If it is, then the head of the rule will take the
infix form.

TIP: Functions and other program values are first class values; as a result
they may be passed as arguments to other functions as well as being
assigned as attributes of records.

Functions can be defined in a let expression, in recursive records, in packages
-- or <<lambdaExpression>> can be used to craft a function literal directly as
an expression.

[#equation]
==== Equations

An equation is a rule for deciding how to rewrite an expression into a simpler
expression. Each equation consists of a <<tuplePattern>> that is used to match
the call to the function and a replacement expression. The left hand side of the
function may also have a guard associated with it, this guard may use variables
introduced in the pattern.

NOTE: An equation is said to apply iff the patterns in the left hand side of
the equation (including any `where` clauses) all match the
corresponding actual arguments to the function application.

(((theta environment)))
Functions are defined in the context of a scope --
for example, in the body of a `let` expression (see
<<letExpression>>), or at the top-level of a `package`.

==== Type of Functions

There are two primary ways in which the type of a function is computed: by
declaration or by inference.

If a function's type has been declared -- by having a <<typeAnnotation>> for the
name of the function in the same scope -- then the equations are _checked_ for
consistency with the type declaration. If the equations are not consistent with
the declaration then an error will be displayed.

If a function has no explicit type declaration then the type is inferred from
the shape of the equations. If no consistent type can be inferred -- for example
if the equations have differring arguments, or if the return values of the
equations are not consistent -- then a compiler error will be displayed.

Apart from the algorithms involved, there are other differences in types derived
by checking or inference:

* An inferred type will never be quantified. Any underspecified types arising as
  part of the inference process will be left unspecified. This may result in the
  unspecified types becoming bound by other elements of the program.
* As with quantification, type inference will not result in a generalized
  contract constraint. Any contract constraints that arise in the text of any
  equations will have to be resolved at the point of the function definition.
* Type inference cannot result in arguments to the function be assigned
  quantified types.footnote:[However, arguments can have type annotations of
  quantified types.]
* If a function is verified against a type declaration then some additional
  rules will be applied during type checking:
** a universally bound type variable may not be constrained further by the text of the function definition: it is as though such types were fixed and unique in the program (i.e., not equalt to any other type).
** an existentially bound type variable may be constrained by the text of the
 function. However, such constraints are not permitted to further constrain the
 type of the function and applications of the function will only 'see' a new
 constant type.
+
NOTE: Universally quantified and existentially quantified types
 are mirror images of each other: when a universal type variable is fixed, the
 existential type is variable and vice-versa.

==== Evaluation Order of Equations

(((equations,evaluation order)))
Using multiple equations to define a function permits a case-base approach to
function design -- each equation relates to a single case in the function. When
such a function is _applied_ to actual arguments then only one of the equations
in the definition may apply.

Equations are applied in the order that they are written -- apart from
any equation that is marked `default`. If two equations overlap
in their patterns then the first equation to apply is the one used.

==== Default Equations

(((default equation`default` equation)))
(((functions,default`default` equation)))
It is permitted to assign one of the equations in a function definition to be
the `default` equation. An equation marked as `default` is guaranteed _not_ to
be used if any of the non-default equations apply. Thus, a `default` equation
may be used to capture any remaining cases not covered by other equations.

(((patterns,variable pattern)))
A `default` equation may not have a `where` clause associated with
it, and furthermore, the patterns in the left hand-side should be
generally be variable patterns (see <<patternVariable>>).

NOTE: In particular, it _should_ be guaranteed that a `default`
equation cannot fail to apply.

==== Evaluation Order of Arguments

(((function application,evaluation order)))
There is _no_ guarantee as to the order of evaluation of
arguments to a function application. In fact, there is no guarantee
that a given expression will, in fact, be evaluated.

NOTE: The programmer should also _not_ assume that argument expressions
will _not_ be evaluated!

In general, the programmer should make the fewest possible assumptions
about order of evaluation.

[#patternCoverage]
==== Pattern Coverage

(((patterns,coverage of)))
Any given equation in a function definition need not completely cover
the possible arguments to the function. For example, in
[source,star]
----
F : (integer)=>integer.
F(0) => 1.
F(X) => X*F(X-1).
----

the first equation only applies if the actual argument is the number
`0`; which is certainly not all the `integer`s.

The set of equations that define a function also define a coverage of
the potential values of the actual arguments. In general, the coverage
of a set of equations is smaller than the possible values as
determined by the type of the function.

If a function is _partial_ -- i.e., if the coverage implied by
the patterns of the function's equations is not complete with respect
to the types -- then the compiler _may_ issue an incomplete
coverage warning. Furthermore, if a function fails to apply at
run-time then this is a _fatal error_ and evaluation of the
program will halt.

NOTE: The programmer is advised to make functions _total_ by supplying
an appropriate `default` equation. In the case of the
`F`actorial function above, we can make the `default` case
explicit as is shown in <<factorialFunProg>>.

[#factorialFunProg]
.Factorial Function
[source,star]
----
fact : (integer)=>integer.
fact(X) where X>0 => X*fact(X-1).
fact(X) default => 1
----


[#throwingFunctions]
==== Functions that throw exceptions
(((exception, throwing function)))

A function whose type is a throwing type, (see <<throwingFunctionType>>), may
return an exceptional value rather than a normal value. For example, this
definition of `check` will throw an exception -- encoded as a `string` -- when
its argument is false:

[source,star]
----
check:all t ~~ (boolean,t) => t throws string.
check(X,Y) => (~X ?? throw "check exception" || Y).
----

NOTE: This definition has an explicit type signature; this is because we cannot
reliably infer that a function should throw an exception.

[#exceptionType]
==== The standard `exception` type

Although not essential, Star has a built-in type that may be convenient for
reporting exceptions. The `exception` type is defined as:

[source,star]
----
public exception ::= .exception(string).
----

[#contract]
== Contract
(((type,contracts)))

A contract definition is a statement that defines the functions and
action procedures associated with a contract. As can be seen in
_contractFig_, a contract statement associates a contract name --
together with a set of type variables -- with a set of
_TypeAnnotation_s that define the elements of the contract. Within
the _Contract_ statement, a _TypeAnnotation_ may varer to the
type(s) in the contract head.

[#contractFig]
[#contractSpec]
.Contract Definition
[source,star]
----
contractDefinition --> ["contract"], contractSpec, ["::="], faceType.

contractSpec --> ["all","~~"], identifier, ["["], contractTypeArgs, ["]"].
contractSpec --> identifier, ["["], contractTypeArgs, ["]"].

contractTypeArgs --> typeVariable*, ["->>"], typeVariable*.
contractTypeArgs --> typeVariable*.
----

For example, the contract that underlies a <<typeCoercion>> expressions is:
[source,star]
----
contract all s,t ~~ coercion[s,t] ::= { coerce:(s)=>option[t] }
----

TIP: The type quantifier may be omitted from <<contract>> definitions -- _except_
for the case that a higher-kinded type is being quantified.

TIP: An important usage pattern for contracts is to represent
_abstract types_. An abstract type is one defined by its contract
rather than one defined by an explicit type definition.

For example, the `arith` contract in <<arithContractProg>> defines a set of
arithmetic functions. However, it can also be interpreted as a definition of an
abstract type of arithmetic values -- the values that implement the `arith`
contract.

.Under the covers
[sidebar]
****
If the contract statement looks like a type definition, that is
because it _is_ a kind of type definition. Specifically, it
defines a dictionary of sorts -- of the elements defined within the
contract.
****

[#ContractFunctionalDependency]
=== Functional Dependencies

(((type,contracts!functional dependencies)))
(((functional dependencies in contracts)))
For certain forms of contract, it may be that the type parameters may
not all be independent of each other. For example, consider the
standard `stream` contract (defined in
((streamContractProg))) which reads:
[source,star]
----
public contract all S,E ~~ stream[S ->> E] ::= {
  _eof:(S) => boolean.
  _hdtl:(S) => option[(E,S)].
}
----

The intention of the `stream` contract is to support processing collections of
elements in a sequential manner. The type parameter `S` identifies the
collection to be iterated over; and the type parameter `E` identifies the type
of each element.

However, the collection's type uniquely determines the type of each element: the
element type is not independent of the collection. For example, to iterate over
a `cons[t]`, each element will be of type `t`; and to iterate over a `string`
each element will be a `char` even though the `string` type does not mention
`char`.

Using a `->>` clause in a `contract` -- and in
corresponding contract `implementation` statements -- allows the
contract designer to signal this relationship.

=== Contract Implementation
(((type,contracts!implementation)))

A contract implementation is a specification of how a contract is to be
implemented for a specific type combination.

[#contractImplementationFig]
.Contract Implementation Statement
[source,star]
----
contractImplementation --> ["implementation"], contractSpec, ["=>"], expression.
----

NOTE: It is not permitted to define an `implementation` of a contract for
_FunctionType_s.

It is permissible, however, to implement contracts for
tuple types (see <<tupleType>>).

The body of a contract `implementation` must be an expression
that gives a definition for each of the elements of the
`contract` specification.

NOTE: A `contract` implementation often takes the form of a regular
_AnonymousRecord_ or an anonymous _ThetaRecord_.

Usually, the implementation of a `contract` is fairly
straightforward. The program in <<consSizeProg>>, for example, gives the
implementation of the standard `sizeable` contract for the
`cons` type.

[#consSizeProg]
.Implementation of `sizeable` for `cons` values
[source,star]
----
implementation all e ~~ sizeable[cons[e]] => {
  size(nil) => 0
  size(cons(_,T)) => size(T)+1

  isEmpty(nil) => .true.
  isEmpty(_) default  => .false
}
----

[#implContractFunctionalDependency]
=== Implementing Contracts with Functional Dependencies

(((type,contracts!functional dependencies)))
Implementing a contract which has a functional dependency is exactly analogous
to implementing a regular contract. The dependent type(s) must be identified in
the `implementation` statement. For example, the initial part of the
implementation of the `stream` contract over `cons` lists:

[source,star]
----
implementation all e ~~ stream[cons[e]->>e] => {
----

Note that this `implementation` implies that a `stream`
over a `cons` list connects the element type of the `cons[t]` type to the elements of the `stream` contract.

=== Recursive Contract Implementations

More complex contract implementations may require the use of auxiliary
function definitions; and hence may involve the use of `let`
expressions. This is particularly the case when implementing a
contract that itself depends on other contracts being implemented.

For example, this is an implementation of the `comp`
contract for `cons` values:

[#consCompProg]
.Implementation of `comp` for `cons`
[source,star]
----
public implementation all x ~~ comp[x],equality[x] |= comp[cons[x]] => let{.
  consLess(nil,_) => .true.
  consLess(cons(H1,T1),cons(H2,T2)) where H1<H2 => .true.
  consLess(cons(H1,T1),cons(H2,T2)) where H1==H2 => consLess(T1,T2).
  consLess(_,_) default => .false.

  consGe(L1,L2) => ~ consLess(L2,L1).
.} in {
  (<) = consLess.
  (>=) = consGe
}
----

NOTE: The implementation of `comp` for `cons` types is based
on a requirement that the individual elements of lists must also be
compared. Hence the clause

[source,star]
----
comp[x],equality[x] |= comp[cons[x]]
----

in the head of the contract `implementation` statement. The
primary job of the `consLess` function is to show how `cons`
values may be compared. However, it depends on `<` being defined
for the element of the `cons` list.

Our definition of inequality for `cons` values assumes that:
* `nil` lists are less than any non-empty list;
* one non-empty list is less than another if the first element is less
than the first element of the second; and finally
* if the first elements of the two lists are identical then we consider
the tails of each list.

TIP: The curious reader may wonder why we introduce a new name `consLess` in
order to define `<` (and, by extension `consGe` for `>=`). The reason for this
has to do with limitations on type inference in the context of recursive
programs: within the equations that define a function, any _use_ of the function
symbol must represent a recursive use.


For example, in the equation:
[source,star]
----
consLess(cons(H1,T1),cons(H2,T2)) where H1<H2 => .true.
----
we are relying on a definition of inequality for the elements of the
`cons` list -- whilst we are defining inequality for `cons`
lists themselves.

If we had tried to define `<` directly, using, for example:
[source,star]
----
cons(H1,T1)<cons(H2,T2) where H1<H2 => .true.
----
then we would have two occurrences of `<` which really
represent different functions.

Normally, outside of the definition of the function, it is permitted
to allow a given function to be used in different uses -- always
assuming that the types are consistent. However, within the definition
of a function, all occurrences of the function symbol must varer to
the same function.

In the case of the `<` equation above, the type inference system would not be
able to distinguish a recursive call from a call to a different overloaded
function of the same name; and would assume that both uses of `<` are intended
to be part of the same definition. This, in turn, would result in a type error
being generated.

In summary, when defining an overloaded function like `<`, we often have to
introduce an auxiliary function to _carry_ the recursion.

By using the `let` expression and the auxilliary `consLess` function we are able
to separately define inequality for `cons` lists while depending on the
implementation of `<` for their elements.

== Importing Packages

(((import package)))
(((package,import)))
The <<importStatement>> is used to signal that this package
depends on other packages.footnote:[The `import` statement is
only permitted at the top-level of a package.]

A package may use another package by importing it. The <<importStatement>>
denotes a requirement that the types, programs and other elements of the
imported package are made available to the importing package.

The <<importStatement>> is used to denote that the exported
elements of another package should be made available within this package.

[#importStatementFig]
.Import Package Statement
[source,star]
----
importStatement --> ["import"], packageName.
importStatement --> ["public", "import"], packageName.
----

[#importStatement]
=== The `import` Statement

(((import,statement)))
(((statement,import)))
An `import` statement of the form:
[source,star]
----
import sample.pkg
----
imports all the definitions that are located with the `sample.pkg` and
declares them as being at the _same_ scope level as other
((Definition))s within the package.

This has two primary implications: all the exported definitions may be used
without qualification as though they had been defined locally. However, if a
given name is declared twice -- even if in two separate packages -- then the
compiler will show an error.

In addition to the regular functions and types defined in the imported package,
any contracts, and contract implementations that are defined in the imported
package are also in scope.

If the <<openStatement>> is prefixed by a `public` keyword then, in addition to
importing the definitions, they are also implicitly _re-exported_ by thhis
package.

NOTE: By using `public` package imports it is possible to construct the
equivalent of a library -- consisting of multiple packages internally
but viewed as a single package externally.

[#openStatement]
=== Open Statement

(((open statement)))
(((opening a record)))
(((record,opening)))
The `open` statement takes a record-valued expression and
opens its contents in a <<thetaEnvironment>> -- such as a package.

[#openStatementFig]
.Open Statement
[source,star]
----
openStatement --> ["open"], expression.
----

Any fields and types that are declared within the <<expression>>'s
type become defined within the enclosing scope.

NOTE: The existing scope rules continue to apply; in particular, if there is
a name that is duplicated already in scope then a duplicate definition
error will be signaled.

Normal type inference is not able to infer anything about the type of
the `open`ed <<expression>>. Hence, this statement requires
that the type of the expression is already known.

For example, given the definition:
[source,star]
----
R : { type elem. op:(elem,elem)=>elem. zero:elem }
R = {
  integer ~> elem.
  op(X,Y) => X+Y.
  zero = 0.
}
----

then we can `open` `R` in a <<letExpression>>:
[source,star]
----
let{
  open R.
  Z : elem.
  Z = zero.
} in Z
----

NOTE: Although the `open` statement makes available the types and fields
embedded in a record; existential abstraction still applies. In particular, in
this case the fact that the `elem` type is manifest as `integer` within the
record expression `R` is hidden.

The `elem` type (and the `zero` and `op` fields) are available within the `let`;
but no information about what `elem` actually is is available.




